{"id": 59, "pattern_type": "refactoring", "file_path": "community/memories/spring-ai-alibaba-mysql-memory/src/main/java/com/alibaba/cloud/ai/memory/mysql/serializer/MessageDeserializer.java", "file_extension": "java", "input": "package com.alibaba.cloud.ai.memory.mysql.serializer;\n\nimport com.fasterxml.jackson.core.JsonParser;\nimport com.fasterxml.jackson.core.type.TypeReference;\nimport com.fasterxml.jackson.databind.DeserializationContext;\nimport com.fasterxml.jackson.databind.JsonDeserializer;\nimport com.fasterxml.jackson.databind.JsonNode;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.ai.chat.messages.AssistantMessage;\nimport org.springframework.ai.chat.messages.Message;\nimport org.springframework.ai.chat.messages.UserMessage;\nimport org.springframework.ai.model.Media;\n\nimport java.io.IOException;\nimport java.util.Collection;\nimport java.util.Map;\n\n/**\n * @author yingzi\n * @date 2025/3/23:15:12\n */\npublic class MessageDeserializer extends JsonDeserializer<Message> {\n\n\tprivate static final Logger logger = LoggerFactory.getLogger(MessageDeserializer.class);\n\n\tpublic Message deserialize(JsonParser p, DeserializationContext ctxt) {\n\t\tObjectMapper mapper = (ObjectMapper) p.getCodec();\n\t\tJsonNode node = null;\n\t\tMessage message = null;\n\t\ttry {\n\t\t\tnode = mapper.readTree(p);\n\t\t\tString messageType = node.get(\"messageType\").asText();\n\t\t\tswitch (messageType) {\n\t\t\t\tcase \"USER\" -> message = new UserMessage(node.get(\"text\").asText(),\n\t\t\t\t\t\tmapper.convertValue(node.get(\"media\"), new TypeReference<Collection<Media>>() {\n\t\t\t\t\t\t}), mapper.convertValue(node.get(\"metadata\"), new TypeReference<Map<String, Object>>() {\n\t\t\t\t\t\t}));\n\t\t\t\tcase \"ASSISTANT\" -> message = new AssistantMessage(node.get(\"text\").asText());\n\t\t\t\tdefault -> throw new IllegalArgumentException(\"Unknown message type: \" + messageType);\n\t\t\t}\n\t\t\t;\n\t\t}\n\t\tcatch (IOException e) {\n\t\t\tlogger.error(\"Error deserializing message\", e);\n\t\t}\n\t\treturn message;\n\t}\n\n}", "output": "/*\n * Copyright 2024-2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.alibaba.cloud.ai.memory.mysql.serializer;\n\nimport com.fasterxml.jackson.core.JsonParser;\nimport com.fasterxml.jackson.core.type.TypeReference;\nimport com.fasterxml.jackson.databind.DeserializationContext;\nimport com.fasterxml.jackson.databind.JsonDeserializer;\nimport com.fasterxml.jackson.databind.JsonNode;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.ai.chat.messages.AssistantMessage;\nimport org.springframework.ai.chat.messages.Message;\nimport org.springframework.ai.chat.messages.UserMessage;\nimport org.springframework.ai.model.Media;\n\nimport java.io.IOException;\nimport java.util.Collection;\nimport java.util.Map;\n\npublic class MessageDeserializer extends JsonDeserializer<Message> {\n\n\tprivate static final Logger logger = LoggerFactory.getLogger(MessageDeserializer.class);\n\n\tpublic Message deserialize(JsonParser p, DeserializationContext ctxt) {\n\t\tObjectMapper mapper = (ObjectMapper) p.getCodec();\n\t\tJsonNode node = null;\n\t\tMessage message = null;\n\t\ttry {\n\t\t\tnode = mapper.readTree(p);\n\t\t\tString messageType = node.get(\"messageType\").asText();\n\t\t\tswitch (messageType) {\n\t\t\t\tcase \"USER\" -> message = new UserMessage(node.get(\"text\").asText(),\n\t\t\t\t\t\tmapper.convertValue(node.get(\"media\"), new TypeReference<Collection<Media>>() {\n\t\t\t\t\t\t}), mapper.convertValue(node.get(\"metadata\"), new TypeReference<Map<String, Object>>() {\n\t\t\t\t\t\t}));\n\t\t\t\tcase \"ASSISTANT\" -> message = new AssistantMessage(node.get(\"text\").asText());\n\t\t\t\tdefault -> throw new IllegalArgumentException(\"Unknown message type: \" + messageType);\n\t\t\t}\n\t\t\t;\n\t\t}\n\t\tcatch (IOException e) {\n\t\t\tlogger.error(\"Error deserializing message\", e);\n\t\t}\n\t\treturn message;\n\t}\n\n}", "metadata": {"commit_sha": "8f186538", "lines_added": 15, "lines_deleted": 4, "total_changes": 19, "chunks": 2}}
{"id": 178, "pattern_type": "other", "file_path": "spring-ai-alibaba-deepresearch/src/main/java/com/alibaba/cloud/ai/example/deepresearch/config/DeepResearchConfiguration.java", "file_extension": "java", "input": "/*\n * Copyright 2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage com.alibaba.cloud.ai.example.deepresearch.config;\n\nimport com.alibaba.cloud.ai.example.deepresearch.config.rag.RagProperties;\nimport com.alibaba.cloud.ai.example.deepresearch.dispatcher.BackgroundInvestigationDispatcher;\nimport com.alibaba.cloud.ai.example.deepresearch.dispatcher.CoordinatorDispatcher;\nimport com.alibaba.cloud.ai.example.deepresearch.dispatcher.HumanFeedbackDispatcher;\nimport com.alibaba.cloud.ai.example.deepresearch.dispatcher.InformationDispatcher;\nimport com.alibaba.cloud.ai.example.deepresearch.dispatcher.ProfessionalKbDispatcher;\nimport com.alibaba.cloud.ai.example.deepresearch.dispatcher.ResearchTeamDispatcher;\nimport com.alibaba.cloud.ai.example.deepresearch.dispatcher.RewriteAndMultiQueryDispatcher;\nimport com.alibaba.cloud.ai.example.deepresearch.dispatcher.UserFileRagDispatcher;\nimport com.alibaba.cloud.ai.example.deepresearch.model.enums.ParallelEnum;\n\nimport com.alibaba.cloud.ai.example.deepresearch.node.BackgroundInvestigationNode;\nimport com.alibaba.cloud.ai.example.deepresearch.node.CoderNode;\nimport com.alibaba.cloud.ai.example.deepresearch.node.CoordinatorNode;\nimport com.alibaba.cloud.ai.example.deepresearch.node.HumanFeedbackNode;\nimport com.alibaba.cloud.ai.example.deepresearch.node.InformationNode;\nimport com.alibaba.cloud.ai.example.deepresearch.node.ParallelExecutorNode;\nimport com.alibaba.cloud.ai.example.deepresearch.node.PlannerNode;\nimport com.alibaba.cloud.ai.example.deepresearch.node.ProfessionalKbDecisionNode;\nimport com.alibaba.cloud.ai.example.deepresearch.node.ReporterNode;\nimport com.alibaba.cloud.ai.example.deepresearch.node.ResearchTeamNode;\nimport com.alibaba.cloud.ai.example.deepresearch.node.ResearcherNode;\nimport com.alibaba.cloud.ai.example.deepresearch.node.RewriteAndMultiQueryNode;\nimport com.alibaba.cloud.ai.example.deepresearch.service.RagNodeService;\nimport com.alibaba.cloud.ai.example.deepresearch.service.SessionContextService;\nimport com.alibaba.cloud.ai.example.deepresearch.service.multiagent.QuestionClassifierService;\nimport com.alibaba.cloud.ai.example.deepresearch.service.ReportService;\nimport com.alibaba.cloud.ai.example.deepresearch.service.multiagent.SearchPlatformSelectionService;\nimport com.alibaba.cloud.ai.example.deepresearch.service.multiagent.SmartAgentDispatcherService;\n\nimport com.alibaba.cloud.ai.example.deepresearch.serializer.DeepResearchStateSerializer;\nimport com.alibaba.cloud.ai.example.deepresearch.service.InfoCheckService;\nimport com.alibaba.cloud.ai.example.deepresearch.service.SearchFilterService;\nimport com.alibaba.cloud.ai.example.deepresearch.service.multiagent.ToolCallingSearchService;\nimport com.alibaba.cloud.ai.example.deepresearch.util.ReflectionProcessor;\nimport com.alibaba.cloud.ai.graph.GraphRepresentation;\nimport com.alibaba.cloud.ai.graph.KeyStrategy;\nimport com.alibaba.cloud.ai.graph.KeyStrategyFactory;\nimport com.alibaba.cloud.ai.graph.OverAllState;\nimport com.alibaba.cloud.ai.graph.StateGraph;\nimport com.alibaba.cloud.ai.graph.exception.GraphStateException;\nimport com.alibaba.cloud.ai.graph.state.strategy.ReplaceStrategy;\nimport com.alibaba.cloud.ai.toolcalling.jinacrawler.JinaCrawlerService;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.ai.chat.client.ChatClient;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.boot.context.properties.EnableConfigurationProperties;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\n\nimport java.util.HashMap;\nimport java.util.Map;\n\nimport static com.alibaba.cloud.ai.graph.StateGraph.END;\nimport static com.alibaba.cloud.ai.graph.StateGraph.START;\nimport static com.alibaba.cloud.ai.graph.action.AsyncEdgeAction.edge_async;\nimport static com.alibaba.cloud.ai.graph.action.AsyncNodeAction.node_async;\n\nimport com.alibaba.cloud.ai.example.deepresearch.service.McpProviderFactory;\n\n/**\n * @author yingzi\n * @since 2025/5/17 17:10\n */\n@Configuration\n@EnableConfigurationProperties({ DeepResearchProperties.class, PythonCoderProperties.class,\n\t\tMcpAssignNodeProperties.class, RagProperties.class, ReflectionProperties.class, SmartAgentProperties.class })\npublic class DeepResearchConfiguration {\n\n\tprivate static final Logger logger = LoggerFactory.getLogger(DeepResearchConfiguration.class);\n\n\t@Autowired\n\tprivate ChatClient coderAgent;\n\n\t@Autowired\n\tprivate ChatClient researchAgent;\n\n\t@Autowired\n\tprivate ChatClient reporterAgent;\n\n\t@Autowired\n\tprivate ChatClient backgroundAgent;\n\n\t@Autowired\n\tprivate ChatClient coordinatorAgent;\n\n\t@Autowired\n\tprivate ChatClient plannerAgent;\n\n\t@Autowired\n\tprivate ChatClient reflectionAgent;\n\n\t@Autowired\n\tprivate ChatClient.Builder rewriteAndMultiQueryChatClientBuilder;\n\n\t@Autowired\n\tprivate DeepResearchProperties deepResearchProperties;\n\n\t@Autowired\n\tprivate ReflectionProperties reflectionProperties;\n\n\t@Autowired(required = false)\n\tprivate JinaCrawlerService jinaCrawlerService;\n\n\t@Autowired\n\tprivate RagProperties ragProperties;\n\n\t@Autowired\n\tprivate ReportService reportService;\n\n\t@Autowired\n\tprivate SessionContextService sessionContextService;\n\n\t@Autowired(required = false)\n\tprivate McpProviderFactory mcpProviderFactory;\n\n\t@Autowired\n\tprivate InfoCheckService infoCheckService;\n\n\t@Autowired\n\tprivate SearchFilterService searchFilterService;\n\n\t// 可选的工具调用服务（智能平台用）\n\t@Autowired(required = false)\n\tprivate ToolCallingSearchService toolCallingSearchService;\n\n\t@Autowired(required = false)\n\tprivate QuestionClassifierService questionClassifierService;\n\n\t@Autowired(required = false)\n\tprivate SearchPlatformSelectionService searchPlatformSelectionService;\n\n\t@Autowired(required = false)\n\tprivate SmartAgentDispatcherService smartAgentDispatcher;\n\n\t@Autowired\n\tprivate SmartAgentProperties smartAgentProperties;\n\n\t@Autowired\n\tprivate RagNodeService ragNodeService;\n\n\t@Bean\n\tpublic ReflectionProcessor reflectionProcessor() {\n\t\tif (!reflectionProperties.isEnabled()) {\n\t\t\treturn null; // Return null if reflection mechanism is not enabled\n\t\t}\n\t\t// Use dedicated reflection agent\n\t\treturn new ReflectionProcessor(reflectionAgent, reflectionProperties.getMaxAttempts());\n\t}\n\n\t@Bean\n\tpublic StateGraph deepResearch(ChatClient researchAgent) throws GraphStateException {\n\n\t\tKeyStrategyFactory keyStrategyFactory = () -> {\n\t\t\tHashMap<String, KeyStrategy> keyStrategyHashMap = new HashMap<>();\n\t\t\t// 条件边控制：跳转下一个节点\n\t\t\tkeyStrategyHashMap.put(\"coordinator_next_node\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"rewrite_multi_query_next_node\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"background_investigation_next_node\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"planner_next_node\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"information_next_node\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"human_next_node\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"research_team_next_node\", new ReplaceStrategy());\n\t\t\t// 用户输入\n\t\t\tkeyStrategyHashMap.put(\"query\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"optimize_queries\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"thread_id\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"enable_deepresearch\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"auto_accepted_plan\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"plan_max_iterations\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"max_step_num\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"mcp_settings\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"optimize_query_num\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"user_upload_file\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"session_id\", new ReplaceStrategy());\n\n\t\t\tkeyStrategyHashMap.put(\"feed_back\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"feed_back_content\", new ReplaceStrategy());\n\n\t\t\t// 专业知识库决策相关\n\t\t\tkeyStrategyHashMap.put(\"use_professional_kb\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"selected_knowledge_bases\", new ReplaceStrategy());\n\n\t\t\t// 节点输出\n\t\t\tkeyStrategyHashMap.put(\"background_investigation_results\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"site_information\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"output\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"plan_iterations\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"current_plan\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"observations\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"final_report\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"planner_content\", new ReplaceStrategy());\n\n\t\t\tfor (int i = 0; i < deepResearchProperties.getParallelNodeCount()\n\t\t\t\t.get(ParallelEnum.RESEARCHER.getValue()); i++) {\n\t\t\t\tkeyStrategyHashMap.put(ParallelEnum.RESEARCHER.getValue() + \"_content_\" + i, new ReplaceStrategy());\n\t\t\t}\n\t\t\tfor (int i = 0; i < deepResearchProperties.getParallelNodeCount().get(ParallelEnum.CODER.getValue()); i++) {\n\t\t\t\tkeyStrategyHashMap.put(ParallelEnum.CODER.getValue() + \"_content_\" + i, new ReplaceStrategy());\n\t\t\t}\n\n\t\t\treturn keyStrategyHashMap;\n\t\t};\n\n\t\tStateGraph stateGraph = new StateGraph(\"deep research\", keyStrategyFactory,\n\t\t\t\tnew DeepResearchStateSerializer(OverAllState::new))\n\t\t\t.addNode(\"coordinator\", node_async(new CoordinatorNode(coordinatorAgent, sessionContextService)))\n\t\t\t.addNode(\"rewrite_multi_query\",\n\t\t\t\t\tnode_async(new RewriteAndMultiQueryNode(rewriteAndMultiQueryChatClientBuilder)))\n\t\t\t.addNode(\"background_investigator\",\n\t\t\t\t\tnode_async(new BackgroundInvestigationNode(jinaCrawlerService, infoCheckService,\n\t\t\t\t\t\t\tsearchFilterService, questionClassifierService, searchPlatformSelectionService,\n\t\t\t\t\t\t\tsmartAgentProperties, backgroundAgent, sessionContextService, toolCallingSearchService)))\n\t\t\t.addNode(\"user_file_rag\", ragNodeService.createUserFileRagNode())\n\t\t\t.addNode(\"planner\", node_async((new PlannerNode(plannerAgent))))\n\t\t\t.addNode(\"professional_kb_decision\",\n\t\t\t\t\tnode_async(new ProfessionalKbDecisionNode(researchAgent, ragProperties)))\n\t\t\t.addNode(\"professional_kb_rag\", ragNodeService.createProfessionalKbRagNode())\n\t\t\t.addNode(\"information\", node_async((new InformationNode())))\n\t\t\t.addNode(\"human_feedback\", node_async(new HumanFeedbackNode()))\n\t\t\t.addNode(\"research_team\", node_async(new ResearchTeamNode()))\n\t\t\t.addNode(\"parallel_executor\", node_async(new ParallelExecutorNode(deepResearchProperties)))\n\t\t\t.addNode(\"reporter\", node_async(new ReporterNode(reporterAgent, reportService, sessionContextService)));\n\n\t\t// 添加并行节点块\n\t\tconfigureParallelNodes(stateGraph);\n\n\t\tstateGraph.addEdge(START, \"coordinator\")\n\t\t\t.addConditionalEdges(\"coordinator\", edge_async(new CoordinatorDispatcher()),\n\t\t\t\t\tMap.of(\"rewrite_multi_query\", \"rewrite_multi_query\", END, END))\n\t\t\t.addConditionalEdges(\"rewrite_multi_query\", edge_async(new RewriteAndMultiQueryDispatcher()),\n\t\t\t\t\tMap.of(\"background_investigator\", \"background_investigator\", \"user_file_rag\", \"user_file_rag\", END,\n\t\t\t\t\t\t\tEND))\n\t\t\t.addConditionalEdges(\"background_investigator\", edge_async(new BackgroundInvestigationDispatcher()),\n\t\t\t\t\tMap.of(\"reporter\", \"reporter\", \"planner\", \"planner\", END, END))\n\t\t\t.addConditionalEdges(\"user_file_rag\", edge_async(new UserFileRagDispatcher()),\n\t\t\t\t\tMap.of(\"background_investigator\", \"background_investigator\", END, END))\n\t\t\t.addEdge(\"planner\", \"information\")\n\t\t\t.addConditionalEdges(\"information\", edge_async(new InformationDispatcher()),\n\t\t\t\t\tMap.of(\"reporter\", \"reporter\", \"human_feedback\", \"human_feedback\", \"planner\", \"planner\",\n\t\t\t\t\t\t\t\"research_team\", \"research_team\", END, END))\n\t\t\t.addConditionalEdges(\"human_feedback\", edge_async(new HumanFeedbackDispatcher()),\n\t\t\t\t\tMap.of(\"planner\", \"planner\", \"research_team\", \"research_team\", END, END))\n\t\t\t.addConditionalEdges(\"research_team\", edge_async(new ResearchTeamDispatcher()),\n\t\t\t\t\tMap.of(\"professional_kb_decision\", \"professional_kb_decision\", \"parallel_executor\",\n\t\t\t\t\t\t\t\"parallel_executor\", END, END))\n\t\t\t.addConditionalEdges(\"professional_kb_decision\", edge_async(new ProfessionalKbDispatcher()),\n\t\t\t\t\tMap.of(\"professional_kb_rag\", \"professional_kb_rag\", \"reporter\", \"reporter\", END, END))\n\t\t\t.addEdge(\"professional_kb_rag\", \"reporter\")\n\t\t\t.addEdge(\"reporter\", END);\n\n\t\tGraphRepresentation graphRepresentation = stateGraph.getGraph(GraphRepresentation.Type.PLANTUML,\n\t\t\t\t\"workflow graph\");\n\n\t\tlogger.info(\"\\n\\n\");\n\t\tlogger.info(graphRepresentation.content());\n\t\tlogger.info(\"\\n\\n\");\n\n\t\treturn stateGraph;\n\t}\n\n\tprivate void configureParallelNodes(StateGraph stateGraph) throws GraphStateException {\n\t\taddResearcherNodes(stateGraph);\n\n\t\taddCoderNodes(stateGraph);\n\t}\n\n\tprivate void addResearcherNodes(StateGraph stateGraph) throws GraphStateException {\n\t\tReflectionProcessor reflectionProcessor = reflectionProcessor();\n\t\tfor (int i = 0; i < deepResearchProperties.getParallelNodeCount()\n\t\t\t.get(ParallelEnum.RESEARCHER.getValue()); i++) {\n\t\t\tString nodeId = \"researcher_\" + i;\n\t\t\tstateGraph.addNode(nodeId,\n\t\t\t\t\tnode_async(new ResearcherNode(researchAgent, String.valueOf(i), reflectionProcessor,\n\t\t\t\t\t\t\tmcpProviderFactory, searchFilterService, smartAgentDispatcher, smartAgentProperties,\n\t\t\t\t\t\t\tjinaCrawlerService)));\n\t\t\tstateGraph.addEdge(\"parallel_executor\", nodeId).addEdge(nodeId, \"research_team\");\n\t\t}\n\t}\n\n\tprivate void addCoderNodes(StateGraph stateGraph) throws GraphStateException {\n\t\tReflectionProcessor reflectionProcessor = reflectionProcessor();\n\t\tfor (int i = 0; i < deepResearchProperties.getParallelNodeCount().get(ParallelEnum.CODER.getValue()); i++) {\n\t\t\tString nodeId = \"coder_\" + i;\n\t\t\tstateGraph.addNode(nodeId,\n\t\t\t\t\tnode_async(new CoderNode(coderAgent, String.valueOf(i), reflectionProcessor, mcpProviderFactory)));\n\t\t\tstateGraph.addEdge(\"parallel_executor\", nodeId).addEdge(nodeId, \"research_team\");\n\t\t}\n\t}\n\n}", "output": "/*\n * Copyright 2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage com.alibaba.cloud.ai.example.deepresearch.config;\n\nimport com.alibaba.cloud.ai.example.deepresearch.config.rag.RagProperties;\nimport com.alibaba.cloud.ai.example.deepresearch.dispatcher.BackgroundInvestigationDispatcher;\nimport com.alibaba.cloud.ai.example.deepresearch.dispatcher.CoordinatorDispatcher;\nimport com.alibaba.cloud.ai.example.deepresearch.dispatcher.HumanFeedbackDispatcher;\nimport com.alibaba.cloud.ai.example.deepresearch.dispatcher.InformationDispatcher;\nimport com.alibaba.cloud.ai.example.deepresearch.dispatcher.ProfessionalKbDispatcher;\nimport com.alibaba.cloud.ai.example.deepresearch.dispatcher.ResearchTeamDispatcher;\nimport com.alibaba.cloud.ai.example.deepresearch.dispatcher.RewriteAndMultiQueryDispatcher;\nimport com.alibaba.cloud.ai.example.deepresearch.model.enums.ParallelEnum;\n\nimport com.alibaba.cloud.ai.example.deepresearch.node.BackgroundInvestigationNode;\nimport com.alibaba.cloud.ai.example.deepresearch.node.CoderNode;\nimport com.alibaba.cloud.ai.example.deepresearch.node.CoordinatorNode;\nimport com.alibaba.cloud.ai.example.deepresearch.node.HumanFeedbackNode;\nimport com.alibaba.cloud.ai.example.deepresearch.node.InformationNode;\nimport com.alibaba.cloud.ai.example.deepresearch.node.ParallelExecutorNode;\nimport com.alibaba.cloud.ai.example.deepresearch.node.PlannerNode;\nimport com.alibaba.cloud.ai.example.deepresearch.node.ProfessionalKbDecisionNode;\nimport com.alibaba.cloud.ai.example.deepresearch.node.ReporterNode;\nimport com.alibaba.cloud.ai.example.deepresearch.node.ResearchTeamNode;\nimport com.alibaba.cloud.ai.example.deepresearch.node.ResearcherNode;\nimport com.alibaba.cloud.ai.example.deepresearch.node.RewriteAndMultiQueryNode;\nimport com.alibaba.cloud.ai.example.deepresearch.service.RagNodeService;\nimport com.alibaba.cloud.ai.example.deepresearch.service.SessionContextService;\nimport com.alibaba.cloud.ai.example.deepresearch.service.multiagent.QuestionClassifierService;\nimport com.alibaba.cloud.ai.example.deepresearch.service.ReportService;\nimport com.alibaba.cloud.ai.example.deepresearch.service.multiagent.SearchPlatformSelectionService;\nimport com.alibaba.cloud.ai.example.deepresearch.service.multiagent.SmartAgentDispatcherService;\n\nimport com.alibaba.cloud.ai.example.deepresearch.serializer.DeepResearchStateSerializer;\nimport com.alibaba.cloud.ai.example.deepresearch.service.InfoCheckService;\nimport com.alibaba.cloud.ai.example.deepresearch.service.SearchFilterService;\nimport com.alibaba.cloud.ai.example.deepresearch.service.multiagent.ToolCallingSearchService;\nimport com.alibaba.cloud.ai.example.deepresearch.util.ReflectionProcessor;\nimport com.alibaba.cloud.ai.graph.GraphRepresentation;\nimport com.alibaba.cloud.ai.graph.KeyStrategy;\nimport com.alibaba.cloud.ai.graph.KeyStrategyFactory;\nimport com.alibaba.cloud.ai.graph.OverAllState;\nimport com.alibaba.cloud.ai.graph.StateGraph;\nimport com.alibaba.cloud.ai.graph.exception.GraphStateException;\nimport com.alibaba.cloud.ai.graph.state.strategy.ReplaceStrategy;\nimport com.alibaba.cloud.ai.toolcalling.jinacrawler.JinaCrawlerService;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.ai.chat.client.ChatClient;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.boot.context.properties.EnableConfigurationProperties;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\n\nimport java.util.HashMap;\nimport java.util.Map;\n\nimport static com.alibaba.cloud.ai.graph.StateGraph.END;\nimport static com.alibaba.cloud.ai.graph.StateGraph.START;\nimport static com.alibaba.cloud.ai.graph.action.AsyncEdgeAction.edge_async;\nimport static com.alibaba.cloud.ai.graph.action.AsyncNodeAction.node_async;\n\nimport com.alibaba.cloud.ai.example.deepresearch.service.McpProviderFactory;\n\n/**\n * @author yingzi\n * @since 2025/5/17 17:10\n */\n@Configuration\n@EnableConfigurationProperties({ DeepResearchProperties.class, PythonCoderProperties.class,\n\t\tMcpAssignNodeProperties.class, RagProperties.class, ReflectionProperties.class, SmartAgentProperties.class })\npublic class DeepResearchConfiguration {\n\n\tprivate static final Logger logger = LoggerFactory.getLogger(DeepResearchConfiguration.class);\n\n\t@Autowired\n\tprivate ChatClient coderAgent;\n\n\t@Autowired\n\tprivate ChatClient researchAgent;\n\n\t@Autowired\n\tprivate ChatClient reporterAgent;\n\n\t@Autowired\n\tprivate ChatClient backgroundAgent;\n\n\t@Autowired\n\tprivate ChatClient coordinatorAgent;\n\n\t@Autowired\n\tprivate ChatClient plannerAgent;\n\n\t@Autowired\n\tprivate ChatClient reflectionAgent;\n\n\t@Autowired\n\tprivate ChatClient.Builder rewriteAndMultiQueryChatClientBuilder;\n\n\t@Autowired\n\tprivate DeepResearchProperties deepResearchProperties;\n\n\t@Autowired\n\tprivate ReflectionProperties reflectionProperties;\n\n\t@Autowired(required = false)\n\tprivate JinaCrawlerService jinaCrawlerService;\n\n\t@Autowired\n\tprivate RagProperties ragProperties;\n\n\t@Autowired\n\tprivate ReportService reportService;\n\n\t@Autowired\n\tprivate SessionContextService sessionContextService;\n\n\t@Autowired(required = false)\n\tprivate McpProviderFactory mcpProviderFactory;\n\n\t@Autowired\n\tprivate InfoCheckService infoCheckService;\n\n\t@Autowired\n\tprivate SearchFilterService searchFilterService;\n\n\t// 可选的工具调用服务（智能平台用）\n\t@Autowired(required = false)\n\tprivate ToolCallingSearchService toolCallingSearchService;\n\n\t@Autowired(required = false)\n\tprivate QuestionClassifierService questionClassifierService;\n\n\t@Autowired(required = false)\n\tprivate SearchPlatformSelectionService searchPlatformSelectionService;\n\n\t@Autowired(required = false)\n\tprivate SmartAgentDispatcherService smartAgentDispatcher;\n\n\t@Autowired\n\tprivate SmartAgentProperties smartAgentProperties;\n\n\t@Autowired\n\tprivate RagNodeService ragNodeService;\n\n\t@Bean\n\tpublic ReflectionProcessor reflectionProcessor() {\n\t\tif (!reflectionProperties.isEnabled()) {\n\t\t\treturn null; // Return null if reflection mechanism is not enabled\n\t\t}\n\t\t// Use dedicated reflection agent\n\t\treturn new ReflectionProcessor(reflectionAgent, reflectionProperties.getMaxAttempts());\n\t}\n\n\t@Bean\n\tpublic StateGraph deepResearch(ChatClient researchAgent) throws GraphStateException {\n\n\t\tKeyStrategyFactory keyStrategyFactory = () -> {\n\t\t\tHashMap<String, KeyStrategy> keyStrategyHashMap = new HashMap<>();\n\t\t\t// 条件边控制：跳转下一个节点\n\t\t\tkeyStrategyHashMap.put(\"coordinator_next_node\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"rewrite_multi_query_next_node\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"background_investigation_next_node\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"planner_next_node\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"information_next_node\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"human_next_node\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"research_team_next_node\", new ReplaceStrategy());\n\t\t\t// 用户输入\n\t\t\tkeyStrategyHashMap.put(\"query\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"optimize_queries\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"thread_id\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"enable_deepresearch\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"auto_accepted_plan\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"plan_max_iterations\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"max_step_num\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"mcp_settings\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"optimize_query_num\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"user_upload_file\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"session_id\", new ReplaceStrategy());\n\n\t\t\tkeyStrategyHashMap.put(\"feed_back\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"feed_back_content\", new ReplaceStrategy());\n\n\t\t\t// 专业知识库决策相关\n\t\t\tkeyStrategyHashMap.put(\"use_professional_kb\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"selected_knowledge_bases\", new ReplaceStrategy());\n\n\t\t\t// 节点输出\n\t\t\tkeyStrategyHashMap.put(\"background_investigation_results\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"site_information\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"output\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"plan_iterations\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"current_plan\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"observations\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"final_report\", new ReplaceStrategy());\n\t\t\tkeyStrategyHashMap.put(\"planner_content\", new ReplaceStrategy());\n\n\t\t\tfor (int i = 0; i < deepResearchProperties.getParallelNodeCount()\n\t\t\t\t.get(ParallelEnum.RESEARCHER.getValue()); i++) {\n\t\t\t\tkeyStrategyHashMap.put(ParallelEnum.RESEARCHER.getValue() + \"_content_\" + i, new ReplaceStrategy());\n\t\t\t}\n\t\t\tfor (int i = 0; i < deepResearchProperties.getParallelNodeCount().get(ParallelEnum.CODER.getValue()); i++) {\n\t\t\t\tkeyStrategyHashMap.put(ParallelEnum.CODER.getValue() + \"_content_\" + i, new ReplaceStrategy());\n\t\t\t}\n\n\t\t\treturn keyStrategyHashMap;\n\t\t};\n\n\t\tStateGraph stateGraph = new StateGraph(\"deep research\", keyStrategyFactory,\n\t\t\t\tnew DeepResearchStateSerializer(OverAllState::new))\n\t\t\t.addNode(\"coordinator\", node_async(new CoordinatorNode(coordinatorAgent, sessionContextService)))\n\t\t\t.addNode(\"rewrite_multi_query\",\n\t\t\t\t\tnode_async(new RewriteAndMultiQueryNode(rewriteAndMultiQueryChatClientBuilder)))\n\t\t\t.addNode(\"background_investigator\",\n\t\t\t\t\tnode_async(new BackgroundInvestigationNode(jinaCrawlerService, infoCheckService,\n\t\t\t\t\t\t\tsearchFilterService, questionClassifierService, searchPlatformSelectionService,\n\t\t\t\t\t\t\tsmartAgentProperties, backgroundAgent, sessionContextService, toolCallingSearchService)))\n\t\t\t.addNode(\"user_file_rag\", ragNodeService.createUserFileRagNode())\n\t\t\t.addNode(\"planner\", node_async((new PlannerNode(plannerAgent))))\n\t\t\t.addNode(\"professional_kb_decision\",\n\t\t\t\t\tnode_async(new ProfessionalKbDecisionNode(researchAgent, ragProperties)))\n\t\t\t.addNode(\"professional_kb_rag\", ragNodeService.createProfessionalKbRagNode())\n\t\t\t.addNode(\"information\", node_async((new InformationNode())))\n\t\t\t.addNode(\"human_feedback\", node_async(new HumanFeedbackNode()))\n\t\t\t.addNode(\"research_team\", node_async(new ResearchTeamNode()))\n\t\t\t.addNode(\"parallel_executor\", node_async(new ParallelExecutorNode(deepResearchProperties)))\n\t\t\t.addNode(\"reporter\", node_async(new ReporterNode(reporterAgent, reportService, sessionContextService)));\n\n\t\t// 添加并行节点块\n\t\tconfigureParallelNodes(stateGraph);\n\n\t\tstateGraph.addEdge(START, \"coordinator\")\n\t\t\t.addConditionalEdges(\"coordinator\", edge_async(new CoordinatorDispatcher()),\n\t\t\t\t\tMap.of(\"rewrite_multi_query\", \"rewrite_multi_query\", END, END))\n\t\t\t.addConditionalEdges(\"rewrite_multi_query\", edge_async(new RewriteAndMultiQueryDispatcher()),\n\t\t\t\t\tMap.of(\"background_investigator\", \"background_investigator\", \"user_file_rag\", \"user_file_rag\", END,\n\t\t\t\t\t\t\tEND))\n\t\t\t.addConditionalEdges(\"background_investigator\", edge_async(new BackgroundInvestigationDispatcher()),\n\t\t\t\t\tMap.of(\"reporter\", \"reporter\", \"planner\", \"planner\", END, END))\n\t\t\t.addEdge(\"user_file_rag\", \"background_investigator\")\n\t\t\t.addEdge(\"planner\", \"information\")\n\t\t\t.addConditionalEdges(\"information\", edge_async(new InformationDispatcher()),\n\t\t\t\t\tMap.of(\"reporter\", \"reporter\", \"human_feedback\", \"human_feedback\", \"planner\", \"planner\",\n\t\t\t\t\t\t\t\"research_team\", \"research_team\", END, END))\n\t\t\t.addConditionalEdges(\"human_feedback\", edge_async(new HumanFeedbackDispatcher()),\n\t\t\t\t\tMap.of(\"planner\", \"planner\", \"research_team\", \"research_team\", END, END))\n\t\t\t.addConditionalEdges(\"research_team\", edge_async(new ResearchTeamDispatcher()),\n\t\t\t\t\tMap.of(\"professional_kb_decision\", \"professional_kb_decision\", \"parallel_executor\",\n\t\t\t\t\t\t\t\"parallel_executor\", END, END))\n\t\t\t.addConditionalEdges(\"professional_kb_decision\", edge_async(new ProfessionalKbDispatcher()),\n\t\t\t\t\tMap.of(\"professional_kb_rag\", \"professional_kb_rag\", \"reporter\", \"reporter\", END, END))\n\t\t\t.addEdge(\"professional_kb_rag\", \"reporter\")\n\t\t\t.addEdge(\"reporter\", END);\n\n\t\tGraphRepresentation graphRepresentation = stateGraph.getGraph(GraphRepresentation.Type.PLANTUML,\n\t\t\t\t\"workflow graph\");\n\n\t\tlogger.info(\"\\n\\n\");\n\t\tlogger.info(graphRepresentation.content());\n\t\tlogger.info(\"\\n\\n\");\n\n\t\treturn stateGraph;\n\t}\n\n\tprivate void configureParallelNodes(StateGraph stateGraph) throws GraphStateException {\n\t\taddResearcherNodes(stateGraph);\n\n\t\taddCoderNodes(stateGraph);\n\t}\n\n\tprivate void addResearcherNodes(StateGraph stateGraph) throws GraphStateException {\n\t\tReflectionProcessor reflectionProcessor = reflectionProcessor();\n\t\tfor (int i = 0; i < deepResearchProperties.getParallelNodeCount()\n\t\t\t.get(ParallelEnum.RESEARCHER.getValue()); i++) {\n\t\t\tString nodeId = \"researcher_\" + i;\n\t\t\tstateGraph.addNode(nodeId,\n\t\t\t\t\tnode_async(new ResearcherNode(researchAgent, String.valueOf(i), reflectionProcessor,\n\t\t\t\t\t\t\tmcpProviderFactory, searchFilterService, smartAgentDispatcher, smartAgentProperties,\n\t\t\t\t\t\t\tjinaCrawlerService)));\n\t\t\tstateGraph.addEdge(\"parallel_executor\", nodeId).addEdge(nodeId, \"research_team\");\n\t\t}\n\t}\n\n\tprivate void addCoderNodes(StateGraph stateGraph) throws GraphStateException {\n\t\tReflectionProcessor reflectionProcessor = reflectionProcessor();\n\t\tfor (int i = 0; i < deepResearchProperties.getParallelNodeCount().get(ParallelEnum.CODER.getValue()); i++) {\n\t\t\tString nodeId = \"coder_\" + i;\n\t\t\tstateGraph.addNode(nodeId,\n\t\t\t\t\tnode_async(new CoderNode(coderAgent, String.valueOf(i), reflectionProcessor, mcpProviderFactory)));\n\t\t\tstateGraph.addEdge(\"parallel_executor\", nodeId).addEdge(nodeId, \"research_team\");\n\t\t}\n\t}\n\n}", "metadata": {"commit_sha": "fd108221", "lines_added": 1, "lines_deleted": 3, "total_changes": 4, "chunks": 2}}
{"id": 55, "pattern_type": "refactoring", "file_path": "community/openmanus/src/main/java/com/alibaba/cloud/ai/example/manus/config/ManusChromeDriverInit.java", "file_extension": "java", "input": "/*\n * Copyright 2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage com.alibaba.cloud.ai.example.manus.config;\n\nimport java.net.URISyntaxException;\nimport java.net.URL;\nimport java.nio.file.Paths;\n\nimport com.alibaba.cloud.ai.example.manus.OpenManusSpringBootApplication;\n\nimport org.springframework.boot.ApplicationArguments;\nimport org.springframework.boot.ApplicationRunner;\nimport org.springframework.stereotype.Component;\n\n/**\n * @author yuluo\n * @author <a href=\"mailto:yuluo08290126@gmail.com\">yuluo</a>\n */\n\n@Component\npublic class ManusChromeDriverInit implements ApplicationRunner {\n\n\t@Override\n\tpublic void run(ApplicationArguments args) throws Exception {\n\n\t\tString chromedriverPath;\n\n\t\tif (checkOS()) {\n\t\t\tchromedriverPath = getChromedriverPath(\"data/chromedriver.exe\");\n\t\t} else {\n\t\t\tchromedriverPath = getChromedriverPath(\"data/chromedriver\");\n\t\t}\n\n\t\tsetChromeDriver(chromedriverPath);\n\t}\n\n\tprivate String getChromedriverPath(String resourcePath) throws URISyntaxException {\n\n\t\tURL resource = OpenManusSpringBootApplication.class.getClassLoader().getResource(resourcePath);\n\t\tif (resource == null) {\n\t\t\tthrow new IllegalStateException(\"Chromedriver not found: \" + resourcePath);\n\t\t}\n\n\t\treturn Paths.get(resource.toURI()).toFile().getAbsolutePath();\n\t}\n\n\tprivate static Boolean checkOS() {\n\n\t\tString os = System.getProperty(\"os.name\").toLowerCase();\n\n\t\tif (os.contains(\"win\")) {\n\t\t\treturn true;\n\t\t} else if (os.contains(\"mac\")) {\n\t\t\treturn false;\n\t\t} else if (os.contains(\"nix\") || os.contains(\"nux\") || os.contains(\"aix\")) {\n\t\t\tSystem.out.println(\"Operating System: Unix/Linux\");\n\t\t\treturn false;\n\t\t} else {\n\t\t\tSystem.out.println(\"Operating System: Unknown\");\n\t\t\treturn false;\n\t\t}\n\t}\n\n\tprivate static void setChromeDriver(String path) {\n\n\t\tSystem.setProperty(\"webdriver.chrome.driver\", path);\n\t}\n\n}", "output": "/*\n * Copyright 2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage com.alibaba.cloud.ai.example.manus.config;\n\nimport java.net.URISyntaxException;\nimport java.net.URL;\nimport java.nio.file.Paths;\n\nimport com.alibaba.cloud.ai.example.manus.OpenManusSpringBootApplication;\n\nimport org.springframework.boot.ApplicationArguments;\nimport org.springframework.boot.ApplicationRunner;\nimport org.springframework.stereotype.Component;\n\n/**\n * @author yuluo\n * @author <a href=\"mailto:yuluo08290126@gmail.com\">yuluo</a>\n */\n\n@Component\npublic class ManusChromeDriverInit implements ApplicationRunner {\n\n\t@Override\n\tpublic void run(ApplicationArguments args) throws Exception {\n\n\t\tString chromedriverPath;\n\n\t\tif (checkOS()) {\n\t\t\tchromedriverPath = getChromedriverPath(\"data/chromedriver.exe\");\n\t\t}\n\t\telse {\n\t\t\tchromedriverPath = getChromedriverPath(\"data/chromedriver\");\n\t\t}\n\n\t\tsetChromeDriver(chromedriverPath);\n\t}\n\n\tprivate String getChromedriverPath(String resourcePath) throws URISyntaxException {\n\n\t\tURL resource = OpenManusSpringBootApplication.class.getClassLoader().getResource(resourcePath);\n\t\tif (resource == null) {\n\t\t\tthrow new IllegalStateException(\"Chromedriver not found: \" + resourcePath);\n\t\t}\n\n\t\treturn Paths.get(resource.toURI()).toFile().getAbsolutePath();\n\t}\n\n\tprivate static Boolean checkOS() {\n\n\t\tString os = System.getProperty(\"os.name\").toLowerCase();\n\n\t\tif (os.contains(\"win\")) {\n\t\t\treturn true;\n\t\t}\n\t\telse if (os.contains(\"mac\")) {\n\t\t\treturn false;\n\t\t}\n\t\telse if (os.contains(\"nix\") || os.contains(\"nux\") || os.contains(\"aix\")) {\n\t\t\tSystem.out.println(\"Operating System: Unix/Linux\");\n\t\t\treturn false;\n\t\t}\n\t\telse {\n\t\t\tSystem.out.println(\"Operating System: Unknown\");\n\t\t\treturn false;\n\t\t}\n\t}\n\n\tprivate static void setChromeDriver(String path) {\n\n\t\tSystem.setProperty(\"webdriver.chrome.driver\", path);\n\t}\n\n}", "metadata": {"commit_sha": "694831b0", "lines_added": 8, "lines_deleted": 4, "total_changes": 12, "chunks": 2}}
{"id": 32, "pattern_type": "import_statement", "file_path": "spring-ai-alibaba-studio/ui/src/pages/run/models/Setup/Prompt/index.tsx", "file_extension": "tsx", "input": "/**\n * Copyright 2024 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { useState } from 'react';\nimport { Form, Input, Flex } from 'antd';\nimport { ChatOptions } from '@/types/options';\n\ntype Props = {\n  onchangePrompt: (prompt: string) => void;\n};\nconst { TextArea } = Input;\n\nexport default function ConfigAndPrompt(props: Props) {\n  const { onchangePrompt } = props;\n\n  const [form] = Form.useForm();\n\n  const [prompt, setPrompt] = useState('');\n\n\n  const sliderLabel = (left, right) => {\n    return (\n      <Flex justify=\"space-between\" style={{ width: 300 }}>\n        <span>{left}</span>\n        <span>{right}</span>\n      </Flex>\n    );\n  };\n\n  return (\n    <>\n      <Form layout=\"vertical\" form={form}>\n        <Form.Item\n          label={sliderLabel('Prompt', prompt)}\n        >\n          <TextArea rows={3} onChange={(e) => { onchangePrompt(e.target.value); setPrompt(e.target.value); }} />\n        </Form.Item>\n      </Form>\n    </>\n  );\n}", "output": "/**\n * Copyright 2024 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport { useState } from 'react';\nimport { Form, Input, Flex, Typography } from 'antd';\nimport { ChatOptions } from '@/types/options';\n\nconst { Paragraph } = Typography;\ntype Props = {\n  onchangePrompt: (prompt: string) => void;\n};\nconst { TextArea } = Input;\n\nexport default function ConfigAndPrompt(props: Props) {\n  const { onchangePrompt } = props;\n\n  const [form] = Form.useForm();\n\n  const [prompt, setPrompt] = useState('');\n\n\n  const sliderLabel = (left, right) => {\n    return (\n      <Flex justify=\"space-between\" style={{ width: 300 }}>\n        <span>{left}</span>\n        <span>{right}</span>\n      </Flex>\n    );\n  };\n\n  const handlePromptChange = (e: React.ChangeEvent<HTMLTextAreaElement>) => {\n    const newPrompt = e.target.value;\n    onchangePrompt(newPrompt);\n    setPrompt(newPrompt);\n  };\n\n  return (\n    <>\n      <Form layout=\"vertical\" form={form}>\n        <Form.Item\n          // label={sliderLabel('Prompt', prompt)}\n        >\n          <Paragraph copyable={{ text: prompt }}>\n            <TextArea rows={3} value={prompt} onChange={handlePromptChange} />\n          </Paragraph>\n        </Form.Item>\n      </Form>\n    </>\n  );\n}", "metadata": {"commit_sha": "abfeaaa0", "lines_added": 12, "lines_deleted": 3, "total_changes": 15, "chunks": 2}}
{"id": 141, "pattern_type": "getter_setter", "file_path": "spring-ai-alibaba-mcp/spring-ai-alibaba-mcp-nacos2/src/main/java/com/alibaba/cloud/ai/mcp/nacos2/NacosMcpProperties.java", "file_extension": "java", "input": "/*\n * Copyright 2024-2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.alibaba.cloud.ai.mcp.nacos2;\n\nimport com.alibaba.nacos.api.PropertyKeyConst;\nimport com.alibaba.nacos.api.utils.NetUtils;\nimport com.alibaba.nacos.api.utils.StringUtils;\nimport com.fasterxml.jackson.annotation.JsonIgnore;\nimport jakarta.annotation.PostConstruct;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.boot.context.properties.ConfigurationProperties;\nimport org.springframework.core.env.ConfigurableEnvironment;\nimport org.springframework.core.env.EnumerablePropertySource;\nimport org.springframework.core.env.Environment;\nimport org.springframework.core.env.PropertyResolver;\nimport org.springframework.core.env.PropertySource;\nimport org.springframework.core.env.PropertySources;\n\nimport java.util.Collections;\nimport java.util.LinkedHashMap;\nimport java.util.Map;\nimport java.util.Objects;\nimport java.util.Properties;\nimport java.util.regex.Matcher;\nimport java.util.regex.Pattern;\n\n/**\n * @author Sunrisea\n */\n@ConfigurationProperties(prefix = NacosMcpProperties.CONFIG_PREFIX)\npublic class NacosMcpProperties {\n\n\tpublic static final String CONFIG_PREFIX = \"spring.ai.alibaba.mcp.nacos\";\n\n\tpublic static final String DEFAULT_NAMESPACE = \"public\";\n\n\tpublic static final String DEFAULT_ADDRESS = \"127.0.0.1:8848\";\n\n\tprivate static final Pattern PATTERN = Pattern.compile(\"-(\\\\w)\");\n\n\tprivate static final Logger log = LoggerFactory.getLogger(NacosMcpProperties.class);\n\n\tString namespace;\n\n\tString serverAddr;\n\n\tString username;\n\n\tString password;\n\n\tString accessKey;\n\n\tString secretKey;\n\n\tString endpoint;\n\n\tString ip;\n\n\t@Autowired\n\t@JsonIgnore\n\tprivate Environment environment;\n\n\tpublic String getNamespace() {\n\t\treturn namespace;\n\t}\n\n\tvoid setNamespace(String namespace) {\n\t\tthis.namespace = namespace;\n\t}\n\n\tpublic String getUsername() {\n\t\treturn username;\n\t}\n\n\tpublic void setUsername(String username) {\n\t\tthis.username = username;\n\t}\n\n\tpublic String getPassword() {\n\t\treturn password;\n\t}\n\n\tpublic void setPassword(String password) {\n\t\tthis.password = password;\n\t}\n\n\tpublic String getAccessKey() {\n\t\treturn accessKey;\n\t}\n\n\tpublic void setAccessKey(String accessKey) {\n\t\tthis.accessKey = accessKey;\n\t}\n\n\tpublic String getSecretKey() {\n\t\treturn secretKey;\n\t}\n\n\tpublic void setSecretKey(String secretKey) {\n\t\tthis.secretKey = secretKey;\n\t}\n\n\tpublic String getIp() {\n\t\treturn ip;\n\t}\n\n\tpublic void setIp(String ip) {\n\t\tthis.ip = ip;\n\t}\n\n\tpublic String getEndpoint() {\n\t\treturn endpoint;\n\t}\n\n\tpublic void setEndpoint(String endpoint) {\n\t\tthis.endpoint = endpoint;\n\t}\n\n\tpublic String getServerAddr() {\n\t\treturn serverAddr;\n\t}\n\n\tvoid setServerAddr(String serverAddr) {\n\t\tthis.serverAddr = serverAddr;\n\t}\n\n\t@PostConstruct\n\tpublic void init() throws Exception {\n\t\tif (StringUtils.isEmpty(this.ip)) {\n\t\t\tthis.ip = NetUtils.localIP();\n\t\t}\n\t}\n\n\tpublic Properties getNacosProperties() {\n\t\tProperties properties = new Properties();\n\t\tproperties.put(PropertyKeyConst.NAMESPACE, Objects.toString(this.namespace, \"\"));\n\t\tproperties.put(PropertyKeyConst.SERVER_ADDR, Objects.toString(this.serverAddr, \"\"));\n\t\tproperties.put(PropertyKeyConst.USERNAME, Objects.toString(this.username, \"\"));\n\t\tproperties.put(PropertyKeyConst.PASSWORD, Objects.toString(this.password, \"\"));\n\t\tproperties.put(PropertyKeyConst.ACCESS_KEY, Objects.toString(this.accessKey, \"\"));\n\t\tproperties.put(PropertyKeyConst.SECRET_KEY, Objects.toString(this.secretKey, \"\"));\n\t\tString endpoint = Objects.toString(this.endpoint, \"\");\n\t\tif (endpoint.contains(\":\")) {\n\t\t\tint index = endpoint.indexOf(\":\");\n\t\t\tproperties.put(PropertyKeyConst.ENDPOINT, endpoint.substring(0, index));\n\t\t\tproperties.put(PropertyKeyConst.ENDPOINT_PORT, endpoint.substring(index + 1));\n\t\t}\n\t\telse {\n\t\t\tproperties.put(PropertyKeyConst.ENDPOINT, endpoint);\n\t\t}\n\n\t\tenrichNacosConfigProperties(properties);\n\n\t\tif (StringUtils.isEmpty(this.serverAddr) && StringUtils.isEmpty(this.endpoint)) {\n\t\t\tproperties.put(PropertyKeyConst.SERVER_ADDR, DEFAULT_ADDRESS);\n\t\t}\n\n\t\treturn properties;\n\t}\n\n\tprotected void enrichNacosConfigProperties(Properties nacosConfigProperties) {\n\t\tif (environment == null) {\n\t\t\treturn;\n\t\t}\n\t\tString prefix = \"spring.ai.alibaba.mcp.nacos\";\n\n\t\tConfigurableEnvironment env = (ConfigurableEnvironment) environment;\n\t\tMap<String, Object> properties = getSubProperties(env.getPropertySources(), env, prefix);\n\t\tproperties.forEach((k, v) -> nacosConfigProperties.putIfAbsent(resolveKey(k), String.valueOf(v)));\n\t}\n\n\tprotected String resolveKey(String key) {\n\t\tMatcher matcher = PATTERN.matcher(key);\n\t\tStringBuilder sb = new StringBuilder();\n\t\twhile (matcher.find()) {\n\t\t\tmatcher.appendReplacement(sb, matcher.group(1).toUpperCase());\n\t\t}\n\t\tmatcher.appendTail(sb);\n\t\treturn sb.toString();\n\t}\n\n\tprivate Map<String, Object> getSubProperties(PropertySources propertySources, PropertyResolver propertyResolver,\n\t\t\tString prefix) {\n\n\t\tMap<String, Object> subProperties = new LinkedHashMap<String, Object>();\n\n\t\tfor (PropertySource<?> source : propertySources) {\n\t\t\tfor (String name : getPropertyNames(source)) {\n\t\t\t\tif (!subProperties.containsKey(name) && name.startsWith(prefix)) {\n\t\t\t\t\tString subName = name.substring(prefix.length());\n\t\t\t\t\tif (!subProperties.containsKey(subName)) { // take first one\n\t\t\t\t\t\tObject value = source.getProperty(name);\n\t\t\t\t\t\tif (value instanceof String) {\n\t\t\t\t\t\t\tvalue = propertyResolver.resolvePlaceholders((String) value);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tsubProperties.put(subName, value);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn Collections.unmodifiableMap(subProperties);\n\t}\n\n\tprivate String[] getPropertyNames(PropertySource propertySource) {\n\n\t\tString[] propertyNames = propertySource instanceof EnumerablePropertySource\n\t\t\t\t? ((EnumerablePropertySource<?>) propertySource).getPropertyNames() : null;\n\n\t\tif (propertyNames == null) {\n\t\t\treturn new String[0];\n\t\t}\n\t\treturn propertyNames;\n\t}\n\n}", "output": "/*\n * Copyright 2024-2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.alibaba.cloud.ai.mcp.nacos2;\n\nimport com.alibaba.nacos.api.PropertyKeyConst;\nimport com.alibaba.nacos.api.utils.NetUtils;\nimport com.alibaba.nacos.api.utils.StringUtils;\nimport com.fasterxml.jackson.annotation.JsonIgnore;\nimport jakarta.annotation.PostConstruct;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.boot.context.properties.ConfigurationProperties;\nimport org.springframework.core.env.ConfigurableEnvironment;\nimport org.springframework.core.env.EnumerablePropertySource;\nimport org.springframework.core.env.Environment;\nimport org.springframework.core.env.PropertyResolver;\nimport org.springframework.core.env.PropertySource;\nimport org.springframework.core.env.PropertySources;\n\nimport java.util.Collections;\nimport java.util.LinkedHashMap;\nimport java.util.Map;\nimport java.util.Objects;\nimport java.util.Properties;\nimport java.util.regex.Matcher;\nimport java.util.regex.Pattern;\n\n/**\n * @author Sunrisea\n */\n@ConfigurationProperties(prefix = NacosMcpProperties.CONFIG_PREFIX)\npublic class NacosMcpProperties {\n\n\tpublic static final String CONFIG_PREFIX = \"spring.ai.alibaba.mcp.nacos\";\n\n\tpublic static final String DEFAULT_NAMESPACE = \"public\";\n\n\tpublic static final String DEFAULT_ADDRESS = \"127.0.0.1:8848\";\n\n\tprivate static final Pattern PATTERN = Pattern.compile(\"-(\\\\w)\");\n\n\tprivate static final Logger log = LoggerFactory.getLogger(NacosMcpProperties.class);\n\n\tString namespace;\n\n\tString serverAddr;\n\n\tString username;\n\n\tString password;\n\n\tString accessKey;\n\n\tString secretKey;\n\n\tString endpoint;\n\n\tString ip;\n\n\t@Autowired\n\t@JsonIgnore\n\tprivate Environment environment;\n\n\tpublic String getNamespace() {\n\t\treturn namespace;\n\t}\n\n\tvoid setNamespace(String namespace) {\n\t\tthis.namespace = namespace;\n\t}\n\n\tpublic String getUsername() {\n\t\treturn username;\n\t}\n\n\tpublic void setUsername(String username) {\n\t\tthis.username = username;\n\t}\n\n\tpublic String getPassword() {\n\t\treturn password;\n\t}\n\n\tpublic void setPassword(String password) {\n\t\tthis.password = password;\n\t}\n\n\tpublic String getAccessKey() {\n\t\treturn accessKey;\n\t}\n\n\tpublic void setAccessKey(String accessKey) {\n\t\tthis.accessKey = accessKey;\n\t}\n\n\tpublic String getSecretKey() {\n\t\treturn secretKey;\n\t}\n\n\tpublic void setSecretKey(String secretKey) {\n\t\tthis.secretKey = secretKey;\n\t}\n\n\tpublic String getIp() {\n\t\treturn ip;\n\t}\n\n\tpublic void setIp(String ip) {\n\t\tthis.ip = ip;\n\t}\n\n\tpublic String getEndpoint() {\n\t\treturn endpoint;\n\t}\n\n\tpublic void setEndpoint(String endpoint) {\n\t\tthis.endpoint = endpoint;\n\t}\n\n\tpublic String getServerAddr() {\n\t\treturn serverAddr;\n\t}\n\n\tvoid setServerAddr(String serverAddr) {\n\t\tthis.serverAddr = serverAddr;\n\t}\n\n\t@PostConstruct\n\tpublic void init() throws Exception {\n\t\tif (StringUtils.isEmpty(this.ip)) {\n\t\t\tthis.ip = NetUtils.localIP();\n\t\t}\n\t}\n\n\tpublic Properties getNacosProperties() {\n\t\tProperties properties = new Properties();\n\t\tproperties.put(PropertyKeyConst.NAMESPACE, Objects.toString(this.namespace, \"\"));\n\t\tproperties.put(PropertyKeyConst.SERVER_ADDR, Objects.toString(this.serverAddr, \"\"));\n\t\tproperties.put(PropertyKeyConst.USERNAME, Objects.toString(this.username, \"\"));\n\t\tproperties.put(PropertyKeyConst.PASSWORD, Objects.toString(this.password, \"\"));\n\t\tproperties.put(PropertyKeyConst.ACCESS_KEY, Objects.toString(this.accessKey, \"\"));\n\t\tproperties.put(PropertyKeyConst.SECRET_KEY, Objects.toString(this.secretKey, \"\"));\n\t\tString endpoint = Objects.toString(this.endpoint, \"\");\n\t\tif (endpoint.contains(\":\")) {\n\t\t\tint index = endpoint.indexOf(\":\");\n\t\t\tproperties.put(PropertyKeyConst.ENDPOINT, endpoint.substring(0, index));\n\t\t\tproperties.put(PropertyKeyConst.ENDPOINT_PORT, endpoint.substring(index + 1));\n\t\t}\n\t\telse {\n\t\t\tproperties.put(PropertyKeyConst.ENDPOINT, endpoint);\n\t\t}\n\n\t\tenrichNacosConfigProperties(properties);\n\n\t\tif (StringUtils.isEmpty(this.serverAddr) && StringUtils.isEmpty(this.endpoint)) {\n\t\t\tproperties.put(PropertyKeyConst.SERVER_ADDR, DEFAULT_ADDRESS);\n\t\t}\n\n\t\treturn properties;\n\t}\n\n\tprotected void enrichNacosConfigProperties(Properties nacosConfigProperties) {\n\t\tif (environment == null) {\n\t\t\treturn;\n\t\t}\n\t\tConfigurableEnvironment env = (ConfigurableEnvironment) environment;\n\t\tMap<String, Object> properties = getSubProperties(env.getPropertySources(), env, CONFIG_PREFIX);\n\t\tproperties.forEach((k, v) -> nacosConfigProperties.putIfAbsent(resolveKey(k), String.valueOf(v)));\n\t}\n\n\tprotected String resolveKey(String key) {\n\t\tMatcher matcher = PATTERN.matcher(key);\n\t\tStringBuilder sb = new StringBuilder();\n\t\twhile (matcher.find()) {\n\t\t\tmatcher.appendReplacement(sb, matcher.group(1).toUpperCase());\n\t\t}\n\t\tmatcher.appendTail(sb);\n\t\treturn sb.toString();\n\t}\n\n\tprivate Map<String, Object> getSubProperties(PropertySources propertySources, PropertyResolver propertyResolver,\n\t\t\tString prefix) {\n\n\t\tMap<String, Object> subProperties = new LinkedHashMap<String, Object>();\n\n\t\tfor (PropertySource<?> source : propertySources) {\n\t\t\tfor (String name : getPropertyNames(source)) {\n\t\t\t\tif (!subProperties.containsKey(name) && name.startsWith(prefix)) {\n\t\t\t\t\tString subName = name.substring(prefix.length() + 1);\n\t\t\t\t\tif (!subProperties.containsKey(subName)) { // take first one\n\t\t\t\t\t\tObject value = source.getProperty(name);\n\t\t\t\t\t\tif (value instanceof String) {\n\t\t\t\t\t\t\tvalue = propertyResolver.resolvePlaceholders((String) value);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tsubProperties.put(subName, value);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn Collections.unmodifiableMap(subProperties);\n\t}\n\n\tprivate String[] getPropertyNames(PropertySource propertySource) {\n\n\t\tString[] propertyNames = propertySource instanceof EnumerablePropertySource\n\t\t\t\t? ((EnumerablePropertySource<?>) propertySource).getPropertyNames() : null;\n\n\t\tif (propertyNames == null) {\n\t\t\treturn new String[0];\n\t\t}\n\t\treturn propertyNames;\n\t}\n\n}", "metadata": {"commit_sha": "442bb2a7", "lines_added": 2, "lines_deleted": 4, "total_changes": 6, "chunks": 2}}
{"id": 176, "pattern_type": "function_signature_change", "file_path": "spring-ai-alibaba-graph-core/src/test/java/com/alibaba/cloud/ai/graph/StateGraphStreamTest.java", "file_extension": "java", "input": "/*\n * Copyright 2024-2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.alibaba.cloud.ai.graph;\n\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi;\nimport com.alibaba.cloud.ai.dashscope.chat.DashScopeChatModel;\nimport com.alibaba.cloud.ai.dashscope.chat.DashScopeChatOptions;\nimport com.alibaba.cloud.ai.graph.action.AsyncEdgeAction;\nimport com.alibaba.cloud.ai.graph.action.AsyncNodeAction;\nimport com.alibaba.cloud.ai.graph.async.AsyncGenerator;\nimport com.alibaba.cloud.ai.graph.async.AsyncGenerator.Data;\nimport com.alibaba.cloud.ai.graph.async.AsyncGeneratorQueue;\nimport com.alibaba.cloud.ai.graph.state.strategy.AppendStrategy;\nimport com.alibaba.cloud.ai.graph.state.strategy.ReplaceStrategy;\nimport com.alibaba.cloud.ai.graph.stream.LLmNodeAction;\nimport com.alibaba.cloud.ai.graph.streaming.StreamingOutput;\nimport com.alibaba.cloud.ai.graph.utils.EdgeMappings;\nimport org.jetbrains.annotations.NotNull;\nimport org.junit.jupiter.api.Assumptions;\nimport org.junit.jupiter.api.BeforeEach;\nimport org.junit.jupiter.api.Tag;\nimport org.junit.jupiter.api.Test;\nimport org.junit.jupiter.api.condition.EnabledIfEnvironmentVariable;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Random;\nimport java.util.concurrent.ArrayBlockingQueue;\nimport java.util.concurrent.BlockingQueue;\nimport java.util.concurrent.CompletableFuture;\nimport java.util.concurrent.ForkJoinPool;\nimport java.util.concurrent.atomic.AtomicInteger;\n\nimport static com.alibaba.cloud.ai.graph.StateGraph.END;\nimport static com.alibaba.cloud.ai.graph.StateGraph.START;\nimport static com.alibaba.cloud.ai.graph.action.AsyncNodeAction.node_async;\nimport static java.util.Arrays.asList;\nimport static java.util.concurrent.CompletableFuture.completedFuture;\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\n\n/**\n * Test class for StateGraph streaming functionality. Verifies the correct behavior of\n * stream-based state transitions and asynchronous processing in state graphs.\n */\npublic class StateGraphStreamTest {\n\n\t/**\n\t * API key for authentication with DashScope services\n\t */\n\tprivate String API_KEY;\n\n\t/**\n\t * Logger instance for tracking test execution and debugging information\n\t */\n\tprivate static final Logger log = LoggerFactory.getLogger(StateGraphStreamTest.class);\n\n\t/**\n\t * Test constant for specifying the Qwen Turbo model in tests\n\t */\n\tprivate static final String TEST_MODEL = \"qwen-turbo\";\n\n\t/**\n\t * Environment variable name containing the DashScope API key\n\t */\n\tprivate static final String API_KEY_ENV = \"AI_DASHSCOPE_API_KEY\";\n\n\t/**\n\t * DashScope API client instance for integration testing\n\t */\n\tprivate DashScopeApi realApi;\n\n\t/**\n\t * Chat options configuration used across multiple tests\n\t */\n\tprivate DashScopeChatOptions options;\n\n\t/**\n\t * Chat model instance configured with test-specific settings\n\t */\n\tprivate DashScopeChatModel chatModel;\n\n\t/**\n\t * Sets up test environment before each test method execution. Initializes API\n\t * credentials and creates configured instances of test dependencies.\n\t */\n\t@BeforeEach\n\tpublic void setUp() {\n\t\tAPI_KEY = System.getenv(API_KEY_ENV); // 替换为你的API密钥\n\t\tAssumptions.assumeTrue(API_KEY != null && !API_KEY.trim().isEmpty(),\n\t\t\t\t\"Skipping tests because \" + API_KEY_ENV + \" environment variable is not set\");\n\t\t// Create real API client with API key from environment\n\t\trealApi = DashScopeApi.builder().apiKey(API_KEY).build();\n\t\t// Create chat model with default options\n\t\toptions = DashScopeChatOptions.builder().withModel(TEST_MODEL).build();\n\t\tchatModel = DashScopeChatModel.builder().dashScopeApi(realApi).defaultOptions(options).build();\n\t}\n\n\t/**\n\t * Creates a basic test node with logging functionality.\n\t * @param id Unique identifier for the node\n\t * @return AsyncNodeAction that logs its execution and returns a simple message\n\t */\n\tprivate AsyncNodeAction makeNode(String id) {\n\t\treturn node_async(state -> {\n\t\t\tlog.info(\"call node {}\", id);\n\t\t\treturn Map.of(\"messages\", id);\n\t\t});\n\t}\n\n\t/**\n\t * Tests basic generator result retrieval from the state graph. Verifies that the\n\t * stream processing correctly handles terminal states and results.\n\t */\n\t@Test\n\tpublic void testGetResultFromGenerator() throws Exception {\n\t\tvar workflow = new StateGraph(() -> {\n\t\t\tMap<String, KeyStrategy> keyStrategyMap = new HashMap<>();\n\t\t\tkeyStrategyMap.put(\"messages\", new AppendStrategy());\n\t\t\treturn keyStrategyMap;\n\t\t}).addEdge(START, \"agent_1\").addNode(\"agent_1\", makeNode(\"agent_1\")).addEdge(\"agent_1\", END);\n\n\t\tvar app = workflow.compile();\n\n\t\tvar iterator = app.stream(Map.of());\n\t\tfor (var i : iterator) {\n\t\t\tSystem.out.println(i);\n\t\t}\n\n\t\tvar generator = (AsyncGenerator.HasResultValue) iterator;\n\n\t\tSystem.out.println(generator.resultValue().orElse(null));\n\n\t}\n\n\t/**\n\t * Tests streaming functionality with basic node actions. Validates that the system\n\t * can handle sequential node execution with streaming outputs.\n\t */\n\t@Test\n\tpublic void testBasicNodeActionStream() throws Exception {\n\t\tStateGraph stateGraph = new StateGraph(() -> {\n\t\t\tMap<String, KeyStrategy> keyStrategyMap = new HashMap<>();\n\t\t\tkeyStrategyMap.put(\"messages\", new AppendStrategy());\n\t\t\tkeyStrategyMap.put(\"count\", (oldValue, newValue) -> oldValue == null ? newValue : 1);\n\t\t\treturn keyStrategyMap;\n\t\t}).addNode(\"collectInput\", node_async(s -> {\n\n\t\t\tString input = s.value(\"input\", \"\");\n\t\t\treturn Map.of(\"messages\", \"Received: \" + input, \"count\", 1);\n\t\t})).addNode(\"processData\", node_async(s -> {\n\n\t\t\tfinal List<String> data = asList(\"这是\", \"一个\", \"流式\", \"输出\", \"测试\");\n\t\t\tAtomicInteger timeOff = new AtomicInteger(1);\n\t\t\tfinal AsyncGenerator<NodeOutput> it = AsyncGenerator.collect(data.iterator(),\n\t\t\t\t\t(index, add) -> add.accept(of(\"processData\", index, 500L * timeOff.getAndIncrement(), s)));\n\t\t\treturn Map.of(\"messages\", it);\n\t\t})).addNode(\"generateResponse\", node_async(s -> {\n\n\t\t\tint count = s.value(\"count\", 0);\n\t\t\treturn Map.of(\"messages\", \"Response generated (processed \" + count + \" items)\", \"result\", \"Success\");\n\t\t}))\n\t\t\t.addEdge(START, \"collectInput\")\n\t\t\t.addEdge(\"collectInput\", \"processData\")\n\t\t\t.addEdge(\"processData\", \"generateResponse\")\n\t\t\t.addEdge(\"generateResponse\", END);\n\n\t\tCompiledGraph compiledGraph = stateGraph.compile();\n\t\t// 初始化输入\n\t\tfor (var output : compiledGraph.stream(Map.of(\"input\", \"hoho~~\"))) {\n\t\t\tif (output instanceof AsyncGenerator<?>) {\n\t\t\t\tAsyncGenerator asyncGenerator = (AsyncGenerator) output;\n\t\t\t\tSystem.out.println(\"Streaming chunk: \" + asyncGenerator);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tSystem.out.println(\"Node output: \" + output);\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * Creates a CompletableFuture containing a StreamingOutput with delayed execution.\n\t * @param node Node identifier\n\t * @param index Index value for the output\n\t * @param delayInMills Delay time in milliseconds\n\t * @param overAllState Current state context\n\t * @return CompletableFuture containing the StreamingOutput\n\t */\n\tstatic CompletableFuture<NodeOutput> of(String node, String index, long delayInMills, OverAllState overAllState) {\n\t\treturn CompletableFuture.supplyAsync(() -> {\n\t\t\ttry {\n\t\t\t\tThread.sleep(delayInMills);\n\t\t\t}\n\t\t\tcatch (InterruptedException e) {\n\t\t\t\tthrow new RuntimeException(e);\n\t\t\t}\n\t\t\treturn new StreamingOutput(index, node, overAllState);\n\t\t});\n\t}\n\n\t/**\n\t * Tests streaming functionality using an AsyncGeneratorQueue implementation. Verifies\n\t * that queue-based streaming works correctly with the state graph architecture.\n\t */\n\t@Test\n\tpublic void testNodeActionStreamForAsyncGeneratorQueue() throws Exception {\n\t\tStateGraph stateGraph = new StateGraph(() -> {\n\t\t\tMap<String, KeyStrategy> keyStrategyMap = new HashMap<>();\n\t\t\tkeyStrategyMap.put(\"messages\", new AppendStrategy());\n\t\t\tkeyStrategyMap.put(\"count\", (oldValue, newValue) -> oldValue == null ? newValue : 1);\n\t\t\treturn keyStrategyMap;\n\t\t}).addNode(\"collectInput\", node_async(s -> {\n\n\t\t\tString input = s.value(\"input\", \"\");\n\t\t\treturn Map.of(\"messages\", \"Received: \" + input, \"count\", 1);\n\t\t})).addNode(\"processData\", node_async(s -> {\n\t\t\tAsyncGenerator.WithResult<StreamingOutput> it = getStreamingOutputWithResult(s);\n\t\t\treturn Map.of(\"messages\", it);\n\t\t})).addNode(\"generateResponse\", node_async(s -> {\n\n\t\t\tint count = s.value(\"count\", 0);\n\t\t\treturn Map.of(\"messages\", \"Response generated (processed \" + count + \" items)\", \"result\", \"Success\");\n\t\t}))\n\t\t\t.addEdge(START, \"collectInput\")\n\t\t\t.addEdge(\"collectInput\", \"processData\")\n\t\t\t.addEdge(\"processData\", \"generateResponse\")\n\t\t\t.addEdge(\"generateResponse\", END);\n\n\t\tCompiledGraph compiledGraph = stateGraph.compile();\n\t\t// 初始化输入\n\t\tfor (var output : compiledGraph.stream(Map.of(\"input\", \"hoho~~\"))) {\n\t\t\tif (output instanceof AsyncGenerator<?>) {\n\t\t\t\tAsyncGenerator asyncGenerator = (AsyncGenerator) output;\n\t\t\t\tSystem.out.println(\"Streaming chunk: \" + asyncGenerator);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tSystem.out.println(\"Node output: \" + output);\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * Creates a streaming output generator that produces random values at intervals.\n\t * @param s Current state context\n\t * @return AsyncGenerator with streaming output values\n\t */\n\tprivate static AsyncGenerator.WithResult<StreamingOutput> getStreamingOutputWithResult(OverAllState s) {\n\n\t\tBlockingQueue<Data<StreamingOutput>> queue = new ArrayBlockingQueue<>(2000);\n\t\tAsyncGenerator.WithResult<StreamingOutput> it = new AsyncGenerator.WithResult<>(\n\t\t\t\tnew AsyncGeneratorQueue.Generator<>(queue));\n\t\tString str = \"random\";\n\t\tnew Thread(() -> {\n\t\t\tfor (int i = 0; i < 10; i++) {\n\t\t\t\ttry {\n\t\t\t\t\tThread.sleep(1000);\n\t\t\t\t}\n\t\t\t\tcatch (InterruptedException e) {\n\t\t\t\t\tthrow new RuntimeException(e);\n\t\t\t\t}\n\t\t\t\tif (i == 9) {\n\t\t\t\t\tqueue.add(Data.done());\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tqueue.add(Data.of(new StreamingOutput(str + new Random().nextInt(10), \"llmNode\", s)));\n\t\t\t\t}\n\t\t\t}\n\t\t}).start();\n\t\treturn it;\n\t}\n\n\t/**\n\t * Integration test for model node action streaming. Verifies end-to-end streaming\n\t * functionality with actual LLM integration.\n\t */\n\t@Test\n\t@Tag(\"integration\")\n\t@EnabledIfEnvironmentVariable(named = \"AI_DASHSCOPE_API_KEY\", matches = \".+\")\n\tpublic void testToModelNodeActionStream() throws Exception {\n\t\tStateGraph stateGraph = new StateGraph(() -> {\n\t\t\tMap<String, KeyStrategy> keyStrategyMap = new HashMap<>();\n\t\t\tkeyStrategyMap.put(\"messages\", new AppendStrategy());\n\t\t\tkeyStrategyMap.put(\"llm_result\", new AppendStrategy());\n\t\t\treturn keyStrategyMap;\n\t\t}).addNode(\"llmNode\", node_async(new LLmNodeAction(chatModel)))\n\t\t\t.addNode(\"toolNode\", node_async((t) -> Map.of(\"messages\", \"tool call result\")))\n\t\t\t.addNode(\"result\", node_async((t) -> Map.of(\"messages\", \"result\", \"llm_result\", \"end\")))\n\t\t\t.addEdge(START, \"llmNode\")\n\t\t\t.addEdge(\"llmNode\", \"toolNode\")\n\t\t\t.addEdge(\"toolNode\", \"result\")\n\t\t\t.addEdge(\"result\", END);\n\n\t\tCompiledGraph compile = stateGraph.compile();\n\t\tAsyncGenerator<NodeOutput> stream = compile.stream(Map.of(OverAllState.DEFAULT_INPUT_KEY, \"给我写一个10字的小文章\"));\n\t\tstream.forEachAsync(nodeOutput -> System.out.println(\"Node output: \" + nodeOutput));\n\t}\n\n\t/**\n\t * Integration test for model node action with conditional edge routing. Verifies that\n\t * streaming works correctly with dynamic path selection based on content.\n\t */\n\t@Test\n\t@Tag(\"integration\")\n\t@EnabledIfEnvironmentVariable(named = \"AI_DASHSCOPE_API_KEY\", matches = \".+\")\n\tpublic void testToModelNodeActionAndConditionEdgeStream() throws Exception {\n\t\tStateGraph stateGraph = new StateGraph(() -> {\n\t\t\tMap<String, KeyStrategy> keyStrategyMap = new HashMap<>();\n\t\t\tkeyStrategyMap.put(\"messages\", new AppendStrategy());\n\t\t\tkeyStrategyMap.put(\"llm_result\", new AppendStrategy());\n\t\t\treturn keyStrategyMap;\n\t\t}).addNode(\"llmNode\", node_async(new LLmNodeAction(chatModel)))\n\t\t\t.addNode(\"toolNode\", node_async((t) -> Map.of(\"messages\", \"tool call result\")))\n\t\t\t.addNode(\"result\", node_async((t) -> Map.of(\"messages\", \"result\", \"llm_result\", \"end\")))\n\t\t\t.addEdge(START, \"llmNode\")\n\t\t\t.addConditionalEdges(\"llmNode\", getAsyncEdgeAction(),\n\t\t\t\t\tEdgeMappings.builder().to(\"toolNode\", \"toolNode\").to(\"result\", \"result\").toEND().build())\n\t\t\t.addEdge(\"toolNode\", \"result\")\n\t\t\t.addEdge(\"result\", END);\n\n\t\tCompiledGraph compile = stateGraph.compile();\n\t\tfor (var output : compile.stream(Map.of(OverAllState.DEFAULT_INPUT_KEY, \"给我写一个10字的小文章\"))) {\n\t\t\tif (output instanceof AsyncGenerator<?>) {\n\t\t\t\tAsyncGenerator asyncGenerator = (AsyncGenerator) output;\n\t\t\t\tSystem.out.println(\"Streaming chunk: \" + asyncGenerator);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tSystem.out.println(\"Node output: \" + output);\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * Creates an asynchronous edge action for conditional routing decisions.\n\t * @return AsyncEdgeAction that determines the next node based on message content\n\t */\n\t@NotNull\n\tprivate static AsyncEdgeAction getAsyncEdgeAction() {\n\t\treturn t -> {\n\t\t\tif (t.value(\"messages\").isEmpty())\n\t\t\t\treturn completedFuture(\"result\");\n\t\t\tList collectedMessages = (List) t.value(\"messages\").get();\n\t\t\t// 使用异步方式等待流结束\n\t\t\tCompletableFuture<String> resultFuture = new CompletableFuture<>();\n\t\t\tif (!collectedMessages.isEmpty()) {\n\t\t\t\tresultFuture.complete(\"toolNode\");\n\t\t\t}\n\t\t\telse {\n\t\t\t\tresultFuture.complete(\"result\");\n\t\t\t}\n\t\t\treturn resultFuture;\n\t\t};\n\t}\n\n\t/**\n\t * Tests comprehensive streaming output processing pipeline. Validates that streaming\n\t * outputs are properly handled and aggregated through the graph.\n\t */\n\t@Test\n\tpublic void testStreamingOutputProcessing() throws Exception {\n\t\tStateGraph stateGraph = new StateGraph(() -> {\n\t\t\tMap<String, KeyStrategy> keyStrategyMap = new HashMap<>();\n\t\t\tkeyStrategyMap.put(\"messages\", new AppendStrategy());\n\t\t\tkeyStrategyMap.put(\"count\", (oldValue, newValue) -> oldValue == null ? newValue : 1);\n\t\t\treturn keyStrategyMap;\n\t\t}).addNode(\"collectInput\", node_async(s -> {\n\t\t\t// 处理输入\n\t\t\tString input = s.value(\"input\", \"\");\n\t\t\treturn Map.of(\"messages\", \"Received: \" + input, \"count\", 1);\n\t\t})).addNode(\"processData\", node_async(s -> {\n\t\t\t// 处理数据 - 这里可以是耗时操作，会以流式方式返回结果\n\t\t\tfinal List<String> data = asList(\"这是\", \"一个\", \"流式\", \"输出\", \"测试\");\n\t\t\tAtomicInteger timeOff = new AtomicInteger(1);\n\t\t\tfinal AsyncGenerator<NodeOutput> it = AsyncGenerator.collect(data.iterator(),\n\t\t\t\t\t(index, add) -> add.accept(of(\"processData\", index, 500L * timeOff.getAndIncrement(), s)));\n\t\t\treturn Map.of(\"messages\", it);\n\t\t})).addNode(\"generateResponse\", node_async(s -> {\n\t\t\t// 生成最终响应\n\t\t\tint count = s.value(\"count\", 0);\n\t\t\treturn Map.of(\"messages\", \"Response generated (processed \" + count + \" items)\", \"result\", \"Success\");\n\t\t}))\n\t\t\t.addEdge(START, \"collectInput\")\n\t\t\t.addEdge(\"collectInput\", \"processData\")\n\t\t\t.addEdge(\"processData\", \"generateResponse\")\n\t\t\t.addEdge(\"generateResponse\", END);\n\n\t\tCompiledGraph app = stateGraph.compile();\n\n\t\tAsyncGenerator<NodeOutput> generator = app.stream(Map.of(\"input\", \"test\"));\n\t\tList states = toStateList(generator);\n\n\t\tassertFalse(states.isEmpty(), \"least one content\");\n\t\tassertEquals(5, states.size(), \"should be five content\");\n\t}\n\n\t/**\n\t * Helper method for processing streaming output. Filters out streaming chunks and\n\t * extracts state information from node outputs.\n\t * @param generator AsyncGenerator producing node outputs\n\t * @return List of OverAllState objects representing processed states\n\t */\n\tprivate List<OverAllState> toStateList(AsyncGenerator<NodeOutput> generator) {\n\t\treturn generator.stream().filter(s -> {\n\t\t\tif (s instanceof StreamingOutput streamingOutput) {\n\t\t\t\tSystem.out\n\t\t\t\t\t.println(String.format(\"stream data %s '%s'\", streamingOutput.node(), streamingOutput.chunk()));\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\treturn true;\n\t\t})\n\t\t\t.peek(s -> System.out.println(String.format(\"NODE: {}\", s.node())))\n\t\t\t.map(NodeOutput::state)\n\t\t\t.collect(java.util.stream.Collectors.toList());\n\t}\n\n\t@Test\n\t@Tag(\"integration\")\n\t@EnabledIfEnvironmentVariable(named = \"AI_DASHSCOPE_API_KEY\", matches = \".+\")\n\tpublic void testParallelNodeStream() throws Exception {\n\t\tStateGraph stateGraph = new StateGraph(() -> {\n\t\t\tMap<String, KeyStrategy> keyStrategyMap = new HashMap<>();\n\t\t\tkeyStrategyMap.put(\"messages\", new AppendStrategy());\n\t\t\tkeyStrategyMap.put(\"llm_result\", new AppendStrategy());\n\t\t\tkeyStrategyMap.put(\"input\", new ReplaceStrategy());\n\t\t\treturn keyStrategyMap;\n\t\t}).addNode(\"llmNode\", node_async(new LLmNodeAction(chatModel, \"llmNode\")))\n\t\t\t.addNode(\"llmNode2\", node_async(new LLmNodeAction(chatModel, \"llmNode2\")))\n\t\t\t.addNode(\"result\", node_async((t) -> Map.of(\"llm_result\", \"llm_result\")))\n\t\t\t.addNode(\"toolNode\", node_async((t) -> Map.of(\"messages\", \"tool call result\")))\n\t\t\t.addEdge(START, \"llmNode\")\n\t\t\t.addEdge(START, \"llmNode2\")\n\t\t\t.addEdge(START, \"result\")\n\t\t\t.addEdge(\"llmNode\", \"toolNode\")\n\t\t\t.addEdge(\"llmNode2\", \"toolNode\")\n\t\t\t.addEdge(\"toolNode\", END);\n\n\t\tCompiledGraph compile = stateGraph.compile();\n\n\t\tfor (var output : compile.stream(Map.of(OverAllState.DEFAULT_INPUT_KEY, \"给我写一个10字的小文章\"),\n\t\t\t\tRunnableConfig.builder().addParallelNodeExecutor(START, ForkJoinPool.commonPool()).build())) {\n\t\t\tif (output instanceof AsyncGenerator<?>) {\n\t\t\t\tAsyncGenerator asyncGenerator = (AsyncGenerator) output;\n\t\t\t\tSystem.out.println(\"Streaming chunk: \" + asyncGenerator);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tSystem.out.println(\"Node output: \" + output);\n\t\t\t}\n\t\t}\n\n\t}\n\n}", "output": "/*\n * Copyright 2024-2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.alibaba.cloud.ai.graph;\n\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi;\nimport com.alibaba.cloud.ai.dashscope.chat.DashScopeChatModel;\nimport com.alibaba.cloud.ai.dashscope.chat.DashScopeChatOptions;\nimport com.alibaba.cloud.ai.graph.action.AsyncEdgeAction;\nimport com.alibaba.cloud.ai.graph.action.AsyncNodeAction;\nimport com.alibaba.cloud.ai.graph.async.AsyncGenerator;\nimport com.alibaba.cloud.ai.graph.async.AsyncGenerator.Data;\nimport com.alibaba.cloud.ai.graph.async.AsyncGeneratorQueue;\nimport com.alibaba.cloud.ai.graph.state.strategy.AppendStrategy;\nimport com.alibaba.cloud.ai.graph.state.strategy.ReplaceStrategy;\nimport com.alibaba.cloud.ai.graph.stream.LLmNodeAction;\nimport com.alibaba.cloud.ai.graph.streaming.StreamingOutput;\nimport com.alibaba.cloud.ai.graph.utils.EdgeMappings;\nimport org.jetbrains.annotations.NotNull;\nimport org.junit.jupiter.api.Assumptions;\nimport org.junit.jupiter.api.BeforeEach;\nimport org.junit.jupiter.api.Tag;\nimport org.junit.jupiter.api.Test;\nimport org.junit.jupiter.api.condition.EnabledIfEnvironmentVariable;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Random;\nimport java.util.concurrent.ArrayBlockingQueue;\nimport java.util.concurrent.BlockingQueue;\nimport java.util.concurrent.CompletableFuture;\nimport java.util.concurrent.ForkJoinPool;\nimport java.util.concurrent.atomic.AtomicInteger;\n\nimport static com.alibaba.cloud.ai.graph.StateGraph.END;\nimport static com.alibaba.cloud.ai.graph.StateGraph.START;\nimport static com.alibaba.cloud.ai.graph.action.AsyncNodeAction.node_async;\nimport static java.util.Arrays.asList;\nimport static java.util.concurrent.CompletableFuture.completedFuture;\nimport static org.junit.jupiter.api.Assertions.assertEquals;\nimport static org.junit.jupiter.api.Assertions.assertFalse;\n\n/**\n * Test class for StateGraph streaming functionality. Verifies the correct behavior of\n * stream-based state transitions and asynchronous processing in state graphs.\n */\npublic class StateGraphStreamTest {\n\n\t/**\n\t * API key for authentication with DashScope services\n\t */\n\tprivate String API_KEY;\n\n\t/**\n\t * Logger instance for tracking test execution and debugging information\n\t */\n\tprivate static final Logger log = LoggerFactory.getLogger(StateGraphStreamTest.class);\n\n\t/**\n\t * Test constant for specifying the Qwen Turbo model in tests\n\t */\n\tprivate static final String TEST_MODEL = \"qwen-turbo\";\n\n\t/**\n\t * Environment variable name containing the DashScope API key\n\t */\n\tprivate static final String API_KEY_ENV = \"AI_DASHSCOPE_API_KEY\";\n\n\t/**\n\t * DashScope API client instance for integration testing\n\t */\n\tprivate DashScopeApi realApi;\n\n\t/**\n\t * Chat options configuration used across multiple tests\n\t */\n\tprivate DashScopeChatOptions options;\n\n\t/**\n\t * Chat model instance configured with test-specific settings\n\t */\n\tprivate DashScopeChatModel chatModel;\n\n\t/**\n\t * Sets up test environment before each test method execution. Initializes API\n\t * credentials and creates configured instances of test dependencies.\n\t */\n\t@BeforeEach\n\tpublic void setUp() {\n\t\tAPI_KEY = System.getenv(API_KEY_ENV); // 替换为你的API密钥\n\t\tAssumptions.assumeTrue(API_KEY != null && !API_KEY.trim().isEmpty(),\n\t\t\t\t\"Skipping tests because \" + API_KEY_ENV + \" environment variable is not set\");\n\t\t// Create real API client with API key from environment\n\t\trealApi = DashScopeApi.builder().apiKey(API_KEY).build();\n\t\t// Create chat model with default options\n\t\toptions = DashScopeChatOptions.builder().withModel(TEST_MODEL).build();\n\t\tchatModel = DashScopeChatModel.builder().dashScopeApi(realApi).defaultOptions(options).build();\n\t}\n\n\t/**\n\t * Creates a basic test node with logging functionality.\n\t * @param id Unique identifier for the node\n\t * @return AsyncNodeAction that logs its execution and returns a simple message\n\t */\n\tprivate AsyncNodeAction makeNode(String id) {\n\t\treturn node_async(state -> {\n\t\t\tlog.info(\"call node {}\", id);\n\t\t\treturn Map.of(\"messages\", id);\n\t\t});\n\t}\n\n\t/**\n\t * Tests basic generator result retrieval from the state graph. Verifies that the\n\t * stream processing correctly handles terminal states and results.\n\t */\n\t@Test\n\tpublic void testGetResultFromGenerator() throws Exception {\n\t\tvar workflow = new StateGraph(() -> {\n\t\t\tMap<String, KeyStrategy> keyStrategyMap = new HashMap<>();\n\t\t\tkeyStrategyMap.put(\"messages\", new AppendStrategy());\n\t\t\treturn keyStrategyMap;\n\t\t}).addEdge(START, \"agent_1\").addNode(\"agent_1\", makeNode(\"agent_1\")).addEdge(\"agent_1\", END);\n\n\t\tvar app = workflow.compile();\n\n\t\tvar iterator = app.stream(Map.of());\n\t\tfor (var i : iterator) {\n\t\t\tSystem.out.println(i);\n\t\t}\n\n\t\tvar generator = (AsyncGenerator.HasResultValue) iterator;\n\n\t\tSystem.out.println(generator.resultValue().orElse(null));\n\n\t}\n\n\t/**\n\t * Tests streaming functionality with basic node actions. Validates that the system\n\t * can handle sequential node execution with streaming outputs.\n\t */\n\t@Test\n\tpublic void testBasicNodeActionStream() throws Exception {\n\t\tStateGraph stateGraph = new StateGraph(() -> {\n\t\t\tMap<String, KeyStrategy> keyStrategyMap = new HashMap<>();\n\t\t\tkeyStrategyMap.put(\"messages\", new AppendStrategy());\n\t\t\tkeyStrategyMap.put(\"count\", (oldValue, newValue) -> oldValue == null ? newValue : 1);\n\t\t\treturn keyStrategyMap;\n\t\t}).addNode(\"collectInput\", node_async(s -> {\n\n\t\t\tString input = s.value(\"input\", \"\");\n\t\t\treturn Map.of(\"messages\", \"Received: \" + input, \"count\", 1);\n\t\t})).addNode(\"processData\", node_async(s -> {\n\n\t\t\tfinal List<String> data = asList(\"这是\", \"一个\", \"流式\", \"输出\", \"测试\");\n\t\t\tAtomicInteger timeOff = new AtomicInteger(1);\n\t\t\tfinal AsyncGenerator<NodeOutput> it = AsyncGenerator.collect(data.iterator(),\n\t\t\t\t\t(index, add) -> add.accept(of(\"processData\", index, 500L * timeOff.getAndIncrement(), s)));\n\t\t\treturn Map.of(\"messages\", it);\n\t\t})).addNode(\"generateResponse\", node_async(s -> {\n\n\t\t\tint count = s.value(\"count\", 0);\n\t\t\treturn Map.of(\"messages\", \"Response generated (processed \" + count + \" items)\", \"result\", \"Success\");\n\t\t}))\n\t\t\t.addEdge(START, \"collectInput\")\n\t\t\t.addEdge(\"collectInput\", \"processData\")\n\t\t\t.addEdge(\"processData\", \"generateResponse\")\n\t\t\t.addEdge(\"generateResponse\", END);\n\n\t\tCompiledGraph compiledGraph = stateGraph.compile();\n\t\t// 初始化输入\n\t\tfor (var output : compiledGraph.stream(Map.of(\"input\", \"hoho~~\"))) {\n\t\t\tif (output instanceof AsyncGenerator<?>) {\n\t\t\t\tAsyncGenerator asyncGenerator = (AsyncGenerator) output;\n\t\t\t\tSystem.out.println(\"Streaming chunk: \" + asyncGenerator);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tSystem.out.println(\"Node output: \" + output);\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * Creates a CompletableFuture containing a StreamingOutput with delayed execution.\n\t * @param node Node identifier\n\t * @param index Index value for the output\n\t * @param delayInMills Delay time in milliseconds\n\t * @param overAllState Current state context\n\t * @return CompletableFuture containing the StreamingOutput\n\t */\n\tstatic CompletableFuture<NodeOutput> of(String node, String index, long delayInMills, OverAllState overAllState) {\n\t\treturn CompletableFuture.supplyAsync(() -> {\n\t\t\ttry {\n\t\t\t\tThread.sleep(delayInMills);\n\t\t\t}\n\t\t\tcatch (InterruptedException e) {\n\t\t\t\tthrow new RuntimeException(e);\n\t\t\t}\n\t\t\treturn new StreamingOutput(index, node, overAllState);\n\t\t});\n\t}\n\n\t/**\n\t * Tests streaming functionality using an AsyncGeneratorQueue implementation. Verifies\n\t * that queue-based streaming works correctly with the state graph architecture.\n\t */\n\t@Test\n\tpublic void testNodeActionStreamForAsyncGeneratorQueue() throws Exception {\n\t\tStateGraph stateGraph = new StateGraph(() -> {\n\t\t\tMap<String, KeyStrategy> keyStrategyMap = new HashMap<>();\n\t\t\tkeyStrategyMap.put(\"messages\", new AppendStrategy());\n\t\t\tkeyStrategyMap.put(\"count\", (oldValue, newValue) -> oldValue == null ? newValue : 1);\n\t\t\treturn keyStrategyMap;\n\t\t}).addNode(\"collectInput\", node_async(s -> {\n\n\t\t\tString input = s.value(\"input\", \"\");\n\t\t\treturn Map.of(\"messages\", \"Received: \" + input, \"count\", 1);\n\t\t})).addNode(\"processData\", node_async(s -> {\n\t\t\tAsyncGenerator.WithResult<StreamingOutput> it = getStreamingOutputWithResult(s);\n\t\t\treturn Map.of(\"messages\", it);\n\t\t})).addNode(\"generateResponse\", node_async(s -> {\n\n\t\t\tint count = s.value(\"count\", 0);\n\t\t\treturn Map.of(\"messages\", \"Response generated (processed \" + count + \" items)\", \"result\", \"Success\");\n\t\t}))\n\t\t\t.addEdge(START, \"collectInput\")\n\t\t\t.addEdge(\"collectInput\", \"processData\")\n\t\t\t.addEdge(\"processData\", \"generateResponse\")\n\t\t\t.addEdge(\"generateResponse\", END);\n\n\t\tCompiledGraph compiledGraph = stateGraph.compile();\n\t\t// 初始化输入\n\t\tfor (var output : compiledGraph.stream(Map.of(\"input\", \"hoho~~\"))) {\n\t\t\tif (output instanceof AsyncGenerator<?>) {\n\t\t\t\tAsyncGenerator asyncGenerator = (AsyncGenerator) output;\n\t\t\t\tSystem.out.println(\"Streaming chunk: \" + asyncGenerator);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tSystem.out.println(\"Node output: \" + output);\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * Creates a streaming output generator that produces random values at intervals.\n\t * @param s Current state context\n\t * @return AsyncGenerator with streaming output values\n\t */\n\tprivate static AsyncGenerator.WithResult<StreamingOutput> getStreamingOutputWithResult(OverAllState s) {\n\n\t\tBlockingQueue<Data<StreamingOutput>> queue = new ArrayBlockingQueue<>(2000);\n\t\tAsyncGenerator.WithResult<StreamingOutput> it = new AsyncGenerator.WithResult<>(\n\t\t\t\tnew AsyncGeneratorQueue.Generator<>(queue));\n\t\tString str = \"random\";\n\t\tnew Thread(() -> {\n\t\t\tfor (int i = 0; i < 10; i++) {\n\t\t\t\ttry {\n\t\t\t\t\tThread.sleep(1000);\n\t\t\t\t}\n\t\t\t\tcatch (InterruptedException e) {\n\t\t\t\t\tthrow new RuntimeException(e);\n\t\t\t\t}\n\t\t\t\tif (i == 9) {\n\t\t\t\t\tqueue.add(Data.done());\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tqueue.add(Data.of(new StreamingOutput(str + new Random().nextInt(10), \"llmNode\", s)));\n\t\t\t\t}\n\t\t\t}\n\t\t}).start();\n\t\treturn it;\n\t}\n\n\t/**\n\t * Integration test for model node action streaming. Verifies end-to-end streaming\n\t * functionality with actual LLM integration.\n\t */\n\t@Test\n\t@Tag(\"integration\")\n\t@EnabledIfEnvironmentVariable(named = \"AI_DASHSCOPE_API_KEY\", matches = \".+\")\n\tpublic void testToModelNodeActionStream() throws Exception {\n\t\tStateGraph stateGraph = new StateGraph(() -> {\n\t\t\tMap<String, KeyStrategy> keyStrategyMap = new HashMap<>();\n\t\t\tkeyStrategyMap.put(\"messages\", new AppendStrategy());\n\t\t\tkeyStrategyMap.put(\"llm_result\", new AppendStrategy());\n\t\t\treturn keyStrategyMap;\n\t\t}).addNode(\"llmNode\", node_async(new LLmNodeAction(chatModel)))\n\t\t\t.addNode(\"toolNode\", node_async((t) -> Map.of(\"messages\", \"tool call result\")))\n\t\t\t.addNode(\"result\", node_async((t) -> Map.of(\"messages\", \"result\", \"llm_result\", \"end\")))\n\t\t\t.addEdge(START, \"llmNode\")\n\t\t\t.addEdge(\"llmNode\", \"toolNode\")\n\t\t\t.addEdge(\"toolNode\", \"result\")\n\t\t\t.addEdge(\"result\", END);\n\n\t\tCompiledGraph compile = stateGraph.compile();\n\t\tAsyncGenerator<NodeOutput> stream = compile.stream(Map.of(OverAllState.DEFAULT_INPUT_KEY, \"给我写一个10字的小文章\"));\n\t\tstream.forEachAsync(nodeOutput -> System.out.println(\"Node output: \" + nodeOutput));\n\t}\n\n\t/**\n\t * Integration test for model node action with conditional edge routing. Verifies that\n\t * streaming works correctly with dynamic path selection based on content.\n\t */\n\t@Test\n\t@Tag(\"integration\")\n\t@EnabledIfEnvironmentVariable(named = \"AI_DASHSCOPE_API_KEY\", matches = \".+\")\n\tpublic void testToModelNodeActionAndConditionEdgeStream() throws Exception {\n\t\tStateGraph stateGraph = new StateGraph(() -> {\n\t\t\tMap<String, KeyStrategy> keyStrategyMap = new HashMap<>();\n\t\t\tkeyStrategyMap.put(\"messages\", new AppendStrategy());\n\t\t\tkeyStrategyMap.put(\"llm_result\", new AppendStrategy());\n\t\t\treturn keyStrategyMap;\n\t\t}).addNode(\"llmNode\", node_async(new LLmNodeAction(chatModel)))\n\t\t\t.addNode(\"toolNode\", node_async((t) -> Map.of(\"messages\", \"tool call result\")))\n\t\t\t.addNode(\"result\", node_async((t) -> Map.of(\"messages\", \"result\", \"llm_result\", \"end\")))\n\t\t\t.addEdge(START, \"llmNode\")\n\t\t\t.addConditionalEdges(\"llmNode\", getAsyncEdgeAction(),\n\t\t\t\t\tEdgeMappings.builder().to(\"toolNode\", \"toolNode\").to(\"result\", \"result\").toEND().build())\n\t\t\t.addEdge(\"toolNode\", \"result\")\n\t\t\t.addEdge(\"result\", END);\n\n\t\tCompiledGraph compile = stateGraph.compile();\n\t\tfor (var output : compile.stream(Map.of(OverAllState.DEFAULT_INPUT_KEY, \"给我写一个10字的小文章\"))) {\n\t\t\tif (output instanceof AsyncGenerator<?>) {\n\t\t\t\tAsyncGenerator asyncGenerator = (AsyncGenerator) output;\n\t\t\t\tSystem.out.println(\"Streaming chunk: \" + asyncGenerator);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tSystem.out.println(\"Node output: \" + output);\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * Creates an asynchronous edge action for conditional routing decisions.\n\t * @return AsyncEdgeAction that determines the next node based on message content\n\t */\n\t@NotNull\n\tprivate static AsyncEdgeAction getAsyncEdgeAction() {\n\t\treturn t -> {\n\t\t\tif (t.value(\"messages\").isEmpty())\n\t\t\t\treturn completedFuture(\"result\");\n\t\t\tList collectedMessages = (List) t.value(\"messages\").get();\n\t\t\t// 使用异步方式等待流结束\n\t\t\tCompletableFuture<String> resultFuture = new CompletableFuture<>();\n\t\t\tif (!collectedMessages.isEmpty()) {\n\t\t\t\tresultFuture.complete(\"toolNode\");\n\t\t\t}\n\t\t\telse {\n\t\t\t\tresultFuture.complete(\"result\");\n\t\t\t}\n\t\t\treturn resultFuture;\n\t\t};\n\t}\n\n\t/**\n\t * Tests comprehensive streaming output processing pipeline. Validates that streaming\n\t * outputs are properly handled and aggregated through the graph.\n\t */\n\t@Test\n\tpublic void testStreamingOutputProcessing() throws Exception {\n\t\tStateGraph stateGraph = new StateGraph(() -> {\n\t\t\tMap<String, KeyStrategy> keyStrategyMap = new HashMap<>();\n\t\t\tkeyStrategyMap.put(\"messages\", new AppendStrategy());\n\t\t\tkeyStrategyMap.put(\"count\", (oldValue, newValue) -> oldValue == null ? newValue : 1);\n\t\t\treturn keyStrategyMap;\n\t\t}).addNode(\"collectInput\", node_async(s -> {\n\t\t\t// 处理输入\n\t\t\tString input = s.value(\"input\", \"\");\n\t\t\treturn Map.of(\"messages\", \"Received: \" + input, \"count\", 1);\n\t\t})).addNode(\"processData\", node_async(s -> {\n\t\t\t// 处理数据 - 这里可以是耗时操作，会以流式方式返回结果\n\t\t\tfinal List<String> data = asList(\"这是\", \"一个\", \"流式\", \"输出\", \"测试\");\n\t\t\tAtomicInteger timeOff = new AtomicInteger(1);\n\t\t\tfinal AsyncGenerator<NodeOutput> it = AsyncGenerator.collect(data.iterator(),\n\t\t\t\t\t(index, add) -> add.accept(of(\"processData\", index, 500L * timeOff.getAndIncrement(), s)));\n\t\t\treturn Map.of(\"messages\", it);\n\t\t})).addNode(\"generateResponse\", node_async(s -> {\n\t\t\t// 生成最终响应\n\t\t\tint count = s.value(\"count\", 0);\n\t\t\treturn Map.of(\"messages\", \"Response generated (processed \" + count + \" items)\", \"result\", \"Success\");\n\t\t}))\n\t\t\t.addEdge(START, \"collectInput\")\n\t\t\t.addEdge(\"collectInput\", \"processData\")\n\t\t\t.addEdge(\"processData\", \"generateResponse\")\n\t\t\t.addEdge(\"generateResponse\", END);\n\n\t\tCompiledGraph app = stateGraph.compile();\n\n\t\tAsyncGenerator<NodeOutput> generator = app.stream(Map.of(\"input\", \"test\"));\n\t\tList states = toStateList(generator);\n\n\t\tassertFalse(states.isEmpty(), \"least one content\");\n\t\tassertEquals(4, states.size(), \"should be five content\");\n\t}\n\n\t/**\n\t * Helper method for processing streaming output. Filters out streaming chunks and\n\t * extracts state information from node outputs.\n\t * @param generator AsyncGenerator producing node outputs\n\t * @return List of OverAllState objects representing processed states\n\t */\n\tprivate List<OverAllState> toStateList(AsyncGenerator<NodeOutput> generator) {\n\t\treturn generator.stream().filter(s -> {\n\t\t\tif (s instanceof StreamingOutput streamingOutput) {\n\t\t\t\tSystem.out\n\t\t\t\t\t.println(String.format(\"stream data %s '%s'\", streamingOutput.node(), streamingOutput.chunk()));\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\treturn true;\n\t\t})\n\t\t\t.peek(s -> System.out.println(String.format(\"NODE: %s\", s.node())))\n\t\t\t.map(NodeOutput::state)\n\t\t\t.collect(java.util.stream.Collectors.toList());\n\t}\n\n\t@Test\n\t@Tag(\"integration\")\n\t@EnabledIfEnvironmentVariable(named = \"AI_DASHSCOPE_API_KEY\", matches = \".+\")\n\tpublic void testParallelNodeStream() throws Exception {\n\t\tStateGraph stateGraph = new StateGraph(() -> {\n\t\t\tMap<String, KeyStrategy> keyStrategyMap = new HashMap<>();\n\t\t\tkeyStrategyMap.put(\"messages\", new AppendStrategy());\n\t\t\tkeyStrategyMap.put(\"llm_result\", new AppendStrategy());\n\t\t\tkeyStrategyMap.put(\"input\", new ReplaceStrategy());\n\t\t\treturn keyStrategyMap;\n\t\t}).addNode(\"llmNode\", node_async(new LLmNodeAction(chatModel, \"llmNode\")))\n\t\t\t.addNode(\"llmNode2\", node_async(new LLmNodeAction(chatModel, \"llmNode2\")))\n\t\t\t.addNode(\"result\", node_async((t) -> Map.of(\"llm_result\", \"llm_result\")))\n\t\t\t.addNode(\"toolNode\", node_async((t) -> Map.of(\"messages\", \"tool call result\")))\n\t\t\t.addEdge(START, \"llmNode\")\n\t\t\t.addEdge(START, \"llmNode2\")\n\t\t\t.addEdge(START, \"result\")\n\t\t\t.addEdge(\"llmNode\", \"toolNode\")\n\t\t\t.addEdge(\"llmNode2\", \"toolNode\")\n\t\t\t.addEdge(\"toolNode\", END);\n\n\t\tCompiledGraph compile = stateGraph.compile();\n\n\t\tfor (var output : compile.stream(Map.of(OverAllState.DEFAULT_INPUT_KEY, \"给我写一个10字的小文章\"),\n\t\t\t\tRunnableConfig.builder().addParallelNodeExecutor(START, ForkJoinPool.commonPool()).build())) {\n\t\t\tif (output instanceof AsyncGenerator<?>) {\n\t\t\t\tAsyncGenerator asyncGenerator = (AsyncGenerator) output;\n\t\t\t\tSystem.out.println(\"Streaming chunk: \" + asyncGenerator);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tSystem.out.println(\"Node output: \" + output);\n\t\t\t}\n\t\t}\n\n\t}\n\n}", "metadata": {"commit_sha": "d5cc0159", "lines_added": 2, "lines_deleted": 2, "total_changes": 4, "chunks": 2}}
{"id": 98, "pattern_type": "getter_setter", "file_path": "community/vector-stores/spring-ai-alibaba-starter-oceanbase-store/src/main/java/com/alibaba/cloud/ai/vectorstore/oceanbase/OceanBaseVectorStore.java", "file_extension": "java", "input": "/*\n * Copyright 2024-2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.alibaba.cloud.ai.vectorstore.oceanbase;\n\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport com.fasterxml.jackson.core.type.TypeReference;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.fasterxml.jackson.databind.json.JsonMapper;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.ai.document.Document;\nimport org.springframework.ai.embedding.EmbeddingModel;\nimport org.springframework.ai.embedding.EmbeddingOptionsBuilder;\nimport org.springframework.ai.util.JacksonUtils;\nimport org.springframework.ai.vectorstore.AbstractVectorStoreBuilder;\nimport org.springframework.ai.vectorstore.SearchRequest;\nimport org.springframework.ai.vectorstore.filter.Filter;\nimport org.springframework.ai.vectorstore.filter.FilterExpressionConverter;\nimport org.springframework.ai.vectorstore.observation.AbstractObservationVectorStore;\nimport org.springframework.ai.vectorstore.observation.VectorStoreObservationContext;\nimport org.springframework.beans.factory.InitializingBean;\nimport org.springframework.util.Assert;\nimport org.springframework.util.CollectionUtils;\n\nimport javax.sql.DataSource;\n\nimport java.sql.Connection;\nimport java.sql.PreparedStatement;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\nimport java.util.*;\nimport java.util.stream.IntStream;\n\nimport static org.springframework.ai.vectorstore.SearchRequest.DEFAULT_TOP_K;\n\npublic class OceanBaseVectorStore extends AbstractObservationVectorStore implements InitializingBean {\n\n\tprivate static final Logger logger = LoggerFactory.getLogger(OceanBaseVectorStore.class);\n\n\tprivate static final String DATA_BASE_SYSTEM = \"oceanbase\";\n\n\tprivate static final String REF_DOC_NAME = \"refDocId\";\n\n\tprivate static final String METADATA_FIELD_NAME = \"metadata\";\n\n\tprivate static final String CONTENT_FIELD_NAME = \"content\";\n\n\tprivate static final String DOC_NAME = \"docId\";\n\n\tprivate static final Double DEFAULT_SIMILARITY_THRESHOLD = 0.0;\n\n\tprivate static final String CREATE_TABLE_SQL_TEMPLATE = \"CREATE TABLE IF NOT EXISTS %s (\"\n\t\t\t+ \"id BIGINT PRIMARY KEY, \" + \"vector VECTOR(384) NOT NULL, \" + \"description text, \" + \"metadata text)\";\n\n\tprivate static final String INSERT_DOC_SQL_TEMPLATE = \"INSERT INTO %s (id, vector, description, metadata) VALUES (?, ?, ?, ?)\";\n\n\tprivate static final String DELETE_DOC_SQL_TEMPLATE = \"DELETE FROM %s WHERE id = ?\";\n\n\tprivate static final String DELETE_DOC_BY_FILTER_SQL_TEMPLATE = \"DELETE FROM %s WHERE %s\";\n\n\tprivate static final String SIMILARITY_SEARCH_SQL_TEMPLATE = \"SELECT id, vector, description, metadata, l2_distance(vector,?) as distance FROM %s \"\n\t\t\t+ \"ORDER BY vector_distance(vector, ?) ASC LIMIT ?\";\n\n\tpublic final FilterExpressionConverter filterExpressionConverter = new OceanBaseVectorFilterExpressionConverter();\n\n\tprivate final String tableName;\n\n\tprivate final Integer defaultTopK;\n\n\tprivate final Double defaultSimilarityThreshold;\n\n\tprivate final DataSource dataSource;\n\n\tprivate final ObjectMapper objectMapper;\n\n\tprotected OceanBaseVectorStore(Builder builder) {\n\t\tsuper(builder);\n\t\tthis.tableName = builder.tableName;\n\t\tthis.dataSource = builder.dataSource;\n\t\tthis.objectMapper = JsonMapper.builder().addModules(JacksonUtils.instantiateAvailableModules()).build();\n\t\tthis.defaultSimilarityThreshold = builder.defaultSimilarityThreshold;\n\t\tthis.defaultTopK = builder.defaultTopK;\n\t}\n\n\tpublic static Builder builder(String tableName, DataSource dataSource, EmbeddingModel embeddingModel) {\n\t\treturn new Builder(tableName, dataSource, embeddingModel);\n\t}\n\n\t@Override\n\tpublic void afterPropertiesSet() {\n\t\tinitializeDatabase();\n\t}\n\n\tprivate void initializeDatabase() {\n\t\texecuteUpdate(String.format(CREATE_TABLE_SQL_TEMPLATE, tableName));\n\t\tlogger.debug(\"Successfully created or verified table: {}\", tableName);\n\t}\n\n\t@Override\n\tpublic void doAdd(List<Document> documents) {\n\t\tAssert.notNull(documents, \"The document list should not be null.\");\n\t\tif (CollectionUtils.isEmpty(documents)) {\n\t\t\treturn;\n\t\t}\n\t\tList<float[]> embeddings = this.embeddingModel.embed(documents, EmbeddingOptionsBuilder.builder().build(),\n\t\t\t\tthis.batchingStrategy);\n\t\tString sql = String.format(INSERT_DOC_SQL_TEMPLATE, tableName);\n\t\ttry (Connection connection = dataSource.getConnection();\n\t\t\t\tPreparedStatement pstmt = connection.prepareStatement(sql)) {\n\t\t\tfor (int i = 0; i < documents.size(); i++) {\n\t\t\t\tDocument doc = documents.get(i);\n\t\t\t\tMap<String, String> metadata = createMetadata(doc);\n\t\t\t\tString vectorString = convertEmbeddingToString(embeddings.get(i));\n\t\t\t\tpstmt.setLong(1, Long.parseLong(doc.getId()));\n\t\t\t\tpstmt.setString(2, vectorString);\n\t\t\t\tpstmt.setString(3, doc.getText());\n\t\t\t\tpstmt.setString(4, objectMapper.writeValueAsString(metadata));\n\t\t\t\tpstmt.addBatch();\n\t\t\t}\n\t\t\tpstmt.executeBatch();\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlogger.error(\"Failed to add documents\", e);\n\t\t\tthrow new RuntimeException(\"Failed to add documents to OceanBase\", e);\n\t\t}\n\t}\n\n\tprivate Map<String, String> createMetadata(Document doc) throws JsonProcessingException {\n\t\tMap<String, String> metadata = new HashMap<>();\n\t\tString refDocId = Optional.ofNullable(doc.getMetadata().get(DOC_NAME))\n\t\t\t.map(Object::toString)\n\t\t\t.orElse(doc.getId());\n\t\tmetadata.put(REF_DOC_NAME, refDocId);\n\t\tmetadata.put(CONTENT_FIELD_NAME, doc.getText());\n\t\tmetadata.put(METADATA_FIELD_NAME, objectMapper.writeValueAsString(doc.getMetadata()));\n\t\treturn metadata;\n\t}\n\n\tprivate String convertEmbeddingToString(float[] embedding) {\n\t\treturn Arrays.toString(IntStream.range(0, embedding.length).mapToObj(i -> embedding[i]).toArray());\n\t}\n\n\t@Override\n\tpublic void doDelete(List<String> ids) {\n\t\tif (CollectionUtils.isEmpty(ids)) {\n\t\t\treturn;\n\t\t}\n\t\texecuteBatchUpdate(String.format(DELETE_DOC_SQL_TEMPLATE, tableName), ids);\n\t}\n\n\t@Override\n\tpublic void doDelete(Filter.Expression filterExpression) {\n\t\tString nativeFilterExpression = filterExpressionConverter.convertExpression(filterExpression);\n\t\texecuteUpdate(String.format(DELETE_DOC_BY_FILTER_SQL_TEMPLATE, tableName, nativeFilterExpression));\n\t}\n\n\t@Override\n\tpublic List<Document> similaritySearch(String query) {\n\t\treturn this.similaritySearch(SearchRequest.builder()\n\t\t\t.query(query)\n\t\t\t.topK(this.defaultTopK)\n\t\t\t.similarityThreshold(this.defaultSimilarityThreshold)\n\t\t\t.build());\n\t}\n\n\t@Override\n\tpublic List<Document> doSimilaritySearch(SearchRequest searchRequest) {\n\t\tString sql = String.format(SIMILARITY_SEARCH_SQL_TEMPLATE, tableName);\n\t\tList<Document> similarDocuments = new ArrayList<>();\n\t\ttry (Connection connection = dataSource.getConnection();\n\t\t\t\tPreparedStatement pstmt = connection.prepareStatement(sql)) {\n\t\t\tString vector = convertQueryToVectorBytes(searchRequest.getQuery());\n\t\t\tpstmt.setString(1, vector);\n\t\t\tpstmt.setString(2, vector);\n\t\t\tpstmt.setInt(3, searchRequest.getTopK());\n\t\t\tResultSet rs = pstmt.executeQuery();\n\t\t\twhile (rs.next()) {\n\t\t\t\tDocument doc = extractDocumentFromResultSet(rs);\n\t\t\t\tsimilarDocuments.add(doc);\n\t\t\t}\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlogger.error(\"Failed to perform similarity search\", e);\n\t\t\tthrow new RuntimeException(\"Failed to perform similarity search in OceanBase\", e);\n\t\t}\n\t\treturn similarDocuments;\n\t}\n\n\tprivate Document extractDocumentFromResultSet(ResultSet rs) throws SQLException, JsonProcessingException {\n\t\tlong id = rs.getLong(\"id\");\n\t\tString vectorMetadata = rs.getString(\"metadata\");\n\t\tString distance = rs.getString(\"distance\");\n\t\tMap<String, String> metadata = extractMetadata(vectorMetadata);\n\t\tString pageContent = metadata.get(CONTENT_FIELD_NAME);\n\t\tMap<String, Object> metadataJson = objectMapper.readValue(metadata.get(METADATA_FIELD_NAME),\n\t\t\t\tnew TypeReference<Map<String, Object>>() {\n\t\t\t\t});\n\t\tmetadataJson.put(\"distance\", distance);\n\t\treturn new Document(String.valueOf(id), pageContent, metadataJson);\n\t}\n\n\tprivate Map<String, String> extractMetadata(String vectorStr) throws JsonProcessingException {\n\t\treturn objectMapper.readValue(vectorStr, Map.class);\n\t}\n\n\tprivate String convertQueryToVectorBytes(String query) {\n\t\treturn Arrays.toString(this.embeddingModel.embed(query));\n\t}\n\n\tprivate void executeUpdate(String sql) {\n\t\ttry (Connection connection = dataSource.getConnection();\n\t\t\t\tPreparedStatement pstmt = connection.prepareStatement(sql)) {\n\t\t\tpstmt.execute();\n\t\t}\n\t\tcatch (SQLException e) {\n\t\t\tlogger.error(\"SQL execution failed\", e);\n\t\t\tthrow new RuntimeException(\"Failed to execute SQL\", e);\n\t\t}\n\t}\n\n\tprivate void executeBatchUpdate(String sql, List<String> params) {\n\t\ttry (Connection connection = dataSource.getConnection();\n\t\t\t\tPreparedStatement pstmt = connection.prepareStatement(sql)) {\n\t\t\tfor (String param : params) {\n\t\t\t\tpstmt.setLong(1, Long.parseLong(param));\n\t\t\t\tpstmt.addBatch();\n\t\t\t}\n\t\t\tpstmt.executeBatch();\n\t\t}\n\t\tcatch (SQLException e) {\n\t\t\tlogger.error(\"Batch SQL execution failed\", e);\n\t\t\tthrow new RuntimeException(\"Failed to execute batch SQL\", e);\n\t\t}\n\t}\n\n\t@Override\n\tpublic VectorStoreObservationContext.Builder createObservationContextBuilder(String operationName) {\n\t\treturn VectorStoreObservationContext.builder(DATA_BASE_SYSTEM, operationName)\n\t\t\t.collectionName(this.tableName)\n\t\t\t.dimensions(this.embeddingModel.dimensions());\n\t}\n\n\tpublic static class Builder extends AbstractVectorStoreBuilder<Builder> {\n\n\t\tprivate final String tableName;\n\n\t\tprivate final DataSource dataSource;\n\n\t\tprivate int defaultTopK = DEFAULT_TOP_K;\n\n\t\tprivate Double defaultSimilarityThreshold = DEFAULT_SIMILARITY_THRESHOLD;\n\n\t\tprivate Builder(String tableName, DataSource dataSource, EmbeddingModel embeddingModel) {\n\t\t\tsuper(embeddingModel);\n\t\t\tAssert.notNull(tableName, \"Table name must not be null\");\n\t\t\tAssert.notNull(dataSource, \"Data source must not be null\");\n\t\t\tthis.tableName = tableName.toLowerCase();\n\t\t\tthis.dataSource = dataSource;\n\t\t}\n\n\t\tpublic Builder defaultTopK(int defaultTopK) {\n\t\t\tAssert.isTrue(defaultTopK >= 0, \"The topK should be positive value.\");\n\t\t\tthis.defaultTopK = defaultTopK;\n\t\t\treturn this;\n\t\t}\n\n\t\tpublic Builder defaultSimilarityThreshold(Double defaultSimilarityThreshold) {\n\t\t\tAssert.isTrue(defaultSimilarityThreshold >= 0.0 && defaultSimilarityThreshold <= 1.0,\n\t\t\t\t\t\"The similarity threshold must be in range [0.0:1.0].\");\n\t\t\tthis.defaultSimilarityThreshold = defaultSimilarityThreshold;\n\t\t\treturn this;\n\t\t}\n\n\t\t@Override\n\t\tpublic OceanBaseVectorStore build() {\n\t\t\ttry {\n\t\t\t\treturn new OceanBaseVectorStore(this);\n\t\t\t}\n\t\t\tcatch (Exception e) {\n\t\t\t\tthrow new RuntimeException(\"Failed to build OceanBaseVectorStore: \" + e.getMessage(), e);\n\t\t\t}\n\t\t}\n\n\t}\n\n}", "output": "/*\n * Copyright 2024-2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.alibaba.cloud.ai.vectorstore.oceanbase;\n\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport com.fasterxml.jackson.core.type.TypeReference;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.fasterxml.jackson.databind.json.JsonMapper;\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.ai.document.Document;\nimport org.springframework.ai.embedding.EmbeddingModel;\nimport org.springframework.ai.embedding.EmbeddingOptionsBuilder;\nimport org.springframework.ai.util.JacksonUtils;\nimport org.springframework.ai.vectorstore.AbstractVectorStoreBuilder;\nimport org.springframework.ai.vectorstore.SearchRequest;\nimport org.springframework.ai.vectorstore.filter.Filter;\nimport org.springframework.ai.vectorstore.filter.FilterExpressionConverter;\nimport org.springframework.ai.vectorstore.observation.AbstractObservationVectorStore;\nimport org.springframework.ai.vectorstore.observation.VectorStoreObservationContext;\nimport org.springframework.beans.factory.InitializingBean;\nimport org.springframework.util.Assert;\nimport org.springframework.util.CollectionUtils;\n\nimport javax.sql.DataSource;\n\nimport java.sql.Connection;\nimport java.sql.PreparedStatement;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\nimport java.util.*;\nimport java.util.stream.IntStream;\n\nimport static org.springframework.ai.vectorstore.SearchRequest.DEFAULT_TOP_K;\n\npublic class OceanBaseVectorStore extends AbstractObservationVectorStore implements InitializingBean {\n\n\tprivate static final Logger logger = LoggerFactory.getLogger(OceanBaseVectorStore.class);\n\n\tprivate static final String DATA_BASE_SYSTEM = \"oceanbase\";\n\n\tprivate static final String REF_DOC_NAME = \"refDocId\";\n\n\tprivate static final String METADATA_FIELD_NAME = \"metadata\";\n\n\tprivate static final String CONTENT_FIELD_NAME = \"content\";\n\n\tprivate static final String DOC_NAME = \"docId\";\n\n\tprivate static final Double DEFAULT_SIMILARITY_THRESHOLD = 0.0;\n\n\tprivate static final String CREATE_TABLE_SQL_TEMPLATE = \"CREATE TABLE IF NOT EXISTS %s (\"\n\t\t\t+ \"id varchar(100) PRIMARY KEY, \" + \"vector VECTOR(384) NOT NULL, \" + \"description text, \"\n\t\t\t+ \"metadata text)\";\n\n\tprivate static final String INSERT_DOC_SQL_TEMPLATE = \"INSERT INTO %s (id, vector, description, metadata) VALUES (?, ?, ?, ?)\";\n\n\tprivate static final String DELETE_DOC_SQL_TEMPLATE = \"DELETE FROM %s WHERE id = ?\";\n\n\tprivate static final String DELETE_DOC_BY_FILTER_SQL_TEMPLATE = \"DELETE FROM %s WHERE %s\";\n\n\tprivate static final String SIMILARITY_SEARCH_SQL_TEMPLATE = \"SELECT id, vector, description, metadata, l2_distance(vector,?) as distance FROM %s \"\n\t\t\t+ \"ORDER BY vector_distance(vector, ?) ASC LIMIT ?\";\n\n\tpublic final FilterExpressionConverter filterExpressionConverter = new OceanBaseVectorFilterExpressionConverter();\n\n\tprivate final String tableName;\n\n\tprivate final Integer defaultTopK;\n\n\tprivate final Double defaultSimilarityThreshold;\n\n\tprivate final DataSource dataSource;\n\n\tprivate final ObjectMapper objectMapper;\n\n\tprotected OceanBaseVectorStore(Builder builder) {\n\t\tsuper(builder);\n\t\tthis.tableName = builder.tableName;\n\t\tthis.dataSource = builder.dataSource;\n\t\tthis.objectMapper = JsonMapper.builder().addModules(JacksonUtils.instantiateAvailableModules()).build();\n\t\tthis.defaultSimilarityThreshold = builder.defaultSimilarityThreshold;\n\t\tthis.defaultTopK = builder.defaultTopK;\n\t}\n\n\tpublic static Builder builder(String tableName, DataSource dataSource, EmbeddingModel embeddingModel) {\n\t\treturn new Builder(tableName, dataSource, embeddingModel);\n\t}\n\n\t@Override\n\tpublic void afterPropertiesSet() {\n\t\tinitializeDatabase();\n\t}\n\n\tprivate void initializeDatabase() {\n\t\texecuteUpdate(String.format(CREATE_TABLE_SQL_TEMPLATE, tableName));\n\t\tlogger.debug(\"Successfully created or verified table: {}\", tableName);\n\t}\n\n\t@Override\n\tpublic void doAdd(List<Document> documents) {\n\t\tAssert.notNull(documents, \"The document list should not be null.\");\n\t\tif (CollectionUtils.isEmpty(documents)) {\n\t\t\treturn;\n\t\t}\n\t\tList<float[]> embeddings = this.embeddingModel.embed(documents, EmbeddingOptionsBuilder.builder().build(),\n\t\t\t\tthis.batchingStrategy);\n\t\tString sql = String.format(INSERT_DOC_SQL_TEMPLATE, tableName);\n\t\ttry (Connection connection = dataSource.getConnection();\n\t\t\t\tPreparedStatement pstmt = connection.prepareStatement(sql)) {\n\t\t\tfor (int i = 0; i < documents.size(); i++) {\n\t\t\t\tDocument doc = documents.get(i);\n\t\t\t\tMap<String, String> metadata = createMetadata(doc);\n\t\t\t\tString vectorString = convertEmbeddingToString(embeddings.get(i));\n\t\t\t\tpstmt.setString(1, doc.getId());\n\t\t\t\tpstmt.setString(2, vectorString);\n\t\t\t\tpstmt.setString(3, doc.getText());\n\t\t\t\tpstmt.setString(4, objectMapper.writeValueAsString(metadata));\n\t\t\t\tpstmt.addBatch();\n\t\t\t}\n\t\t\tpstmt.executeBatch();\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlogger.error(\"Failed to add documents\", e);\n\t\t\tthrow new RuntimeException(\"Failed to add documents to OceanBase\", e);\n\t\t}\n\t}\n\n\tprivate Map<String, String> createMetadata(Document doc) throws JsonProcessingException {\n\t\tMap<String, String> metadata = new HashMap<>();\n\t\tString refDocId = Optional.ofNullable(doc.getMetadata().get(DOC_NAME))\n\t\t\t.map(Object::toString)\n\t\t\t.orElse(doc.getId());\n\t\tmetadata.put(REF_DOC_NAME, refDocId);\n\t\tmetadata.put(CONTENT_FIELD_NAME, doc.getText());\n\t\tmetadata.put(METADATA_FIELD_NAME, objectMapper.writeValueAsString(doc.getMetadata()));\n\t\treturn metadata;\n\t}\n\n\tprivate String convertEmbeddingToString(float[] embedding) {\n\t\treturn Arrays.toString(IntStream.range(0, embedding.length).mapToObj(i -> embedding[i]).toArray());\n\t}\n\n\t@Override\n\tpublic void doDelete(List<String> ids) {\n\t\tif (CollectionUtils.isEmpty(ids)) {\n\t\t\treturn;\n\t\t}\n\t\texecuteBatchUpdate(String.format(DELETE_DOC_SQL_TEMPLATE, tableName), ids);\n\t}\n\n\t@Override\n\tpublic void doDelete(Filter.Expression filterExpression) {\n\t\tString nativeFilterExpression = filterExpressionConverter.convertExpression(filterExpression);\n\t\texecuteUpdate(String.format(DELETE_DOC_BY_FILTER_SQL_TEMPLATE, tableName, nativeFilterExpression));\n\t}\n\n\t@Override\n\tpublic List<Document> similaritySearch(String query) {\n\t\treturn this.similaritySearch(SearchRequest.builder()\n\t\t\t.query(query)\n\t\t\t.topK(this.defaultTopK)\n\t\t\t.similarityThreshold(this.defaultSimilarityThreshold)\n\t\t\t.build());\n\t}\n\n\t@Override\n\tpublic List<Document> doSimilaritySearch(SearchRequest searchRequest) {\n\t\tString sql = String.format(SIMILARITY_SEARCH_SQL_TEMPLATE, tableName);\n\t\tList<Document> similarDocuments = new ArrayList<>();\n\t\ttry (Connection connection = dataSource.getConnection();\n\t\t\t\tPreparedStatement pstmt = connection.prepareStatement(sql)) {\n\t\t\tString vector = convertQueryToVectorBytes(searchRequest.getQuery());\n\t\t\tpstmt.setString(1, vector);\n\t\t\tpstmt.setString(2, vector);\n\t\t\tpstmt.setInt(3, searchRequest.getTopK());\n\t\t\tResultSet rs = pstmt.executeQuery();\n\t\t\twhile (rs.next()) {\n\t\t\t\tDocument doc = extractDocumentFromResultSet(rs);\n\t\t\t\tsimilarDocuments.add(doc);\n\t\t\t}\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlogger.error(\"Failed to perform similarity search\", e);\n\t\t\tthrow new RuntimeException(\"Failed to perform similarity search in OceanBase\", e);\n\t\t}\n\t\treturn similarDocuments;\n\t}\n\n\tprivate Document extractDocumentFromResultSet(ResultSet rs) throws SQLException, JsonProcessingException {\n\t\tString id = rs.getString(\"id\");\n\t\tString vectorMetadata = rs.getString(\"metadata\");\n\t\tString distance = rs.getString(\"distance\");\n\t\tMap<String, String> metadata = extractMetadata(vectorMetadata);\n\t\tString pageContent = metadata.get(CONTENT_FIELD_NAME);\n\t\tMap<String, Object> metadataJson = objectMapper.readValue(metadata.get(METADATA_FIELD_NAME),\n\t\t\t\tnew TypeReference<Map<String, Object>>() {\n\t\t\t\t});\n\t\tmetadataJson.put(\"distance\", distance);\n\t\treturn new Document(String.valueOf(id), pageContent, metadataJson);\n\t}\n\n\tprivate Map<String, String> extractMetadata(String vectorStr) throws JsonProcessingException {\n\t\treturn objectMapper.readValue(vectorStr, Map.class);\n\t}\n\n\tprivate String convertQueryToVectorBytes(String query) {\n\t\treturn Arrays.toString(this.embeddingModel.embed(query));\n\t}\n\n\tprivate void executeUpdate(String sql) {\n\t\ttry (Connection connection = dataSource.getConnection();\n\t\t\t\tPreparedStatement pstmt = connection.prepareStatement(sql)) {\n\t\t\tpstmt.execute();\n\t\t}\n\t\tcatch (SQLException e) {\n\t\t\tlogger.error(\"SQL execution failed\", e);\n\t\t\tthrow new RuntimeException(\"Failed to execute SQL\", e);\n\t\t}\n\t}\n\n\tprivate void executeBatchUpdate(String sql, List<String> params) {\n\t\ttry (Connection connection = dataSource.getConnection();\n\t\t\t\tPreparedStatement pstmt = connection.prepareStatement(sql)) {\n\t\t\tfor (String param : params) {\n\t\t\t\tpstmt.setLong(1, Long.parseLong(param));\n\t\t\t\tpstmt.addBatch();\n\t\t\t}\n\t\t\tpstmt.executeBatch();\n\t\t}\n\t\tcatch (SQLException e) {\n\t\t\tlogger.error(\"Batch SQL execution failed\", e);\n\t\t\tthrow new RuntimeException(\"Failed to execute batch SQL\", e);\n\t\t}\n\t}\n\n\t@Override\n\tpublic VectorStoreObservationContext.Builder createObservationContextBuilder(String operationName) {\n\t\treturn VectorStoreObservationContext.builder(DATA_BASE_SYSTEM, operationName)\n\t\t\t.collectionName(this.tableName)\n\t\t\t.dimensions(this.embeddingModel.dimensions());\n\t}\n\n\tpublic static class Builder extends AbstractVectorStoreBuilder<Builder> {\n\n\t\tprivate final String tableName;\n\n\t\tprivate final DataSource dataSource;\n\n\t\tprivate int defaultTopK = DEFAULT_TOP_K;\n\n\t\tprivate Double defaultSimilarityThreshold = DEFAULT_SIMILARITY_THRESHOLD;\n\n\t\tprivate Builder(String tableName, DataSource dataSource, EmbeddingModel embeddingModel) {\n\t\t\tsuper(embeddingModel);\n\t\t\tAssert.notNull(tableName, \"Table name must not be null\");\n\t\t\tAssert.notNull(dataSource, \"Data source must not be null\");\n\t\t\tthis.tableName = tableName.toLowerCase();\n\t\t\tthis.dataSource = dataSource;\n\t\t}\n\n\t\tpublic Builder defaultTopK(int defaultTopK) {\n\t\t\tAssert.isTrue(defaultTopK >= 0, \"The topK should be positive value.\");\n\t\t\tthis.defaultTopK = defaultTopK;\n\t\t\treturn this;\n\t\t}\n\n\t\tpublic Builder defaultSimilarityThreshold(Double defaultSimilarityThreshold) {\n\t\t\tAssert.isTrue(defaultSimilarityThreshold >= 0.0 && defaultSimilarityThreshold <= 1.0,\n\t\t\t\t\t\"The similarity threshold must be in range [0.0:1.0].\");\n\t\t\tthis.defaultSimilarityThreshold = defaultSimilarityThreshold;\n\t\t\treturn this;\n\t\t}\n\n\t\t@Override\n\t\tpublic OceanBaseVectorStore build() {\n\t\t\ttry {\n\t\t\t\treturn new OceanBaseVectorStore(this);\n\t\t\t}\n\t\t\tcatch (Exception e) {\n\t\t\t\tthrow new RuntimeException(\"Failed to build OceanBaseVectorStore: \" + e.getMessage(), e);\n\t\t\t}\n\t\t}\n\n\t}\n\n}", "metadata": {"commit_sha": "fb71ce7f", "lines_added": 5, "lines_deleted": 4, "total_changes": 9, "chunks": 4}}
{"id": 39, "pattern_type": "refactoring", "file_path": "spring-ai-alibaba-core/src/main/java/com/alibaba/cloud/ai/dashscope/chat/DashScopeChatModel.java", "file_extension": "java", "input": "/*\n * Copyright 2024-2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.alibaba.cloud.ai.dashscope.chat;\n\nimport java.util.ArrayList;\nimport java.util.Base64;\nimport java.util.HashSet;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.concurrent.ConcurrentHashMap;\n\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi.ChatCompletion;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi.ChatCompletionChunk;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi.ChatCompletionFinishReason;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi.ChatCompletionMessage;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi.ChatCompletionMessage.ChatCompletionFunction;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi.ChatCompletionMessage.MediaContent;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi.ChatCompletionMessage.ToolCall;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi.ChatCompletionOutput;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi.ChatCompletionOutput.Choice;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi.ChatCompletionRequest;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi.ChatCompletionRequestInput;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi.ChatCompletionRequestParameter;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi.FunctionTool;\nimport com.alibaba.cloud.ai.dashscope.chat.observation.DashScopeChatModelObservationConvention;\nimport com.alibaba.cloud.ai.dashscope.common.DashScopeApiConstants;\nimport com.alibaba.cloud.ai.dashscope.metadata.DashScopeAiUsage;\nimport io.micrometer.observation.Observation;\nimport io.micrometer.observation.ObservationRegistry;\nimport io.micrometer.observation.contextpropagation.ObservationThreadLocalAccessor;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport reactor.core.publisher.Flux;\nimport reactor.core.publisher.Mono;\n\nimport org.springframework.ai.chat.messages.AssistantMessage;\nimport org.springframework.ai.chat.messages.MessageType;\nimport org.springframework.ai.chat.messages.ToolResponseMessage;\nimport org.springframework.ai.chat.messages.UserMessage;\nimport org.springframework.ai.chat.metadata.ChatGenerationMetadata;\nimport org.springframework.ai.chat.metadata.ChatResponseMetadata;\nimport org.springframework.ai.chat.model.AbstractToolCallSupport;\nimport org.springframework.ai.chat.model.ChatModel;\nimport org.springframework.ai.chat.model.ChatResponse;\nimport org.springframework.ai.chat.model.Generation;\nimport org.springframework.ai.chat.model.MessageAggregator;\nimport org.springframework.ai.chat.observation.ChatModelObservationContext;\nimport org.springframework.ai.chat.observation.ChatModelObservationConvention;\nimport org.springframework.ai.chat.observation.ChatModelObservationDocumentation;\nimport org.springframework.ai.chat.prompt.ChatOptions;\nimport org.springframework.ai.chat.prompt.Prompt;\nimport org.springframework.ai.model.ModelOptionsUtils;\nimport org.springframework.ai.model.function.FunctionCallback;\nimport org.springframework.ai.model.function.FunctionCallbackResolver;\nimport org.springframework.ai.retry.RetryUtils;\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.retry.support.RetryTemplate;\nimport org.springframework.util.Assert;\nimport org.springframework.util.CollectionUtils;\nimport org.springframework.util.MimeType;\n\n/**\n * {@link ChatModel} implementation for {@literal Alibaba DashScope} backed by\n * {@link Generation}.\n *\n * @author yuluo\n * @author <a href=\"mailto:yuluo08290126@gmail.com\">yuluo</a>\n * @see ChatModel\n * @see com.alibaba.dashscope.aigc.generation\n */\npublic class DashScopeChatModel extends AbstractToolCallSupport implements ChatModel {\n\n\tpublic static final String MESSAGE_FORMAT = \"messageFormat\";\n\n\tprivate static final Logger logger = LoggerFactory.getLogger(DashScopeChatModel.class);\n\n\tprivate static final ChatModelObservationConvention DEFAULT_OBSERVATION_CONVENTION = new DashScopeChatModelObservationConvention();\n\n\t/** Low-level access to the DashScope API */\n\tprivate final DashScopeApi dashscopeApi;\n\n\t/** The retry template used to retry the OpenAI API calls. */\n\tpublic final RetryTemplate retryTemplate;\n\n\t/**\n\t * Observation registry used for instrumentation.\n\t */\n\tprivate final ObservationRegistry observationRegistry;\n\n\t/** The default options used for the chat completion requests. */\n\tprivate DashScopeChatOptions defaultOptions;\n\n\t/**\n\t * Conventions to use for generating observations.\n\t */\n\tprivate ChatModelObservationConvention observationConvention = DEFAULT_OBSERVATION_CONVENTION;\n\n\tpublic DashScopeChatModel(DashScopeApi dashscopeApi) {\n\t\tthis(dashscopeApi,\n\t\t\t\tDashScopeChatOptions.builder()\n\t\t\t\t\t.withModel(DashScopeApi.DEFAULT_CHAT_MODEL)\n\t\t\t\t\t.withTemperature(0.7d)\n\t\t\t\t\t.build());\n\t}\n\n\tpublic DashScopeChatModel(DashScopeApi dashscopeApi, DashScopeChatOptions options) {\n\t\tthis(dashscopeApi, options, null, RetryUtils.DEFAULT_RETRY_TEMPLATE);\n\t}\n\n\tpublic DashScopeChatModel(DashScopeApi dashscopeApi, DashScopeChatOptions options,\n\t\t\tFunctionCallbackResolver functionCallbackResolver, RetryTemplate retryTemplate) {\n\t\tthis(dashscopeApi, options, functionCallbackResolver, List.of(), retryTemplate);\n\t}\n\n\tpublic DashScopeChatModel(DashScopeApi dashscopeApi, DashScopeChatOptions options,\n\t\t\tFunctionCallbackResolver functionCallbackResolver, List<FunctionCallback> toolFunctionCallbacks,\n\t\t\tRetryTemplate retryTemplate) {\n\n\t\tthis(dashscopeApi, options, functionCallbackResolver, toolFunctionCallbacks, retryTemplate,\n\t\t\t\tObservationRegistry.NOOP);\n\t}\n\n\tpublic DashScopeChatModel(DashScopeApi dashscopeApi, DashScopeChatOptions options,\n\t\t\tFunctionCallbackResolver functionCallbackResolver, List<FunctionCallback> toolFunctionCallbacks,\n\t\t\tRetryTemplate retryTemplate, ObservationRegistry observationRegistry) {\n\n\t\tsuper(functionCallbackResolver, options, toolFunctionCallbacks);\n\n\t\tAssert.notNull(dashscopeApi, \"DashScopeApi must not be null\");\n\t\tAssert.notNull(options, \"Options must not be null\");\n\t\tAssert.notNull(retryTemplate, \"RetryTemplate must not be null\");\n\t\tAssert.isTrue(CollectionUtils.isEmpty(options.getFunctionCallbacks()),\n\t\t\t\t\"The default function callbacks must be set via the toolFunctionCallbacks constructor parameter\");\n\t\tAssert.notNull(observationRegistry, \"ObservationRegistry must not be null\");\n\n\t\tthis.dashscopeApi = dashscopeApi;\n\t\tthis.defaultOptions = options;\n\t\tthis.retryTemplate = retryTemplate;\n\t\tthis.observationRegistry = observationRegistry;\n\t}\n\n\t@Override\n\tpublic ChatResponse call(Prompt prompt) {\n\n\t\tChatModelObservationContext observationContext = ChatModelObservationContext.builder()\n\t\t\t.prompt(prompt)\n\t\t\t.provider(DashScopeApiConstants.PROVIDER_NAME)\n\t\t\t.requestOptions(prompt.getOptions() != null ? prompt.getOptions() : this.defaultOptions)\n\t\t\t.build();\n\n\t\tChatResponse chatResponse = ChatModelObservationDocumentation.CHAT_MODEL_OPERATION\n\t\t\t.observation(this.observationConvention, DEFAULT_OBSERVATION_CONVENTION, () -> observationContext,\n\t\t\t\t\tthis.observationRegistry)\n\t\t\t.observe(() -> {\n\t\t\t\tDashScopeApi.ChatCompletionRequest request = createRequest(prompt, false);\n\n\t\t\t\tResponseEntity<ChatCompletion> completionEntity = this.retryTemplate\n\t\t\t\t\t.execute(ctx -> this.dashscopeApi.chatCompletionEntity(request));\n\n\t\t\t\tvar chatCompletion = completionEntity.getBody();\n\n\t\t\t\tif (chatCompletion == null) {\n\t\t\t\t\tlogger.warn(\"No chat completion returned for prompt: {}\", prompt);\n\t\t\t\t\treturn new ChatResponse(List.of());\n\t\t\t\t}\n\n\t\t\t\tList<ChatCompletionOutput.Choice> choices = chatCompletion.output().choices();\n\n\t\t\t\tList<Generation> generations = choices.stream().map(choice -> {\n\t\t\t// @formatter:off\n\t\t\t\t\t\tMap<String, Object> metadata = Map.of(\n\t\t\t\t\t\t\t\t\"id\", chatCompletion.requestId(),\n\t\t\t\t\t\t\t\t\"role\", choice.message().role() != null ? choice.message().role().name() : \"\",\n\t\t\t\t\t\t\t\t\"finishReason\", choice.finishReason() != null ? choice.finishReason().name() : \"\");\n\t\t\t\t\t\t// @formatter:on\n\t\t\t\t\treturn buildGeneration(choice, metadata);\n\t\t\t\t}).toList();\n\n\t\t\t\tChatResponse response = new ChatResponse(generations, from(completionEntity.getBody()));\n\n\t\t\t\tobservationContext.setResponse(response);\n\n\t\t\t\treturn response;\n\t\t\t});\n\n\t\tif (isToolCall(chatResponse,\n\t\t\t\tSet.of(ChatCompletionFinishReason.TOOL_CALLS.name(), ChatCompletionFinishReason.STOP.name()))) {\n\t\t\tvar toolCallConversation = handleToolCalls(prompt, chatResponse);\n\t\t\t// Recursively call the call method with the tool call message\n\t\t\t// conversation that contains the call responses.\n\t\t\treturn this.call(new Prompt(toolCallConversation, prompt.getOptions()));\n\t\t}\n\n\t\treturn chatResponse;\n\t}\n\n\t@Override\n\tpublic ChatOptions getDefaultOptions() {\n\t\treturn DashScopeChatOptions.fromOptions(this.defaultOptions);\n\t}\n\n\t@Override\n\tpublic Flux<ChatResponse> stream(Prompt prompt) {\n\n\t\treturn Flux.deferContextual(contextView -> {\n\t\t\tChatCompletionRequest request = createRequest(prompt, true);\n\n\t\t\tFlux<ChatCompletionChunk> completionChunks = this.retryTemplate\n\t\t\t\t.execute(ctx -> this.dashscopeApi.chatCompletionStream(request));\n\n\t\t\t// For chunked responses, only the first chunk contains the choice role.\n\t\t\t// The rest of the chunks with same ID share the same role.\n\t\t\tConcurrentHashMap<String, String> roleMap = new ConcurrentHashMap<>();\n\n\t\t\tChatModelObservationContext observationContext = ChatModelObservationContext.builder()\n\t\t\t\t.prompt(prompt)\n\t\t\t\t.provider(DashScopeApiConstants.PROVIDER_NAME)\n\t\t\t\t.requestOptions(prompt.getOptions() != null ? prompt.getOptions() : this.defaultOptions)\n\t\t\t\t.build();\n\n\t\t\tObservation observation = ChatModelObservationDocumentation.CHAT_MODEL_OPERATION.observation(\n\t\t\t\t\tthis.observationConvention, DEFAULT_OBSERVATION_CONVENTION, () -> observationContext,\n\t\t\t\t\tthis.observationRegistry);\n\n\t\t\tobservation.parentObservation(contextView.getOrDefault(ObservationThreadLocalAccessor.KEY, null)).start();\n\n\t\t\t// Convert the ChatCompletionChunk into a ChatCompletion to be able to reuse\n\t\t\t// the function call handling logic.\n\t\t\tFlux<ChatResponse> chatResponse = completionChunks.map(this::chunkToChatCompletion)\n\t\t\t\t.switchMap(chatCompletion -> Mono.just(chatCompletion).map(chatCompletion2 -> {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t@SuppressWarnings(\"null\")\n\t\t\t\t\t\tString requestId = chatCompletion2.requestId();\n\n\t\t\t\t// @formatter:off\n\t\t\t\t\t\t\tList<Generation> generations = chatCompletion2.output().choices().stream().map(choice -> {\n\t\t\t\t\t\t\t\tif (choice.message().role() != null) {\n\t\t\t\t\t\t\t\t\troleMap.putIfAbsent(requestId, choice.message().role().name());\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tMap<String, Object> metadata = Map.of(\n\t\t\t\t\t\t\t\t\t\t\"id\", chatCompletion2.requestId(),\n\t\t\t\t\t\t\t\t\t\t\"role\", roleMap.getOrDefault(requestId, \"\"),\n\t\t\t\t\t\t\t\t\t\t\"finishReason\", choice.finishReason() != null ? choice.finishReason().name() : \"\");\n\t\t\t\t\t\t\t\treturn buildGeneration(choice, metadata);\n\t\t\t\t\t\t\t}).toList();\n\t\t\t\t\t\t\t// @formatter:on\n\n\t\t\t\t\t\tif (chatCompletion2.usage() != null) {\n\t\t\t\t\t\t\treturn new ChatResponse(generations, from(chatCompletion2));\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\treturn new ChatResponse(generations);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tcatch (Exception e) {\n\t\t\t\t\t\tlogger.error(\"Error processing chat completion\", e);\n\t\t\t\t\t\treturn new ChatResponse(List.of());\n\t\t\t\t\t}\n\n\t\t\t\t}));\n\n\t\t\t// @formatter:off\n\t\t\tFlux<ChatResponse> flux = chatResponse.flatMap(response -> {\n\n\t\t\t\tif (isToolCall(response,\n\t\t\t\t\t\tSet.of(ChatCompletionFinishReason.TOOL_CALLS.name(), ChatCompletionFinishReason.STOP.name()))) {\n\t\t\t\t\tvar toolCallConversation = handleToolCalls(prompt, response);\n\t\t\t\t\t// Recursively call the stream method with the tool call message\n\t\t\t\t\t// conversation that contains the call responses.\n\t\t\t\t\treturn this.stream(new Prompt(toolCallConversation, prompt.getOptions()));\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\treturn Flux.just(response);\n\t\t\t\t}\n\t\t\t})\n\t\t\t.doOnError(observation::error)\n\t\t\t.doFinally(s -> observation.stop())\n\t\t\t.contextWrite(ctx -> ctx.put(ObservationThreadLocalAccessor.KEY, observation));\n\n\t\t\treturn new MessageAggregator().aggregate(flux, observationContext::setResponse);\n\t\t});\n\t}\n\n\tprivate static Generation buildGeneration(Choice choice, Map<String, Object> metadata) {\n\t\tList<AssistantMessage.ToolCall> toolCalls = choice.message().toolCalls() == null ? List.of()\n\t\t\t\t: choice.message()\n\t\t\t\t\t.toolCalls()\n\t\t\t\t\t.stream()\n\t\t\t\t\t.map(toolCall -> new AssistantMessage.ToolCall(toolCall.id(), \"function\",\n\t\t\t\t\t\t\ttoolCall.function().name(), toolCall.function().arguments()))\n\t\t\t\t\t.toList();\n\n\t\tvar assistantMessage = new AssistantMessage(choice.message().content(), metadata, toolCalls);\n\t\tString finishReason = (choice.finishReason() != null ? choice.finishReason().name() : \"\");\n\t\tvar generationMetadata = ChatGenerationMetadata.builder().finishReason(finishReason).build();\n\t\treturn new Generation(assistantMessage, generationMetadata);\n\t}\n\n\t/**\n\t * Convert the ChatCompletionChunk into a ChatCompletion. The Usage is set to null.\n\t * @param chunk the ChatCompletionChunk to convert\n\t * @return the ChatCompletion\n\t */\n\tprivate ChatCompletion chunkToChatCompletion(ChatCompletionChunk chunk) {\n\t\treturn new ChatCompletion(chunk.requestId(),\n\t\t\t\tnew ChatCompletionOutput(chunk.output().text(), chunk.output().choices()), chunk.usage());\n\t}\n\n\tprivate ChatResponseMetadata from(ChatCompletion result) {\n\t\tAssert.notNull(result, \"DashScopeAi ChatCompletionResult must not be null\");\n\t\treturn ChatResponseMetadata.builder()\n\t\t\t.id(result.requestId())\n\t\t\t.usage(DashScopeAiUsage.from(result.usage()))\n\t\t\t.model(\"\")\n\t\t\t.build();\n\t}\n\n\t/**\n\t * Accessible for testing.\n\t */\n\tChatCompletionRequest createRequest(Prompt prompt, boolean stream) {\n\t\tSet<String> enabledToolsToUse = new HashSet<>();\n\n\t\tDashScopeChatOptions options = DashScopeChatOptions.builder().build();\n\t\tif (prompt.getOptions() != null) {\n\t\t\tDashScopeChatOptions updatedRuntimeOptions = ModelOptionsUtils.copyToTarget(prompt.getOptions(),\n\t\t\t\t\tChatOptions.class, DashScopeChatOptions.class);\n\n\t\t\tenabledToolsToUse.addAll(this.runtimeFunctionCallbackConfigurations(updatedRuntimeOptions));\n\t\t\toptions = ModelOptionsUtils.merge(updatedRuntimeOptions, options, DashScopeChatOptions.class);\n\t\t}\n\n\t\tif (!CollectionUtils.isEmpty(this.defaultOptions.getFunctions())) {\n\t\t\tenabledToolsToUse.addAll(this.defaultOptions.getFunctions());\n\t\t}\n\n\t\toptions = ModelOptionsUtils.merge(options, this.defaultOptions, DashScopeChatOptions.class);\n\n\t\tif (!CollectionUtils.isEmpty(enabledToolsToUse)) {\n\t\t\toptions.setTools(this.getFunctionTools(enabledToolsToUse));\n\t\t}\n\n\t\tList<ChatCompletionMessage> chatCompletionMessages = prompt.getInstructions().stream().map(message -> {\n\t\t\tif (message.getMessageType() == MessageType.USER || message.getMessageType() == MessageType.SYSTEM) {\n\t\t\t\tObject content = message.getText();\n\t\t\t\tif (message instanceof UserMessage userMessage) {\n\t\t\t\t\tif (!CollectionUtils.isEmpty(userMessage.getMedia())) {\n\t\t\t\t\t\tcontent = convertMediaContent(userMessage);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\treturn List.of(new ChatCompletionMessage(content,\n\t\t\t\t\t\tChatCompletionMessage.Role.valueOf(message.getMessageType().name())));\n\t\t\t}\n\t\t\telse if (message.getMessageType() == MessageType.ASSISTANT) {\n\t\t\t\tvar assistantMessage = (AssistantMessage) message;\n\t\t\t\tList<ToolCall> toolCalls = null;\n\t\t\t\tif (!CollectionUtils.isEmpty(assistantMessage.getToolCalls())) {\n\t\t\t\t\ttoolCalls = assistantMessage.getToolCalls().stream().map(toolCall -> {\n\t\t\t\t\t\tvar function = new ChatCompletionFunction(toolCall.name(), toolCall.arguments());\n\t\t\t\t\t\treturn new ToolCall(toolCall.id(), toolCall.type(), function);\n\t\t\t\t\t}).toList();\n\t\t\t\t}\n\t\t\t\treturn List.of(new ChatCompletionMessage(assistantMessage.getContent(),\n\t\t\t\t\t\tChatCompletionMessage.Role.ASSISTANT, null, null, toolCalls));\n\t\t\t}\n\t\t\telse if (message.getMessageType() == MessageType.TOOL) {\n\t\t\t\tToolResponseMessage toolMessage = (ToolResponseMessage) message;\n\n\t\t\t\ttoolMessage.getResponses().forEach(response -> {\n\t\t\t\t\tAssert.isTrue(response.id() != null, \"ToolResponseMessage must have an id\");\n\t\t\t\t\tAssert.isTrue(response.name() != null, \"ToolResponseMessage must have a name\");\n\t\t\t\t});\n\n\t\t\t\treturn toolMessage.getResponses()\n\t\t\t\t\t.stream()\n\t\t\t\t\t.map(tr -> new ChatCompletionMessage(tr.responseData(), ChatCompletionMessage.Role.TOOL, tr.name(),\n\t\t\t\t\t\t\ttr.id(), null))\n\t\t\t\t\t.toList();\n\t\t\t}\n\t\t\telse {\n\t\t\t\tthrow new IllegalArgumentException(\"Unsupported message type: \" + message.getMessageType());\n\t\t\t}\n\t\t}).flatMap(List::stream).toList();\n\n\t\tboolean multiModel = options.getMultiModel();\n\t\treturn new ChatCompletionRequest(options.getModel(), new ChatCompletionRequestInput(chatCompletionMessages),\n\t\t\t\ttoDashScopeRequestParameter(options, stream), stream, multiModel);\n\t}\n\n\tprivate List<MediaContent> convertMediaContent(UserMessage message) {\n\t\tMessageFormat format = MessageFormat.IMAGE;\n\t\tif (message.getMetadata().get(MESSAGE_FORMAT) instanceof MessageFormat messageFormat) {\n\t\t\tformat = messageFormat;\n\t\t}\n\n\t\tList<MediaContent> contentList = new ArrayList<>();\n\t\tif (format == MessageFormat.VIDEO) {\n\t\t\tMediaContent mediaContent = new MediaContent(message.getContent());\n\t\t\tcontentList.add(mediaContent);\n\n\t\t\tList<String> mediaList = message.getMedia()\n\t\t\t\t.stream()\n\t\t\t\t.map(media -> this.fromMediaData(media.getMimeType(), media.getData()))\n\t\t\t\t.toList();\n\n\t\t\tcontentList.add(new MediaContent(\"video\", null, null, mediaList));\n\t\t}\n\t\telse {\n\t\t\tMediaContent mediaContent = new MediaContent(message.getContent());\n\t\t\tcontentList.add(mediaContent);\n\n\t\t\tcontentList.addAll(message.getMedia()\n\t\t\t\t.stream()\n\t\t\t\t.map(media -> new MediaContent(\"image\", null, this.fromMediaData(media.getMimeType(), media.getData()),\n\t\t\t\t\t\tnull))\n\t\t\t\t.toList());\n\t\t}\n\n\t\treturn contentList;\n\t}\n\n\tprivate String fromMediaData(MimeType mimeType, Object mediaContentData) {\n\t\tif (mediaContentData instanceof byte[] bytes) {\n\t\t\t// Assume the bytes are an image. So, convert the bytes to a base64 encoded\n\t\t\t// following the prefix pattern.\n\t\t\treturn String.format(\"data:%s;base64,%s\", mimeType.toString(), Base64.getEncoder().encodeToString(bytes));\n\t\t}\n\t\telse if (mediaContentData instanceof String text) {\n\t\t\t// Assume the text is a URLs or a base64 encoded image prefixed by the user.\n\t\t\treturn text;\n\t\t}\n\t\telse {\n\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\"Unsupported media data type: \" + mediaContentData.getClass().getSimpleName());\n\t\t}\n\t}\n\n\tprivate List<FunctionTool> getFunctionTools(Set<String> functionNames) {\n\t\treturn this.resolveFunctionCallbacks(functionNames).stream().map(functionCallback -> {\n\t\t\tvar function = new FunctionTool.Function(functionCallback.getDescription(), functionCallback.getName(),\n\t\t\t\t\tfunctionCallback.getInputTypeSchema());\n\t\t\treturn new FunctionTool(function);\n\t\t}).toList();\n\t}\n\n\tprivate ChatCompletionRequestParameter toDashScopeRequestParameter(DashScopeChatOptions options, boolean stream) {\n\n\t\tif (options == null) {\n\t\t\treturn new ChatCompletionRequestParameter();\n\t\t}\n\n\t\tBoolean incrementalOutput = stream && options.getIncrementalOutput();\n\t\treturn new ChatCompletionRequestParameter(\n\t\t\t\t\"message\",\n\t\t\t\toptions.getSeed(),\n\t\t\t\toptions.getMaxTokens(),\n\t\t\t\toptions.getTopP(),\n\t\t\t\toptions.getTopK(),\n\t\t\t\toptions.getRepetitionPenalty(),\n\t\t\t\toptions.getPresencePenalty(),\n\t\t\t\toptions.getTemperature(),\n\t\t\t\toptions.getStop(),\n\t\t\t\toptions.getEnableSearch(),\n\t\t\t\toptions.getResponseFormat(),\n\t\t\t\tincrementalOutput,\n\t\t\t\toptions.getTools(),\n\t\t\t\toptions.getToolChoice(),\n\t\t\t\tstream, options.getVlHighResolutionImages()\n\t\t);\n\t}\n\n\t/**\n\t * Use the provided convention for reporting observation data\n\t * @param observationConvention The provided convention\n\t */\n\tpublic void setObservationConvention(ChatModelObservationConvention observationConvention) {\n\t\tAssert.notNull(observationConvention, \"observationConvention cannot be null\");\n\t\tthis.observationConvention = observationConvention;\n\t}\n\n}", "output": "/*\n * Copyright 2024-2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.alibaba.cloud.ai.dashscope.chat;\n\nimport java.util.ArrayList;\nimport java.util.Base64;\nimport java.util.HashSet;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Set;\nimport java.util.concurrent.ConcurrentHashMap;\n\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi.ChatCompletion;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi.ChatCompletionChunk;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi.ChatCompletionFinishReason;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi.ChatCompletionMessage;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi.ChatCompletionMessage.ChatCompletionFunction;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi.ChatCompletionMessage.MediaContent;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi.ChatCompletionMessage.ToolCall;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi.ChatCompletionOutput;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi.ChatCompletionOutput.Choice;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi.ChatCompletionRequest;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi.ChatCompletionRequestInput;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi.ChatCompletionRequestParameter;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi.FunctionTool;\nimport com.alibaba.cloud.ai.dashscope.chat.observation.DashScopeChatModelObservationConvention;\nimport com.alibaba.cloud.ai.dashscope.common.DashScopeApiConstants;\nimport com.alibaba.cloud.ai.dashscope.metadata.DashScopeAiUsage;\nimport io.micrometer.observation.Observation;\nimport io.micrometer.observation.ObservationRegistry;\nimport io.micrometer.observation.contextpropagation.ObservationThreadLocalAccessor;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport reactor.core.publisher.Flux;\nimport reactor.core.publisher.Mono;\n\nimport org.springframework.ai.chat.messages.AssistantMessage;\nimport org.springframework.ai.chat.messages.MessageType;\nimport org.springframework.ai.chat.messages.ToolResponseMessage;\nimport org.springframework.ai.chat.messages.UserMessage;\nimport org.springframework.ai.chat.metadata.ChatGenerationMetadata;\nimport org.springframework.ai.chat.metadata.ChatResponseMetadata;\nimport org.springframework.ai.chat.model.AbstractToolCallSupport;\nimport org.springframework.ai.chat.model.ChatModel;\nimport org.springframework.ai.chat.model.ChatResponse;\nimport org.springframework.ai.chat.model.Generation;\nimport org.springframework.ai.chat.model.MessageAggregator;\nimport org.springframework.ai.chat.observation.ChatModelObservationContext;\nimport org.springframework.ai.chat.observation.ChatModelObservationConvention;\nimport org.springframework.ai.chat.observation.ChatModelObservationDocumentation;\nimport org.springframework.ai.chat.prompt.ChatOptions;\nimport org.springframework.ai.chat.prompt.Prompt;\nimport org.springframework.ai.model.ModelOptionsUtils;\nimport org.springframework.ai.model.function.FunctionCallback;\nimport org.springframework.ai.model.function.FunctionCallbackResolver;\nimport org.springframework.ai.retry.RetryUtils;\nimport org.springframework.http.ResponseEntity;\nimport org.springframework.retry.support.RetryTemplate;\nimport org.springframework.util.Assert;\nimport org.springframework.util.CollectionUtils;\nimport org.springframework.util.MimeType;\n\n/**\n * {@link ChatModel} implementation for {@literal Alibaba DashScope} backed by\n * {@link Generation}.\n *\n * @author yuluo\n * @author <a href=\"mailto:yuluo08290126@gmail.com\">yuluo</a>\n * @see ChatModel\n * @see com.alibaba.dashscope.aigc.generation\n */\npublic class DashScopeChatModel extends AbstractToolCallSupport implements ChatModel {\n\n\tpublic static final String MESSAGE_FORMAT = \"messageFormat\";\n\n\tprivate static final Logger logger = LoggerFactory.getLogger(DashScopeChatModel.class);\n\n\tprivate static final ChatModelObservationConvention DEFAULT_OBSERVATION_CONVENTION = new DashScopeChatModelObservationConvention();\n\n\t/** Low-level access to the DashScope API */\n\tprivate final DashScopeApi dashscopeApi;\n\n\t/** The retry template used to retry the OpenAI API calls. */\n\tpublic final RetryTemplate retryTemplate;\n\n\t/**\n\t * Observation registry used for instrumentation.\n\t */\n\tprivate final ObservationRegistry observationRegistry;\n\n\t/** The default options used for the chat completion requests. */\n\tprivate DashScopeChatOptions defaultOptions;\n\n\t/**\n\t * Conventions to use for generating observations.\n\t */\n\tprivate ChatModelObservationConvention observationConvention = DEFAULT_OBSERVATION_CONVENTION;\n\n\tpublic DashScopeChatModel(DashScopeApi dashscopeApi) {\n\t\tthis(dashscopeApi,\n\t\t\t\tDashScopeChatOptions.builder()\n\t\t\t\t\t.withModel(DashScopeApi.DEFAULT_CHAT_MODEL)\n\t\t\t\t\t.withTemperature(0.7d)\n\t\t\t\t\t.build());\n\t}\n\n\tpublic DashScopeChatModel(DashScopeApi dashscopeApi, DashScopeChatOptions options) {\n\t\tthis(dashscopeApi, options, null, RetryUtils.DEFAULT_RETRY_TEMPLATE);\n\t}\n\n\tpublic DashScopeChatModel(DashScopeApi dashscopeApi, DashScopeChatOptions options,\n\t\t\tFunctionCallbackResolver functionCallbackResolver, RetryTemplate retryTemplate) {\n\t\tthis(dashscopeApi, options, functionCallbackResolver, List.of(), retryTemplate);\n\t}\n\n\tpublic DashScopeChatModel(DashScopeApi dashscopeApi, DashScopeChatOptions options,\n\t\t\tFunctionCallbackResolver functionCallbackResolver, List<FunctionCallback> toolFunctionCallbacks,\n\t\t\tRetryTemplate retryTemplate) {\n\n\t\tthis(dashscopeApi, options, functionCallbackResolver, toolFunctionCallbacks, retryTemplate,\n\t\t\t\tObservationRegistry.NOOP);\n\t}\n\n\tpublic DashScopeChatModel(DashScopeApi dashscopeApi, DashScopeChatOptions options,\n\t\t\tFunctionCallbackResolver functionCallbackResolver, List<FunctionCallback> toolFunctionCallbacks,\n\t\t\tRetryTemplate retryTemplate, ObservationRegistry observationRegistry) {\n\n\t\tsuper(functionCallbackResolver, options, toolFunctionCallbacks);\n\n\t\tAssert.notNull(dashscopeApi, \"DashScopeApi must not be null\");\n\t\tAssert.notNull(options, \"Options must not be null\");\n\t\tAssert.notNull(retryTemplate, \"RetryTemplate must not be null\");\n\t\tAssert.isTrue(CollectionUtils.isEmpty(options.getFunctionCallbacks()),\n\t\t\t\t\"The default function callbacks must be set via the toolFunctionCallbacks constructor parameter\");\n\t\tAssert.notNull(observationRegistry, \"ObservationRegistry must not be null\");\n\n\t\tthis.dashscopeApi = dashscopeApi;\n\t\tthis.defaultOptions = options;\n\t\tthis.retryTemplate = retryTemplate;\n\t\tthis.observationRegistry = observationRegistry;\n\t}\n\n\t@Override\n\tpublic ChatResponse call(Prompt prompt) {\n\n\t\tChatModelObservationContext observationContext = ChatModelObservationContext.builder()\n\t\t\t.prompt(prompt)\n\t\t\t.provider(DashScopeApiConstants.PROVIDER_NAME)\n\t\t\t.requestOptions(prompt.getOptions() != null ? prompt.getOptions() : this.defaultOptions)\n\t\t\t.build();\n\n\t\tChatResponse chatResponse = ChatModelObservationDocumentation.CHAT_MODEL_OPERATION\n\t\t\t.observation(this.observationConvention, DEFAULT_OBSERVATION_CONVENTION, () -> observationContext,\n\t\t\t\t\tthis.observationRegistry)\n\t\t\t.observe(() -> {\n\t\t\t\tDashScopeApi.ChatCompletionRequest request = createRequest(prompt, false);\n\n\t\t\t\tResponseEntity<ChatCompletion> completionEntity = this.retryTemplate\n\t\t\t\t\t.execute(ctx -> this.dashscopeApi.chatCompletionEntity(request));\n\n\t\t\t\tvar chatCompletion = completionEntity.getBody();\n\n\t\t\t\tif (chatCompletion == null) {\n\t\t\t\t\tlogger.warn(\"No chat completion returned for prompt: {}\", prompt);\n\t\t\t\t\treturn new ChatResponse(List.of());\n\t\t\t\t}\n\n\t\t\t\tList<ChatCompletionOutput.Choice> choices = chatCompletion.output().choices();\n\n\t\t\t\tList<Generation> generations = choices.stream().map(choice -> {\n\t\t\t// @formatter:off\n\t\t\t\t\t\tMap<String, Object> metadata = Map.of(\n\t\t\t\t\t\t\t\t\"id\", chatCompletion.requestId(),\n\t\t\t\t\t\t\t\t\"role\", choice.message().role() != null ? choice.message().role().name() : \"\",\n\t\t\t\t\t\t\t\t\"finishReason\", choice.finishReason() != null ? choice.finishReason().name() : \"\");\n\t\t\t\t\t\t// @formatter:on\n\t\t\t\t\treturn buildGeneration(choice, metadata);\n\t\t\t\t}).toList();\n\n\t\t\t\tChatResponse response = new ChatResponse(generations, from(completionEntity.getBody()));\n\n\t\t\t\tobservationContext.setResponse(response);\n\n\t\t\t\treturn response;\n\t\t\t});\n\n\t\tif (!isProxyToolCalls(prompt, this.defaultOptions) && isToolCall(chatResponse,\n\t\t\t\tSet.of(ChatCompletionFinishReason.TOOL_CALLS.name(), ChatCompletionFinishReason.STOP.name()))) {\n\t\t\tvar toolCallConversation = handleToolCalls(prompt, chatResponse);\n\t\t\t// Recursively call the call method with the tool call message\n\t\t\t// conversation that contains the call responses.\n\t\t\treturn this.call(new Prompt(toolCallConversation, prompt.getOptions()));\n\t\t}\n\n\t\treturn chatResponse;\n\t}\n\n\t@Override\n\tpublic ChatOptions getDefaultOptions() {\n\t\treturn DashScopeChatOptions.fromOptions(this.defaultOptions);\n\t}\n\n\t@Override\n\tpublic Flux<ChatResponse> stream(Prompt prompt) {\n\n\t\treturn Flux.deferContextual(contextView -> {\n\t\t\tChatCompletionRequest request = createRequest(prompt, true);\n\n\t\t\tFlux<ChatCompletionChunk> completionChunks = this.retryTemplate\n\t\t\t\t.execute(ctx -> this.dashscopeApi.chatCompletionStream(request));\n\n\t\t\t// For chunked responses, only the first chunk contains the choice role.\n\t\t\t// The rest of the chunks with same ID share the same role.\n\t\t\tConcurrentHashMap<String, String> roleMap = new ConcurrentHashMap<>();\n\n\t\t\tChatModelObservationContext observationContext = ChatModelObservationContext.builder()\n\t\t\t\t.prompt(prompt)\n\t\t\t\t.provider(DashScopeApiConstants.PROVIDER_NAME)\n\t\t\t\t.requestOptions(prompt.getOptions() != null ? prompt.getOptions() : this.defaultOptions)\n\t\t\t\t.build();\n\n\t\t\tObservation observation = ChatModelObservationDocumentation.CHAT_MODEL_OPERATION.observation(\n\t\t\t\t\tthis.observationConvention, DEFAULT_OBSERVATION_CONVENTION, () -> observationContext,\n\t\t\t\t\tthis.observationRegistry);\n\n\t\t\tobservation.parentObservation(contextView.getOrDefault(ObservationThreadLocalAccessor.KEY, null)).start();\n\n\t\t\t// Convert the ChatCompletionChunk into a ChatCompletion to be able to reuse\n\t\t\t// the function call handling logic.\n\t\t\tFlux<ChatResponse> chatResponse = completionChunks.map(this::chunkToChatCompletion)\n\t\t\t\t.switchMap(chatCompletion -> Mono.just(chatCompletion).map(chatCompletion2 -> {\n\t\t\t\t\ttry {\n\t\t\t\t\t\t@SuppressWarnings(\"null\")\n\t\t\t\t\t\tString requestId = chatCompletion2.requestId();\n\n\t\t\t\t// @formatter:off\n\t\t\t\t\t\t\tList<Generation> generations = chatCompletion2.output().choices().stream().map(choice -> {\n\t\t\t\t\t\t\t\tif (choice.message().role() != null) {\n\t\t\t\t\t\t\t\t\troleMap.putIfAbsent(requestId, choice.message().role().name());\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tMap<String, Object> metadata = Map.of(\n\t\t\t\t\t\t\t\t\t\t\"id\", chatCompletion2.requestId(),\n\t\t\t\t\t\t\t\t\t\t\"role\", roleMap.getOrDefault(requestId, \"\"),\n\t\t\t\t\t\t\t\t\t\t\"finishReason\", choice.finishReason() != null ? choice.finishReason().name() : \"\");\n\t\t\t\t\t\t\t\treturn buildGeneration(choice, metadata);\n\t\t\t\t\t\t\t}).toList();\n\t\t\t\t\t\t\t// @formatter:on\n\n\t\t\t\t\t\tif (chatCompletion2.usage() != null) {\n\t\t\t\t\t\t\treturn new ChatResponse(generations, from(chatCompletion2));\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\treturn new ChatResponse(generations);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tcatch (Exception e) {\n\t\t\t\t\t\tlogger.error(\"Error processing chat completion\", e);\n\t\t\t\t\t\treturn new ChatResponse(List.of());\n\t\t\t\t\t}\n\n\t\t\t\t}));\n\n\t\t\t// @formatter:off\n\t\t\tFlux<ChatResponse> flux = chatResponse.flatMap(response -> {\n\t\t\t\tif (!isProxyToolCalls(prompt, this.defaultOptions) &&\n\t\t\t\t\t\tisToolCall(response, Set.of(ChatCompletionFinishReason.TOOL_CALLS.name(), ChatCompletionFinishReason.STOP.name()))) {\n\t\t\t\t\tvar toolCallConversation = handleToolCalls(prompt, response);\n\t\t\t\t\t// Recursively call the stream method with the tool call message\n\t\t\t\t\t// conversation that contains the call responses.\n\t\t\t\t\treturn this.stream(new Prompt(toolCallConversation, prompt.getOptions()));\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\treturn Flux.just(response);\n\t\t\t\t}\n\t\t\t})\n\t\t\t.doOnError(observation::error)\n\t\t\t.doFinally(s -> observation.stop())\n\t\t\t.contextWrite(ctx -> ctx.put(ObservationThreadLocalAccessor.KEY, observation));\n\n\t\t\treturn new MessageAggregator().aggregate(flux, observationContext::setResponse);\n\t\t});\n\t}\n\n\tprivate static Generation buildGeneration(Choice choice, Map<String, Object> metadata) {\n\t\tList<AssistantMessage.ToolCall> toolCalls = choice.message().toolCalls() == null ? List.of()\n\t\t\t\t: choice.message()\n\t\t\t\t\t.toolCalls()\n\t\t\t\t\t.stream()\n\t\t\t\t\t.map(toolCall -> new AssistantMessage.ToolCall(toolCall.id(), \"function\",\n\t\t\t\t\t\t\ttoolCall.function().name(), toolCall.function().arguments()))\n\t\t\t\t\t.toList();\n\n\t\tvar assistantMessage = new AssistantMessage(choice.message().content(), metadata, toolCalls);\n\t\tString finishReason = (choice.finishReason() != null ? choice.finishReason().name() : \"\");\n\t\tvar generationMetadata = ChatGenerationMetadata.builder().finishReason(finishReason).build();\n\t\treturn new Generation(assistantMessage, generationMetadata);\n\t}\n\n\t/**\n\t * Convert the ChatCompletionChunk into a ChatCompletion. The Usage is set to null.\n\t * @param chunk the ChatCompletionChunk to convert\n\t * @return the ChatCompletion\n\t */\n\tprivate ChatCompletion chunkToChatCompletion(ChatCompletionChunk chunk) {\n\t\treturn new ChatCompletion(chunk.requestId(),\n\t\t\t\tnew ChatCompletionOutput(chunk.output().text(), chunk.output().choices()), chunk.usage());\n\t}\n\n\tprivate ChatResponseMetadata from(ChatCompletion result) {\n\t\tAssert.notNull(result, \"DashScopeAi ChatCompletionResult must not be null\");\n\t\treturn ChatResponseMetadata.builder()\n\t\t\t.id(result.requestId())\n\t\t\t.usage(DashScopeAiUsage.from(result.usage()))\n\t\t\t.model(\"\")\n\t\t\t.build();\n\t}\n\n\t/**\n\t * Accessible for testing.\n\t */\n\tChatCompletionRequest createRequest(Prompt prompt, boolean stream) {\n\t\tSet<String> enabledToolsToUse = new HashSet<>();\n\n\t\tDashScopeChatOptions options = DashScopeChatOptions.builder().build();\n\t\tif (prompt.getOptions() != null) {\n\t\t\tDashScopeChatOptions updatedRuntimeOptions = ModelOptionsUtils.copyToTarget(prompt.getOptions(),\n\t\t\t\t\tChatOptions.class, DashScopeChatOptions.class);\n\n\t\t\tenabledToolsToUse.addAll(this.runtimeFunctionCallbackConfigurations(updatedRuntimeOptions));\n\t\t\toptions = ModelOptionsUtils.merge(updatedRuntimeOptions, options, DashScopeChatOptions.class);\n\t\t}\n\n\t\tif (!CollectionUtils.isEmpty(this.defaultOptions.getFunctions())) {\n\t\t\tenabledToolsToUse.addAll(this.defaultOptions.getFunctions());\n\t\t}\n\n\t\toptions = ModelOptionsUtils.merge(options, this.defaultOptions, DashScopeChatOptions.class);\n\n\t\tif (!CollectionUtils.isEmpty(enabledToolsToUse)) {\n\t\t\toptions.setTools(this.getFunctionTools(enabledToolsToUse));\n\t\t}\n\n\t\tList<ChatCompletionMessage> chatCompletionMessages = prompt.getInstructions().stream().map(message -> {\n\t\t\tif (message.getMessageType() == MessageType.USER || message.getMessageType() == MessageType.SYSTEM) {\n\t\t\t\tObject content = message.getText();\n\t\t\t\tif (message instanceof UserMessage userMessage) {\n\t\t\t\t\tif (!CollectionUtils.isEmpty(userMessage.getMedia())) {\n\t\t\t\t\t\tcontent = convertMediaContent(userMessage);\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\treturn List.of(new ChatCompletionMessage(content,\n\t\t\t\t\t\tChatCompletionMessage.Role.valueOf(message.getMessageType().name())));\n\t\t\t}\n\t\t\telse if (message.getMessageType() == MessageType.ASSISTANT) {\n\t\t\t\tvar assistantMessage = (AssistantMessage) message;\n\t\t\t\tList<ToolCall> toolCalls = null;\n\t\t\t\tif (!CollectionUtils.isEmpty(assistantMessage.getToolCalls())) {\n\t\t\t\t\ttoolCalls = assistantMessage.getToolCalls().stream().map(toolCall -> {\n\t\t\t\t\t\tvar function = new ChatCompletionFunction(toolCall.name(), toolCall.arguments());\n\t\t\t\t\t\treturn new ToolCall(toolCall.id(), toolCall.type(), function);\n\t\t\t\t\t}).toList();\n\t\t\t\t}\n\t\t\t\treturn List.of(new ChatCompletionMessage(assistantMessage.getContent(),\n\t\t\t\t\t\tChatCompletionMessage.Role.ASSISTANT, null, null, toolCalls));\n\t\t\t}\n\t\t\telse if (message.getMessageType() == MessageType.TOOL) {\n\t\t\t\tToolResponseMessage toolMessage = (ToolResponseMessage) message;\n\n\t\t\t\ttoolMessage.getResponses().forEach(response -> {\n\t\t\t\t\tAssert.isTrue(response.id() != null, \"ToolResponseMessage must have an id\");\n\t\t\t\t\tAssert.isTrue(response.name() != null, \"ToolResponseMessage must have a name\");\n\t\t\t\t});\n\n\t\t\t\treturn toolMessage.getResponses()\n\t\t\t\t\t.stream()\n\t\t\t\t\t.map(tr -> new ChatCompletionMessage(tr.responseData(), ChatCompletionMessage.Role.TOOL, tr.name(),\n\t\t\t\t\t\t\ttr.id(), null))\n\t\t\t\t\t.toList();\n\t\t\t}\n\t\t\telse {\n\t\t\t\tthrow new IllegalArgumentException(\"Unsupported message type: \" + message.getMessageType());\n\t\t\t}\n\t\t}).flatMap(List::stream).toList();\n\n\t\tboolean multiModel = options.getMultiModel();\n\t\treturn new ChatCompletionRequest(options.getModel(), new ChatCompletionRequestInput(chatCompletionMessages),\n\t\t\t\ttoDashScopeRequestParameter(options, stream), stream, multiModel);\n\t}\n\n\tprivate List<MediaContent> convertMediaContent(UserMessage message) {\n\t\tMessageFormat format = MessageFormat.IMAGE;\n\t\tif (message.getMetadata().get(MESSAGE_FORMAT) instanceof MessageFormat messageFormat) {\n\t\t\tformat = messageFormat;\n\t\t}\n\n\t\tList<MediaContent> contentList = new ArrayList<>();\n\t\tif (format == MessageFormat.VIDEO) {\n\t\t\tMediaContent mediaContent = new MediaContent(message.getContent());\n\t\t\tcontentList.add(mediaContent);\n\n\t\t\tList<String> mediaList = message.getMedia()\n\t\t\t\t.stream()\n\t\t\t\t.map(media -> this.fromMediaData(media.getMimeType(), media.getData()))\n\t\t\t\t.toList();\n\n\t\t\tcontentList.add(new MediaContent(\"video\", null, null, mediaList));\n\t\t}\n\t\telse {\n\t\t\tMediaContent mediaContent = new MediaContent(message.getContent());\n\t\t\tcontentList.add(mediaContent);\n\n\t\t\tcontentList.addAll(message.getMedia()\n\t\t\t\t.stream()\n\t\t\t\t.map(media -> new MediaContent(\"image\", null, this.fromMediaData(media.getMimeType(), media.getData()),\n\t\t\t\t\t\tnull))\n\t\t\t\t.toList());\n\t\t}\n\n\t\treturn contentList;\n\t}\n\n\tprivate String fromMediaData(MimeType mimeType, Object mediaContentData) {\n\t\tif (mediaContentData instanceof byte[] bytes) {\n\t\t\t// Assume the bytes are an image. So, convert the bytes to a base64 encoded\n\t\t\t// following the prefix pattern.\n\t\t\treturn String.format(\"data:%s;base64,%s\", mimeType.toString(), Base64.getEncoder().encodeToString(bytes));\n\t\t}\n\t\telse if (mediaContentData instanceof String text) {\n\t\t\t// Assume the text is a URLs or a base64 encoded image prefixed by the user.\n\t\t\treturn text;\n\t\t}\n\t\telse {\n\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\"Unsupported media data type: \" + mediaContentData.getClass().getSimpleName());\n\t\t}\n\t}\n\n\tprivate List<FunctionTool> getFunctionTools(Set<String> functionNames) {\n\t\treturn this.resolveFunctionCallbacks(functionNames).stream().map(functionCallback -> {\n\t\t\tvar function = new FunctionTool.Function(functionCallback.getDescription(), functionCallback.getName(),\n\t\t\t\t\tfunctionCallback.getInputTypeSchema());\n\t\t\treturn new FunctionTool(function);\n\t\t}).toList();\n\t}\n\n\tprivate ChatCompletionRequestParameter toDashScopeRequestParameter(DashScopeChatOptions options, boolean stream) {\n\n\t\tif (options == null) {\n\t\t\treturn new ChatCompletionRequestParameter();\n\t\t}\n\n\t\tBoolean incrementalOutput = stream && options.getIncrementalOutput();\n\t\treturn new ChatCompletionRequestParameter(\n\t\t\t\t\"message\",\n\t\t\t\toptions.getSeed(),\n\t\t\t\toptions.getMaxTokens(),\n\t\t\t\toptions.getTopP(),\n\t\t\t\toptions.getTopK(),\n\t\t\t\toptions.getRepetitionPenalty(),\n\t\t\t\toptions.getPresencePenalty(),\n\t\t\t\toptions.getTemperature(),\n\t\t\t\toptions.getStop(),\n\t\t\t\toptions.getEnableSearch(),\n\t\t\t\toptions.getResponseFormat(),\n\t\t\t\tincrementalOutput,\n\t\t\t\toptions.getTools(),\n\t\t\t\toptions.getToolChoice(),\n\t\t\t\tstream, options.getVlHighResolutionImages()\n\t\t);\n\t}\n\n\t/**\n\t * Use the provided convention for reporting observation data\n\t * @param observationConvention The provided convention\n\t */\n\tpublic void setObservationConvention(ChatModelObservationConvention observationConvention) {\n\t\tAssert.notNull(observationConvention, \"observationConvention cannot be null\");\n\t\tthis.observationConvention = observationConvention;\n\t}\n\n}", "metadata": {"commit_sha": "ed874be0", "lines_added": 3, "lines_deleted": 4, "total_changes": 7, "chunks": 2}}
{"id": 17, "pattern_type": "import_statement", "file_path": "spring-ai-alibaba-examples/observability-example/src/main/java/com/alibaba/cloud/ai/example/observability/ObservabilityApplication.java", "file_extension": "java", "input": "package com.alibaba.cloud.ai.example.observability;\n\nimport org.springframework.ai.chat.client.ChatClient;\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.ResponseBody;\n\nimport java.util.Map;\n\n@SpringBootApplication\npublic class ObservabilityApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(ObservabilityApplication.class, args);\n    }\n\n    @Bean\n    ChatClient chatClient(ChatClient.Builder builder) {\n        return builder.build();\n    }\n}\n\n@Controller\n@ResponseBody\nclass JokeController {\n\n    private final ChatClient chatClient;\n\n    JokeController(ChatClient chatClient) {\n        this.chatClient = chatClient;\n    }\n\n    @GetMapping(\"/joke\")\n    Map<String, String> joke() {\n        var reply = chatClient\n                .prompt()\n                .user(\"\"\"\n                        tell me a joke. be concise. don't send anything except the joke.\n                        \"\"\")\n                .call()\n                .content();\n\n        return Map.of(\"joke\", reply);\n    }\n}", "output": "package com.alibaba.cloud.ai.example.observability;\n\nimport io.opentelemetry.api.trace.Span;\nimport io.opentelemetry.api.trace.SpanContext;\nimport io.opentelemetry.context.Context;\nimport org.springframework.ai.chat.client.ChatClient;\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.stereotype.Controller;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.ResponseBody;\n\nimport java.util.Map;\n\n@SpringBootApplication\npublic class ObservabilityApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(ObservabilityApplication.class, args);\n    }\n\n    @Bean\n    ChatClient chatClient(ChatClient.Builder builder) {\n        return builder.build();\n    }\n}\n\n@Controller\n@ResponseBody\nclass JokeController {\n\n    private final ChatClient chatClient;\n\n    JokeController(ChatClient chatClient) {\n        this.chatClient = chatClient;\n    }\n\n    @GetMapping(\"/joke\")\n    Map<String, String> joke() {\n        var reply = chatClient\n                .prompt()\n                .user(\"\"\"\n                        tell me a joke. be concise. don't send anything except the joke.\n                        \"\"\")\n                .call()\n                .content();\n        Span currentSpan = Span.current();\n        return Map.of(\"joke\", reply, \"traceId\", currentSpan.getSpanContext().getTraceId());\n    }\n}", "metadata": {"commit_sha": "7b70cfd0", "lines_added": 5, "lines_deleted": 2, "total_changes": 7, "chunks": 2}}
{"id": 183, "pattern_type": "variable_rename", "file_path": "spring-ai-alibaba-nl2sql/docker-file/docker-compose.yml", "file_extension": "yml", "input": "#Copyright 2024-2025 the original author or authors.\n#\n#Licensed under the Apache License, Version 2.0 (the \"License\");\n#you may not use this file except in compliance with the License.\n#You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n#Unless required by applicable law or agreed to in writing, software\n#distributed under the License is distributed on an \"AS IS\" BASIS,\n#WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#See the License for the specific language governing permissions and\n#limitations under the License.\n\nservices:\n  # MySQL数据库\n  mysql:\n    image: mysql:8.0\n    container_name: nl2sql-mysql-inner\n    environment:\n      MYSQL_ROOT_PASSWORD: root\n      MYSQL_DATABASE: nl2sql_db\n#    volumes:\n#      - nl2sql-mysql-inner-data:/var/lib/mysql\n    networks:\n      - app-network\n    restart: unless-stopped\n    healthcheck:\n      test: [ \"CMD\", \"mysqladmin\", \"ping\", \"-h\", \"localhost\", \"-u\", \"root\", \"-p$$MYSQL_ROOT_PASSWORD\" ]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\n  # 后端服务\n  backend:\n    build:\n      context: ..\n      dockerfile: ./docker-file/Dockerfile-backend\n    container_name: nl2sql-backend\n    environment:\n      - NL2SQL_DATASOURCE_URL=jdbc:mysql://mysql:3306/nl2sql_db?useSSL=false&serverTimezone=UTC&allowPublicKeyRetrieval=true\n      - NL2SQL_DATASOURCE_USERNAME=root\n      - NL2SQL_DATASOURCE_USERNAME=root\n      - AI_DASHSCOPE_API_KEY=${AI_DASHSCOPE_API_KEY}\n    ports:\n      - \"8065:8065\"\n    depends_on:\n      mysql:\n        condition: service_healthy\n      mysql-data:\n        condition: service_healthy\n      postgres-data:\n        condition: service_healthy\n    networks:\n      - app-network\n    restart: no\n\n  # Vue前端服务\n  frontend:\n    build:\n      context: ..\n      dockerfile: ./docker-file/Dockerfile-frontend\n    container_name: nl2sql-frontend\n    ports:\n      - \"3000:3000\"  # 只暴露前端端口\n    depends_on:\n      - backend\n    volumes:\n      - ./config/nginx.conf:/etc/nginx/nginx.conf\n    networks:\n      - app-network\n    restart: unless-stopped\n\n  # MySQL 模拟数据源\n  mysql-data:\n    image: mysql:8.0\n    container_name: nl2sql-mysql-datasource\n    restart: always\n    environment:\n      MYSQL_ROOT_PASSWORD: root\n    networks:\n      - app-network\n    volumes:\n      - ./config/mysql:/docker-entrypoint-initdb.d\n    command: --default-authentication-plugin=mysql_native_password\n    healthcheck:\n      test: [ \"CMD\", \"mysqladmin\", \"ping\", \"-h\", \"localhost\", \"-u\", \"root\", \"-p$$MYSQL_ROOT_PASSWORD\" ]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\n  # PostgreSQL 模拟数据源\n  postgres-data:\n    image: postgres:15\n    container_name: nl2sql-postgres-datasource\n    restart: always\n    environment:\n      POSTGRES_USER: postgres\n      POSTGRES_PASSWORD: postgres\n    networks:\n      - app-network\n    volumes:\n      - ./config/postgres:/docker-entrypoint-initdb.d\n    healthcheck:\n      test: [ \"CMD-SHELL\", \"pg_isready -U postgres\" ]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\nvolumes:\n  nl2sql-mysql-inner-data:\n\nnetworks:\n  app-network:\n    driver: bridge\n    name: \"nl2sql-network\"", "output": "#Copyright 2024-2025 the original author or authors.\n#\n#Licensed under the Apache License, Version 2.0 (the \"License\");\n#you may not use this file except in compliance with the License.\n#You may obtain a copy of the License at\n#\n#     https://www.apache.org/licenses/LICENSE-2.0\n#\n#Unless required by applicable law or agreed to in writing, software\n#distributed under the License is distributed on an \"AS IS\" BASIS,\n#WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n#See the License for the specific language governing permissions and\n#limitations under the License.\n\nservices:\n  # MySQL数据库\n  mysql:\n    image: mysql:8.0\n    container_name: nl2sql-mysql-inner\n    environment:\n      MYSQL_ROOT_PASSWORD: root\n      MYSQL_DATABASE: nl2sql_db\n#    volumes:\n#      - nl2sql-mysql-inner-data:/var/lib/mysql\n    networks:\n      - app-network\n    restart: unless-stopped\n    healthcheck:\n      test: [ \"CMD\", \"mysqladmin\", \"ping\", \"-h\", \"localhost\", \"-u\", \"root\", \"-p$$MYSQL_ROOT_PASSWORD\" ]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\n  # 后端服务\n  backend:\n    build:\n      context: ..\n      dockerfile: ./docker-file/Dockerfile-backend\n      tags:\n        - saa-nl2sql-backend:1.0.0.4-SNAPSHOT\n    container_name: nl2sql-backend\n    environment:\n      - NL2SQL_DATASOURCE_URL=jdbc:mysql://mysql:3306/nl2sql_db?useSSL=false&serverTimezone=UTC&allowPublicKeyRetrieval=true\n      - NL2SQL_DATASOURCE_USERNAME=root\n      - NL2SQL_DATASOURCE_PASSWORD=root\n      - AI_DASHSCOPE_API_KEY=${AI_DASHSCOPE_API_KEY}\n    ports:\n      - \"8065:8065\"\n    depends_on:\n      mysql:\n        condition: service_healthy\n      mysql-data:\n        condition: service_healthy\n      postgres-data:\n        condition: service_healthy\n    networks:\n      - app-network\n    restart: no\n\n  # Vue前端服务\n  frontend:\n    build:\n      context: ..\n      dockerfile: ./docker-file/Dockerfile-frontend\n      tags:\n        - saa-nl2sql-frontend:1.0.0.4-SNAPSHOT\n    container_name: nl2sql-frontend\n    ports:\n      - \"3000:3000\"  # 只暴露前端端口\n    depends_on:\n      - backend\n    volumes:\n      - ./config/nginx.conf:/etc/nginx/nginx.conf\n    networks:\n      - app-network\n    restart: unless-stopped\n\n  # MySQL 模拟数据源\n  mysql-data:\n    image: mysql:8.0\n    container_name: nl2sql-mysql-datasource\n    restart: always\n    environment:\n      MYSQL_ROOT_PASSWORD: root\n    networks:\n      - app-network\n    volumes:\n      - ./config/mysql:/docker-entrypoint-initdb.d\n    command: --default-authentication-plugin=mysql_native_password\n    healthcheck:\n      test: [ \"CMD\", \"mysqladmin\", \"ping\", \"-h\", \"localhost\", \"-u\", \"root\", \"-p$$MYSQL_ROOT_PASSWORD\" ]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\n  # PostgreSQL 模拟数据源\n  postgres-data:\n    image: postgres:15\n    container_name: nl2sql-postgres-datasource\n    restart: always\n    environment:\n      POSTGRES_USER: postgres\n      POSTGRES_PASSWORD: postgres\n    networks:\n      - app-network\n    volumes:\n      - ./config/postgres:/docker-entrypoint-initdb.d\n    healthcheck:\n      test: [ \"CMD-SHELL\", \"pg_isready -U postgres\" ]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\nvolumes:\n  nl2sql-mysql-inner-data:\n\nnetworks:\n  app-network:\n    driver: bridge\n    name: \"nl2sql-network\"", "metadata": {"commit_sha": "813886e4", "lines_added": 5, "lines_deleted": 1, "total_changes": 6, "chunks": 2}}
{"id": 38, "pattern_type": "getter_setter", "file_path": "community/document-readers/gitlab-document-reader/src/test/java/com/alibaba/cloud/ai/reader/gitlab/GitLabRepositoryReaderTest.java", "file_extension": "java", "input": "/*\n * Copyright 2024-2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.alibaba.cloud.ai.reader.gitlab;\n\nimport org.gitlab4j.api.GitLabApiException;\nimport org.junit.jupiter.api.BeforeEach;\nimport org.junit.jupiter.api.Test;\nimport org.springframework.ai.document.Document;\n\nimport java.util.List;\n\nimport static org.assertj.core.api.Assertions.assertThat;\n\n/**\n * Test cases for GitLabRepositoryReader. Using real repository from Spring AI project\n * (https://gitlab.com/spring-ai/spring-ai).\n *\n * @author brianxiadong\n */\nclass GitLabRepositoryReaderTest {\n\n\tprivate static final String TEST_HOST_URL = \"https://gitlab.com\";\n\n\tprivate static final String TEST_NAMESPACE = \"\";\n\n\tprivate static final String TEST_PROJECT_NAME = \"\";\n\n\tprivate static final String TEST_REF = \"master\";\n\n\tprivate static final String TEST_FILE_PATH = \"README.md\";\n\n\tprivate GitLabRepositoryReader reader;\n\n\t@BeforeEach\n\tvoid setUp() throws GitLabApiException {\n\t\t// Create GitLabRepositoryReader instance for accessing public project\n\t\treader = new GitLabRepositoryReader(TEST_HOST_URL, TEST_NAMESPACE, TEST_PROJECT_NAME);\n\t}\n\n\t@Test\n\tvoid testGetSingleFile() {\n\t\t// Configure reader to load a single file\n\t\tList<Document> documents = reader.setRef(TEST_REF).setFilePath(TEST_FILE_PATH).get();\n\n\t\t// Verify results\n\t\tassertThat(documents).hasSize(1);\n\t\tDocument doc = documents.get(0);\n\t\tassertThat(doc.getId()).isNotNull();\n\t\tassertThat(doc.getContent()).isNotBlank();\n\t\tassertThat(doc.getMetadata()).containsKey(\"file_path\")\n\t\t\t.containsKey(\"file_name\")\n\t\t\t.containsKey(\"url\")\n\t\t\t.containsKey(\"ref\");\n\t}\n\n\t@Test\n\tvoid testGetAllFiles() {\n\t\t// Configure reader to load all files from root directory\n\t\tList<Document> documents = reader.setRef(TEST_REF).setRecursive(true).get();\n\n\t\t// Verify results\n\t\tassertThat(documents).isNotEmpty();\n\n\t\t// Verify each document has required metadata\n\t\tfor (Document doc : documents) {\n\t\t\tassertThat(doc.getId()).isNotNull();\n\t\t\tassertThat(doc.getContent()).isNotBlank();\n\t\t\tassertThat(doc.getMetadata()).containsKey(\"file_path\")\n\t\t\t\t.containsKey(\"file_name\")\n\t\t\t\t.containsKey(\"url\")\n\t\t\t\t.containsKey(\"ref\");\n\t\t}\n\t}\n\n\t@Test\n\tvoid testGetMarkdownFiles() {\n\t\t// Configure reader to load only markdown files\n\t\tList<Document> documents = reader.setRef(TEST_REF).setPattern(\"*.md\").setRecursive(true).get();\n\n\t\t// Verify results\n\t\tassertThat(documents).isNotEmpty();\n\n\t\t// Verify all documents are markdown files\n\t\tfor (Document doc : documents) {\n\t\t\tassertThat(doc.getId()).isNotNull();\n\t\t\tassertThat(doc.getContent()).isNotBlank();\n\t\t\tassertThat(doc.getMetadata()).containsKey(\"file_path\")\n\t\t\t\t.containsKey(\"file_name\")\n\t\t\t\t.containsKey(\"url\")\n\t\t\t\t.containsKey(\"ref\");\n\n\t\t\tString filePath = (String) doc.getMetadata().get(\"file_path\");\n\t\t\tassertThat(filePath).endsWith(\".md\");\n\t\t}\n\t}\n\n\t@Test\n\tvoid testGetFilesInDirectory() {\n\t\t// Configure reader to load files from a specific directory\n\t\tList<Document> documents = reader.setRef(TEST_REF).setFilePath(\"docs\").setRecursive(true).get();\n\n\t\t// Verify results\n\t\tassertThat(documents).isNotEmpty();\n\n\t\t// Verify all files are from the docs directory\n\t\tfor (Document doc : documents) {\n\t\t\tString filePath = (String) doc.getMetadata().get(\"file_path\");\n\t\t\tassertThat(filePath).startsWith(\"docs/\");\n\t\t}\n\t}\n\n\t@Test\n\tvoid testGetFilesWithComplexPattern() {\n\t\t// Configure reader to load Java files from src directory and its subdirectories\n\t\tList<Document> documents = reader.setRef(TEST_REF).setPattern(\"src/**/*.java\").setRecursive(true).get();\n\n\t\t// Verify results\n\t\tassertThat(documents).isNotEmpty();\n\n\t\t// Verify all files match the pattern\n\t\tfor (Document doc : documents) {\n\t\t\tString filePath = (String) doc.getMetadata().get(\"file_path\");\n\t\t\tassertThat(filePath).startsWith(\"src/\").endsWith(\".java\");\n\t\t}\n\t}\n\n\t@Test\n\tvoid testGetFilesWithMetadata() {\n\t\t// Configure reader to load a single file and check metadata\n\t\tList<Document> documents = reader.setRef(TEST_REF).setFilePath(TEST_FILE_PATH).get();\n\n\t\t// Verify results\n\t\tassertThat(documents).hasSize(1);\n\t\tDocument doc = documents.get(0);\n\n\t\t// Verify required metadata fields\n\t\tassertThat(doc.getMetadata()).containsKey(\"file_path\")\n\t\t\t.containsKey(\"file_name\")\n\t\t\t.containsKey(\"size\")\n\t\t\t.containsKey(\"url\")\n\t\t\t.containsKey(\"ref\");\n\n\t\t// Verify metadata values\n\t\tassertThat(doc.getMetadata().get(\"file_path\")).isEqualTo(TEST_FILE_PATH);\n\t\tassertThat(doc.getMetadata().get(\"file_name\")).isEqualTo(\"README.md\");\n\t\tassertThat(doc.getMetadata().get(\"size\")).isInstanceOf(Integer.class);\n\t\tassertThat(doc.getMetadata().get(\"url\")).asString().contains(TEST_FILE_PATH);\n\t}\n\n}", "output": "/*\n * Copyright 2024-2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.alibaba.cloud.ai.reader.gitlab;\n\nimport org.gitlab4j.api.GitLabApiException;\nimport org.junit.jupiter.api.BeforeEach;\nimport org.junit.jupiter.api.Test;\nimport org.springframework.ai.document.Document;\n\nimport java.util.List;\n\nimport static org.assertj.core.api.Assertions.assertThat;\n\n/**\n * Test cases for GitLabRepositoryReader. Using real repository from Spring AI project\n * (https://gitlab.com/spring-ai/spring-ai).\n *\n * @author brianxiadong\n */\nclass GitLabRepositoryReaderTest {\n\n\tprivate static final String TEST_HOST_URL = \"https://gitlab.com\";\n\n\tprivate static final String TEST_NAMESPACE = \"\";\n\n\tprivate static final String TEST_PROJECT_NAME = \"\";\n\n\tprivate static final String TEST_REF = \"master\";\n\n\tprivate static final String TEST_FILE_PATH = \"README.md\";\n\n\tprivate GitLabRepositoryReader reader;\n\n\t@BeforeEach\n\tvoid setUp() throws GitLabApiException {\n\t\t// Create GitLabRepositoryReader instance for accessing public project\n\t\treader = new GitLabRepositoryReader(TEST_HOST_URL, TEST_NAMESPACE, TEST_PROJECT_NAME);\n\t}\n\n\t@Test\n\tvoid testGetSingleFile() {\n\t\t// Configure reader to load a single file\n\t\tList<Document> documents = reader.setRef(TEST_REF).setFilePath(TEST_FILE_PATH).get();\n\n\t\t// Verify results\n\t\tassertThat(documents).hasSize(1);\n\t\tDocument doc = documents.get(0);\n\t\tassertThat(doc.getId()).isNotNull();\n\t\tassertThat(doc.getContent()).isNotBlank();\n\t\tassertThat(doc.getMetadata()).containsKey(\"file_path\")\n\t\t\t.containsKey(\"file_name\")\n\t\t\t.containsKey(\"url\")\n\t\t\t.containsKey(\"ref\");\n\t}\n\n\t@Test\n\tvoid testGetAllFiles() {\n\t\t// Configure reader to load all files from root directory\n\t\tList<Document> documents = reader.setRef(TEST_REF).setRecursive(true).get();\n\n\t\t// Verify results\n\t\tassertThat(documents).isNotEmpty();\n\n\t\t// Verify each document has required metadata\n\t\tfor (Document doc : documents) {\n\t\t\tassertThat(doc.getId()).isNotNull();\n\t\t\tassertThat(doc.getText()).isNotBlank();\n\t\t\tassertThat(doc.getMetadata()).containsKey(\"file_path\")\n\t\t\t\t.containsKey(\"file_name\")\n\t\t\t\t.containsKey(\"url\")\n\t\t\t\t.containsKey(\"ref\");\n\t\t}\n\t}\n\n\t@Test\n\tvoid testGetMarkdownFiles() {\n\t\t// Configure reader to load only markdown files\n\t\tList<Document> documents = reader.setRef(TEST_REF).setPattern(\"*.md\").setRecursive(true).get();\n\n\t\t// Verify results\n\t\tassertThat(documents).isNotEmpty();\n\n\t\t// Verify all documents are markdown files\n\t\tfor (Document doc : documents) {\n\t\t\tassertThat(doc.getId()).isNotNull();\n\t\t\tassertThat(doc.getText()).isNotBlank();\n\t\t\tassertThat(doc.getMetadata()).containsKey(\"file_path\")\n\t\t\t\t.containsKey(\"file_name\")\n\t\t\t\t.containsKey(\"url\")\n\t\t\t\t.containsKey(\"ref\");\n\n\t\t\tString filePath = (String) doc.getMetadata().get(\"file_path\");\n\t\t\tassertThat(filePath).endsWith(\".md\");\n\t\t}\n\t}\n\n\t@Test\n\tvoid testGetFilesInDirectory() {\n\t\t// Configure reader to load files from a specific directory\n\t\tList<Document> documents = reader.setRef(TEST_REF).setFilePath(\"docs\").setRecursive(true).get();\n\n\t\t// Verify results\n\t\tassertThat(documents).isNotEmpty();\n\n\t\t// Verify all files are from the docs directory\n\t\tfor (Document doc : documents) {\n\t\t\tString filePath = (String) doc.getMetadata().get(\"file_path\");\n\t\t\tassertThat(filePath).startsWith(\"docs/\");\n\t\t}\n\t}\n\n\t@Test\n\tvoid testGetFilesWithComplexPattern() {\n\t\t// Configure reader to load Java files from src directory and its subdirectories\n\t\tList<Document> documents = reader.setRef(TEST_REF).setPattern(\"src/**/*.java\").setRecursive(true).get();\n\n\t\t// Verify results\n\t\tassertThat(documents).isNotEmpty();\n\n\t\t// Verify all files match the pattern\n\t\tfor (Document doc : documents) {\n\t\t\tString filePath = (String) doc.getMetadata().get(\"file_path\");\n\t\t\tassertThat(filePath).startsWith(\"src/\").endsWith(\".java\");\n\t\t}\n\t}\n\n\t@Test\n\tvoid testGetFilesWithMetadata() {\n\t\t// Configure reader to load a single file and check metadata\n\t\tList<Document> documents = reader.setRef(TEST_REF).setFilePath(TEST_FILE_PATH).get();\n\n\t\t// Verify results\n\t\tassertThat(documents).hasSize(1);\n\t\tDocument doc = documents.get(0);\n\n\t\t// Verify required metadata fields\n\t\tassertThat(doc.getMetadata()).containsKey(\"file_path\")\n\t\t\t.containsKey(\"file_name\")\n\t\t\t.containsKey(\"size\")\n\t\t\t.containsKey(\"url\")\n\t\t\t.containsKey(\"ref\");\n\n\t\t// Verify metadata values\n\t\tassertThat(doc.getMetadata().get(\"file_path\")).isEqualTo(TEST_FILE_PATH);\n\t\tassertThat(doc.getMetadata().get(\"file_name\")).isEqualTo(\"README.md\");\n\t\tassertThat(doc.getMetadata().get(\"size\")).isInstanceOf(Integer.class);\n\t\tassertThat(doc.getMetadata().get(\"url\")).asString().contains(TEST_FILE_PATH);\n\t}\n\n}", "metadata": {"commit_sha": "c0987eb2", "lines_added": 2, "lines_deleted": 2, "total_changes": 4, "chunks": 2}}
{"id": 79, "pattern_type": "import_statement", "file_path": "spring-ai-alibaba-graph/spring-ai-alibaba-graph-studio/src/main/java/com/alibaba/cloud/ai/model/workflow/nodedata/VariableAggregatorNodeData.java", "file_extension": "java", "input": "/*\n * Copyright 2024-2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.alibaba.cloud.ai.model.workflow.nodedata;\n\nimport com.alibaba.cloud.ai.model.Variable;\nimport com.alibaba.cloud.ai.model.VariableSelector;\nimport com.alibaba.cloud.ai.model.workflow.NodeData;\n\nimport java.util.List;\n\npublic class VariableAggregatorNodeData extends NodeData {\n\n\tprivate List<List<String>> variables;\n\n\tprivate String outputType;\n\n\tprivate AdvancedSettings advancedSettings;\n\n\tpublic List<List<String>> getVariables() {\n\t\treturn variables;\n\t}\n\n\tpublic VariableAggregatorNodeData setVariables(List<List<String>> variables) {\n\t\tthis.variables = variables;\n\t\treturn this;\n\t}\n\n\tpublic String getOutputType() {\n\t\treturn outputType;\n\t}\n\n\tpublic VariableAggregatorNodeData setOutputType(String outputType) {\n\t\tthis.outputType = outputType;\n\t\treturn this;\n\t}\n\n\tpublic AdvancedSettings getAdvancedSettings() {\n\t\treturn advancedSettings;\n\t}\n\n\tpublic VariableAggregatorNodeData setAdvancedSettings(AdvancedSettings advancedSettings) {\n\t\tthis.advancedSettings = advancedSettings;\n\t\treturn this;\n\t}\n\n\tpublic VariableAggregatorNodeData(List<VariableSelector> inputs, List<Variable> outputs,\n\t\t\tList<List<String>> variables, String outputType, AdvancedSettings advancedSettings) {\n\t\tsuper(inputs, outputs);\n\t\tthis.variables = variables;\n\t\tthis.outputType = outputType;\n\t\tthis.advancedSettings = advancedSettings;\n\t}\n\n\tpublic static class Groups {\n\n\t\tprivate String outputType;\n\n\t\tprivate List<List<String>> variables;\n\n\t\tprivate String groupName;\n\n\t\tprivate String groupId;\n\n\t\tpublic String getOutputType() {\n\t\t\treturn outputType;\n\t\t}\n\n\t\tpublic Groups setOutputType(String outputType) {\n\t\t\tthis.outputType = outputType;\n\t\t\treturn this;\n\t\t}\n\n\t\tpublic List<List<String>> getVariables() {\n\t\t\treturn variables;\n\t\t}\n\n\t\tpublic Groups setVariables(List<List<String>> variables) {\n\t\t\tthis.variables = variables;\n\t\t\treturn this;\n\t\t}\n\n\t\tpublic String getGroupName() {\n\t\t\treturn groupName;\n\t\t}\n\n\t\tpublic Groups setGroupName(String groupName) {\n\t\t\tthis.groupName = groupName;\n\t\t\treturn this;\n\t\t}\n\n\t\tpublic String getGroupId() {\n\t\t\treturn groupId;\n\t\t}\n\n\t\tpublic Groups setGroupId(String groupId) {\n\t\t\tthis.groupId = groupId;\n\t\t\treturn this;\n\t\t}\n\n\t}\n\n\tpublic static class AdvancedSettings {\n\n\t\tprivate boolean groupEnabled;\n\n\t\tprivate List<Groups> groups;\n\n\t\tpublic boolean isGroupEnabled() {\n\t\t\treturn groupEnabled;\n\t\t}\n\n\t\tpublic AdvancedSettings setGroupEnabled(boolean groupEnabled) {\n\t\t\tthis.groupEnabled = groupEnabled;\n\t\t\treturn this;\n\t\t}\n\n\t\tpublic List<Groups> getGroups() {\n\t\t\treturn groups;\n\t\t}\n\n\t\tpublic AdvancedSettings setGroups(List<Groups> groups) {\n\t\t\tthis.groups = groups;\n\t\t\treturn this;\n\t\t}\n\n\t}\n\n}", "output": "/*\n * Copyright 2024-2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.alibaba.cloud.ai.model.workflow.nodedata;\n\nimport com.alibaba.cloud.ai.model.Variable;\nimport com.alibaba.cloud.ai.model.VariableSelector;\nimport com.alibaba.cloud.ai.model.workflow.NodeData;\nimport com.fasterxml.jackson.annotation.JsonProperty;\n\nimport java.util.List;\n\npublic class VariableAggregatorNodeData extends NodeData {\n\n\tprivate List<List<String>> variables;\n\n\tprivate String outputType;\n\n\tprivate AdvancedSettings advancedSettings;\n\n\tpublic List<List<String>> getVariables() {\n\t\treturn variables;\n\t}\n\n\tpublic VariableAggregatorNodeData setVariables(List<List<String>> variables) {\n\t\tthis.variables = variables;\n\t\treturn this;\n\t}\n\n\tpublic String getOutputType() {\n\t\treturn outputType;\n\t}\n\n\tpublic VariableAggregatorNodeData setOutputType(String outputType) {\n\t\tthis.outputType = outputType;\n\t\treturn this;\n\t}\n\n\tpublic AdvancedSettings getAdvancedSettings() {\n\t\treturn advancedSettings;\n\t}\n\n\tpublic VariableAggregatorNodeData setAdvancedSettings(AdvancedSettings advancedSettings) {\n\t\tthis.advancedSettings = advancedSettings;\n\t\treturn this;\n\t}\n\n\tpublic VariableAggregatorNodeData(List<VariableSelector> inputs, List<Variable> outputs,\n\t\t\tList<List<String>> variables, String outputType, AdvancedSettings advancedSettings) {\n\t\tsuper(inputs, outputs);\n\t\tthis.variables = variables;\n\t\tthis.outputType = outputType;\n\t\tthis.advancedSettings = advancedSettings;\n\t}\n\n\tpublic static class Groups {\n\n\t\t@JsonProperty(\"output_type\")\n\t\tprivate String outputType;\n\n\t\tprivate List<List<String>> variables;\n\n\t\t@JsonProperty(\"group_name\")\n\t\tprivate String groupName;\n\n\t\tprivate String groupId;\n\n\t\tpublic String getOutputType() {\n\t\t\treturn outputType;\n\t\t}\n\n\t\tpublic Groups setOutputType(String outputType) {\n\t\t\tthis.outputType = outputType;\n\t\t\treturn this;\n\t\t}\n\n\t\tpublic List<List<String>> getVariables() {\n\t\t\treturn variables;\n\t\t}\n\n\t\tpublic Groups setVariables(List<List<String>> variables) {\n\t\t\tthis.variables = variables;\n\t\t\treturn this;\n\t\t}\n\n\t\tpublic String getGroupName() {\n\t\t\treturn groupName;\n\t\t}\n\n\t\tpublic Groups setGroupName(String groupName) {\n\t\t\tthis.groupName = groupName;\n\t\t\treturn this;\n\t\t}\n\n\t\tpublic String getGroupId() {\n\t\t\treturn groupId;\n\t\t}\n\n\t\tpublic Groups setGroupId(String groupId) {\n\t\t\tthis.groupId = groupId;\n\t\t\treturn this;\n\t\t}\n\n\t}\n\n\tpublic static class AdvancedSettings {\n\n\t\tprivate boolean groupEnabled;\n\n\t\tprivate List<Groups> groups;\n\n\t\tpublic boolean isGroupEnabled() {\n\t\t\treturn groupEnabled;\n\t\t}\n\n\t\tpublic AdvancedSettings setGroupEnabled(boolean groupEnabled) {\n\t\t\tthis.groupEnabled = groupEnabled;\n\t\t\treturn this;\n\t\t}\n\n\t\tpublic List<Groups> getGroups() {\n\t\t\treturn groups;\n\t\t}\n\n\t\tpublic AdvancedSettings setGroups(List<Groups> groups) {\n\t\t\tthis.groups = groups;\n\t\t\treturn this;\n\t\t}\n\n\t}\n\n}", "metadata": {"commit_sha": "79d30658", "lines_added": 3, "lines_deleted": 0, "total_changes": 3, "chunks": 2}}
{"id": 57, "pattern_type": "import_statement", "file_path": "community/memories/spring-ai-alibaba-mysql-memory/src/main/java/com/alibaba/cloud/ai/memory/mysql/MysqlChatMemory.java", "file_extension": "java", "input": "/*\n * Copyright 2024-2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.alibaba.cloud.ai.memory.mysql;\n\nimport java.sql.DriverManager;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\nimport java.sql.Statement;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.sql.Connection;\n\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport com.fasterxml.jackson.core.type.TypeReference;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport org.springframework.ai.chat.memory.ChatMemory;\nimport org.springframework.ai.chat.messages.Message;\n\npublic class MysqlChatMemory implements ChatMemory, AutoCloseable {\n\n\tprivate static final Logger logger = LoggerFactory.getLogger(MysqlChatMemory.class);\n\n\tprivate static final String DEFAULT_DATABASE = \"spring_ai_alibaba_mysql\";\n\n\tprivate static final String DEFAULT_TABLE_NAME = \"chat_memory\";\n\n\tprivate static final String DEFAULT_URL = \"127.0.0.1:3306\";\n\n\tprivate static final String DEFAULT_USERNAME = \"root\";\n\n\tprivate static final String DEFAULT_PASSWORD = \"root\";\n\n\tprivate final Connection connection;\n\n\tprivate final ObjectMapper objectMapper = new ObjectMapper();\n\n\tpublic MysqlChatMemory() {\n\n\t\tthis(DEFAULT_USERNAME, DEFAULT_PASSWORD, DEFAULT_URL);\n\t}\n\n\tpublic MysqlChatMemory(String username, String password, String url) {\n\n\t\ttry {\n\t\t\tthis.connection = DriverManager.getConnection(\n\t\t\t\t\tString.format(\"jdbc:mysql://%s/%s?serverTimezone=UTC\", url, DEFAULT_DATABASE), username, password);\n\t\t\tcheckAndCreateTable();\n\t\t}\n\t\tcatch (SQLException e) {\n\t\t\tthrow new RuntimeException(\"Error connecting to the database\", e);\n\t\t}\n\t}\n\n\tpublic MysqlChatMemory(Connection connection) {\n\n\t\tthis.connection = connection;\n\n\t\ttry {\n\t\t\tcheckAndCreateTable();\n\t\t}\n\t\tcatch (SQLException e) {\n\t\t\tthrow new RuntimeException(\"Error checking the database table\", e);\n\t\t}\n\t}\n\n\tprivate void checkAndCreateTable() throws SQLException {\n\n\t\tString checkTableQuery = String.format(\"SHOW TABLES LIKE '%s'\", DEFAULT_TABLE_NAME);\n\t\ttry (Statement stmt = connection.createStatement(); ResultSet rs = stmt.executeQuery(checkTableQuery)) {\n\n\t\t\tif (rs.next()) {\n\t\t\t\tlogger.info(\"Table \" + DEFAULT_TABLE_NAME + \" exists.\");\n\t\t\t}\n\t\t\telse {\n\t\t\t\tlogger.info(\"Table \" + DEFAULT_TABLE_NAME + \" does not exist. Creating table...\");\n\t\t\t\tcreateTable();\n\t\t\t}\n\t\t}\n\t}\n\n\tprivate void createTable() {\n\t\ttry (Statement stmt = connection.createStatement()) {\n\t\t\tstmt.execute(\"USE spring_ai_alibaba_mysql\");\n\t\t\tstmt.execute(\n\t\t\t\t\t\"CREATE TABLE chat_memory( id BIGINT AUTO_INCREMENT PRIMARY KEY,conversation_id  VARBINARY(256)  NULL,messages VARBINARY(6144) NULL,UNIQUE (conversation_id));\");\n\t\t\tlogger.info(\"Table \" + DEFAULT_TABLE_NAME + \" created successfully.\");\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new RuntimeException(\"Error creating table \" + DEFAULT_TABLE_NAME + \" \", e);\n\t\t}\n\t}\n\n\t@Override\n\tpublic void add(String conversationId, List<Message> messages) {\n\t\ttry {\n\t\t\tList<Message> all = this.selectMessageById(conversationId);\n\n\t\t\tall.addAll(messages);\n\n\t\t\tthis.updateMessageById(conversationId, this.objectMapper.writeValueAsString(all));\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlogger.error(\"Error adding messages to MySQL chat memory\", e);\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n\t@Override\n\tpublic List<Message> get(String conversationId, int lastN) {\n\t\tList<Message> all;\n\t\ttry {\n\t\t\tall = this.selectMessageById(conversationId);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlogger.error(\"Error getting messages from MySQL chat memory\", e);\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t\treturn all != null ? all.stream().skip(Math.max(0, all.size() - lastN)).toList() : List.of();\n\t}\n\n\t@Override\n\tpublic void clear(String conversationId) {\n\t\tStringBuilder sql = new StringBuilder(\"DELETE FROM \" + DEFAULT_TABLE_NAME + \" WHERE conversation_id = '\");\n\t\tsql.append(conversationId);\n\t\tsql.append(\"'\");\n\t\ttry (Statement stmt = connection.createStatement()) {\n\t\t\tstmt.executeUpdate(sql.toString());\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new RuntimeException(\"Error executing delete \", e);\n\t\t}\n\n\t}\n\n\t@Override\n\tpublic void close() throws Exception {\n\n\t\tif (connection != null) {\n\t\t\tconnection.close();\n\t\t}\n\t}\n\n\tpublic void clearOverLimit(String conversationId, int maxLimit, int deleteSize) {\n\t\ttry {\n\t\t\tList<Message> all = this.selectMessageById(conversationId);\n\n\t\t\tif (all.size() >= maxLimit) {\n\t\t\t\tall = all.stream().skip(Math.max(0, deleteSize)).toList();\n\t\t\t\tthis.updateMessageById(conversationId, this.objectMapper.writeValueAsString(all));\n\t\t\t}\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlogger.error(\"Error clearing messages from MySQL chat memory\", e);\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n\tpublic List<Message> selectMessageById(String conversationId) {\n\t\tList<Message> totalMessage = new ArrayList<>();\n\t\tStringBuilder sql = new StringBuilder(\n\t\t\t\t\"SELECT messages FROM \" + DEFAULT_TABLE_NAME + \" WHERE conversation_id = '\");\n\t\tsql.append(conversationId);\n\t\tsql.append(\"'\");\n\t\ttry (Statement stmt = connection.createStatement()) {\n\t\t\tResultSet resultSet = stmt.executeQuery(sql.toString());\n\t\t\tString oldMessage;\n\t\t\twhile (resultSet.next()) {\n\t\t\t\toldMessage = resultSet.getString(\"messages\");\n\t\t\t\tif (oldMessage != null && !oldMessage.isEmpty()) {\n\t\t\t\t\tList<Message> all = this.objectMapper.readValue(oldMessage, new TypeReference<>() {\n\t\t\t\t\t});\n\t\t\t\t\ttotalMessage.addAll(all);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tcatch (SQLException | JsonProcessingException e) {\n\t\t\tlogger.error(\"select message by mysql error，sql:{}\", sql, e);\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t\treturn totalMessage;\n\t}\n\n\tpublic void updateMessageById(String conversationId, String messages) {\n\t\tStringBuilder sql;\n\t\tif (this.selectMessageById(conversationId).isEmpty()) {\n\t\t\tsql = new StringBuilder(\"INSERT INTO \" + DEFAULT_TABLE_NAME + \" (conversation_id, messages) VALUES ('\");\n\t\t\tsql.append(conversationId);\n\t\t\tsql.append(\"', '\");\n\t\t\tsql.append(messages);\n\t\t\tsql.append(\"')\");\n\t\t}\n\t\telse {\n\t\t\tsql = new StringBuilder(\"UPDATE \" + DEFAULT_TABLE_NAME + \" SET messages = '\");\n\t\t\tsql.append(messages);\n\t\t\tsql.append(\"' WHERE conversation_id = '\");\n\t\t\tsql.append(conversationId);\n\t\t\tsql.append(\"'\");\n\t\t}\n\t\ttry (Statement stmt = connection.createStatement()) {\n\t\t\tstmt.executeUpdate(sql.toString());\n\t\t}\n\t\tcatch (SQLException e) {\n\t\t\tlogger.error(\"update message by mysql error，sql:{}\", sql, e);\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n}", "output": "/*\n * Copyright 2024-2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.alibaba.cloud.ai.memory.mysql;\n\nimport java.sql.DriverManager;\nimport java.sql.ResultSet;\nimport java.sql.SQLException;\nimport java.sql.Statement;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.sql.Connection;\n\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport com.fasterxml.jackson.core.type.TypeReference;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport com.fasterxml.jackson.databind.module.SimpleModule;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport org.springframework.ai.chat.memory.ChatMemory;\nimport org.springframework.ai.chat.messages.Message;\n\nimport com.alibaba.cloud.ai.memory.mysql.serializer.MessageDeserializer;\n\npublic class MysqlChatMemory implements ChatMemory, AutoCloseable {\n\n\tprivate static final Logger logger = LoggerFactory.getLogger(MysqlChatMemory.class);\n\n\tprivate static final String DEFAULT_DATABASE = \"spring_ai_alibaba_mysql\";\n\n\tprivate static final String DEFAULT_TABLE_NAME = \"chat_memory\";\n\n\tprivate static final String DEFAULT_URL = \"127.0.0.1:3306\";\n\n\tprivate static final String DEFAULT_USERNAME = \"root\";\n\n\tprivate static final String DEFAULT_PASSWORD = \"root\";\n\n\tprivate final Connection connection;\n\n\tprivate final ObjectMapper objectMapper = new ObjectMapper();\n\n\tpublic MysqlChatMemory() {\n\n\t\tthis(DEFAULT_USERNAME, DEFAULT_PASSWORD, DEFAULT_URL);\n\t}\n\n\tpublic MysqlChatMemory(String username, String password, String url) {\n\t\t// 配置ObjectMapper以支持接口反序列化\n\t\tSimpleModule module = new SimpleModule();\n\t\tmodule.addDeserializer(Message.class, new MessageDeserializer());\n\t\tthis.objectMapper.registerModule(module);\n\n\t\ttry {\n\t\t\tthis.connection = DriverManager.getConnection(\n\t\t\t\t\tString.format(\"jdbc:mysql://%s/%s?serverTimezone=UTC\", url, DEFAULT_DATABASE), username, password);\n\t\t\tcheckAndCreateTable();\n\t\t}\n\t\tcatch (SQLException e) {\n\t\t\tthrow new RuntimeException(\"Error connecting to the database\", e);\n\t\t}\n\t}\n\n\tpublic MysqlChatMemory(Connection connection) {\n\t\t// 配置ObjectMapper以支持接口反序列化\n\t\tSimpleModule module = new SimpleModule();\n\t\tmodule.addDeserializer(Message.class, new MessageDeserializer());\n\t\tthis.objectMapper.registerModule(module);\n\n\t\tthis.connection = connection;\n\n\t\ttry {\n\t\t\tcheckAndCreateTable();\n\t\t}\n\t\tcatch (SQLException e) {\n\t\t\tthrow new RuntimeException(\"Error checking the database table\", e);\n\t\t}\n\t}\n\n\tprivate void checkAndCreateTable() throws SQLException {\n\n\t\tString checkTableQuery = String.format(\"SHOW TABLES LIKE '%s'\", DEFAULT_TABLE_NAME);\n\t\ttry (Statement stmt = connection.createStatement(); ResultSet rs = stmt.executeQuery(checkTableQuery)) {\n\n\t\t\tif (rs.next()) {\n\t\t\t\tlogger.info(\"Table \" + DEFAULT_TABLE_NAME + \" exists.\");\n\t\t\t}\n\t\t\telse {\n\t\t\t\tlogger.info(\"Table \" + DEFAULT_TABLE_NAME + \" does not exist. Creating table...\");\n\t\t\t\tcreateTable();\n\t\t\t}\n\t\t}\n\t}\n\n\tprivate void createTable() {\n\t\ttry (Statement stmt = connection.createStatement()) {\n\t\t\tstmt.execute(\"USE spring_ai_alibaba_mysql\");\n\t\t\tstmt.execute(\n\t\t\t\t\t\"CREATE TABLE chat_memory( id BIGINT AUTO_INCREMENT PRIMARY KEY,conversation_id  VARBINARY(256)  NULL,messages VARBINARY(6144) NULL,UNIQUE (conversation_id));\");\n\t\t\tlogger.info(\"Table \" + DEFAULT_TABLE_NAME + \" created successfully.\");\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new RuntimeException(\"Error creating table \" + DEFAULT_TABLE_NAME + \" \", e);\n\t\t}\n\t}\n\n\t@Override\n\tpublic void add(String conversationId, List<Message> messages) {\n\t\ttry {\n\t\t\tList<Message> all = this.selectMessageById(conversationId);\n\n\t\t\tall.addAll(messages);\n\n\t\t\tthis.updateMessageById(conversationId, this.objectMapper.writeValueAsString(all));\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlogger.error(\"Error adding messages to MySQL chat memory\", e);\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n\t@Override\n\tpublic List<Message> get(String conversationId, int lastN) {\n\t\tList<Message> all;\n\t\ttry {\n\t\t\tall = this.selectMessageById(conversationId);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlogger.error(\"Error getting messages from MySQL chat memory\", e);\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t\treturn all != null ? all.stream().skip(Math.max(0, all.size() - lastN)).toList() : List.of();\n\t}\n\n\t@Override\n\tpublic void clear(String conversationId) {\n\t\tStringBuilder sql = new StringBuilder(\"DELETE FROM \" + DEFAULT_TABLE_NAME + \" WHERE conversation_id = '\");\n\t\tsql.append(conversationId);\n\t\tsql.append(\"'\");\n\t\ttry (Statement stmt = connection.createStatement()) {\n\t\t\tstmt.executeUpdate(sql.toString());\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new RuntimeException(\"Error executing delete \", e);\n\t\t}\n\n\t}\n\n\t@Override\n\tpublic void close() throws Exception {\n\n\t\tif (connection != null) {\n\t\t\tconnection.close();\n\t\t}\n\t}\n\n\tpublic void clearOverLimit(String conversationId, int maxLimit, int deleteSize) {\n\t\ttry {\n\t\t\tList<Message> all = this.selectMessageById(conversationId);\n\n\t\t\tif (all.size() >= maxLimit) {\n\t\t\t\tall = all.stream().skip(Math.max(0, deleteSize)).toList();\n\t\t\t\tthis.updateMessageById(conversationId, this.objectMapper.writeValueAsString(all));\n\t\t\t}\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlogger.error(\"Error clearing messages from MySQL chat memory\", e);\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n\tpublic List<Message> selectMessageById(String conversationId) {\n\t\tList<Message> totalMessage = new ArrayList<>();\n\t\tStringBuilder sql = new StringBuilder(\n\t\t\t\t\"SELECT messages FROM \" + DEFAULT_TABLE_NAME + \" WHERE conversation_id = '\");\n\t\tsql.append(conversationId);\n\t\tsql.append(\"'\");\n\t\ttry (Statement stmt = connection.createStatement()) {\n\t\t\tResultSet resultSet = stmt.executeQuery(sql.toString());\n\t\t\tString oldMessage;\n\t\t\twhile (resultSet.next()) {\n\t\t\t\toldMessage = resultSet.getString(\"messages\");\n\t\t\t\tif (oldMessage != null && !oldMessage.isEmpty()) {\n\t\t\t\t\tList<Message> all = this.objectMapper.readValue(oldMessage, new TypeReference<>() {\n\t\t\t\t\t});\n\t\t\t\t\ttotalMessage.addAll(all);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tcatch (SQLException | JsonProcessingException e) {\n\t\t\tlogger.error(\"select message by mysql error，sql:{}\", sql, e);\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t\treturn totalMessage;\n\t}\n\n\tpublic void updateMessageById(String conversationId, String messages) {\n\t\tStringBuilder sql;\n\t\tif (this.selectMessageById(conversationId).isEmpty()) {\n\t\t\tsql = new StringBuilder(\"INSERT INTO \" + DEFAULT_TABLE_NAME + \" (conversation_id, messages) VALUES ('\");\n\t\t\tsql.append(conversationId);\n\t\t\tsql.append(\"', '\");\n\t\t\tsql.append(messages);\n\t\t\tsql.append(\"')\");\n\t\t}\n\t\telse {\n\t\t\tsql = new StringBuilder(\"UPDATE \" + DEFAULT_TABLE_NAME + \" SET messages = '\");\n\t\t\tsql.append(messages);\n\t\t\tsql.append(\"' WHERE conversation_id = '\");\n\t\t\tsql.append(conversationId);\n\t\t\tsql.append(\"'\");\n\t\t}\n\t\ttry (Statement stmt = connection.createStatement()) {\n\t\t\tstmt.executeUpdate(sql.toString());\n\t\t}\n\t\tcatch (SQLException e) {\n\t\t\tlogger.error(\"update message by mysql error，sql:{}\", sql, e);\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n}", "metadata": {"commit_sha": "f420b2ad", "lines_added": 11, "lines_deleted": 0, "total_changes": 11, "chunks": 2}}
{"id": 158, "pattern_type": "import_statement", "file_path": "spring-ai-alibaba-jmanus/src/main/java/com/alibaba/cloud/ai/example/manus/tool/FormInputTool.java", "file_extension": "java", "input": "/*\n * Copyright 2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.alibaba.cloud.ai.example.manus.tool;\n\nimport com.alibaba.cloud.ai.example.manus.tool.code.ToolExecuteResult;\nimport com.alibaba.cloud.ai.example.manus.dynamic.prompt.service.PromptService;\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.ai.openai.api.OpenAiApi;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.stereotype.Component;\n\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\n\n/**\n * LLM form input tool: supports multiple input items with labels and descriptions.\n */\n@Component\npublic class FormInputTool extends AbstractBaseTool<FormInputTool.UserFormInput> {\n\n\tprivate final ObjectMapper objectMapper;\n\n\t@Autowired\n\tprivate PromptService promptService;\n\n\tprivate static final Logger log = LoggerFactory.getLogger(FormInputTool.class);\n\n\tprivate String getToolParameters() {\n\t\ttry {\n\t\t\treturn promptService.getPromptByName(\"FORM_INPUT_TOOL_PARAMETERS\").getPromptContent();\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlog.warn(\"Failed to load prompt-based tool parameters, using legacy configuration\", e);\n\t\t\treturn LEGACY_PARAMETERS;\n\t\t}\n\t}\n\n\tprivate String getToolDescription() {\n\t\ttry {\n\t\t\treturn promptService.getPromptByName(\"FORM_INPUT_TOOL_DESCRIPTION\").getPromptContent();\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlog.warn(\"Failed to load prompt-based tool description, using legacy configuration\", e);\n\t\t\treturn LEGACY_DESCRIPTION;\n\t\t}\n\t}\n\n\tprivate static final String LEGACY_PARAMETERS = \"\"\"\n\t\t\t{\n\t\t\t  \"type\": \"object\",\n\t\t\t  \"properties\": {\n\t\t\t    \"inputs\": {\n\t\t\t      \"type\": \"array\",\n\t\t\t      \"description\": \"List of input items, each containing label and value fields\",\n\t\t\t      \"items\": {\n\t\t\t        \"type\": \"object\",\n\t\t\t        \"properties\": {\n\t\t\t          \"label\": { \"type\": \"string\", \"description\": \"Input item label\" },\n\t\t\t          \"value\": { \"type\": \"string\", \"description\": \"Input content\" }\n\t\t\t        },\n\t\t\t        \"required\": [\"label\"]\n\t\t\t      }\n\t\t\t    },\n\t\t\t    \"description\": {\n\t\t\t      \"type\": \"string\",\n\t\t\t      \"description\": \"Instructions on how to fill these input items\"\n\t\t\t    }\n\t\t\t  },\n\t\t\t  \"required\": [ \"description\"]\n\t\t\t}\n\t\t\t\"\"\";\n\n\tpublic static final String name = \"form_input\";\n\n\tprivate static final String LEGACY_DESCRIPTION = \"\"\"\n\t\t\tProvides a labeled multi-input form tool.\n\n\t\t\tLLM can use this tool to let users submit 0 or more input items (each with label and content), along with filling instructions.\n\t\t\tAllows users to submit 0 input items.\n\t\t\tSuitable for scenarios requiring structured input and can also be used when the model needs to wait for user input before continuing.\n\t\t\t\"\"\";\n\n\tpublic OpenAiApi.FunctionTool getToolDefinition() {\n\t\ttry {\n\t\t\tOpenAiApi.FunctionTool.Function function = new OpenAiApi.FunctionTool.Function(getToolDescription(), name,\n\t\t\t\t\tgetToolParameters());\n\t\t\treturn new OpenAiApi.FunctionTool(function);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlog.warn(\"Failed to load prompt-based tool definition, using legacy configuration\", e);\n\t\t\tOpenAiApi.FunctionTool.Function function = new OpenAiApi.FunctionTool.Function(LEGACY_DESCRIPTION, name,\n\t\t\t\t\tLEGACY_PARAMETERS);\n\t\t\treturn new OpenAiApi.FunctionTool(function);\n\t\t}\n\t}\n\n\t// Data structures:\n\t/**\n\t * Form input item containing label and corresponding value.\n\t */\n\tpublic static class InputItem {\n\n\t\tprivate String label;\n\n\t\tprivate String value;\n\n\t\tpublic InputItem() {\n\t\t}\n\n\t\tpublic InputItem(String label, String value) {\n\t\t\tthis.label = label;\n\t\t\tthis.value = value;\n\t\t}\n\n\t\tpublic String getLabel() {\n\t\t\treturn label;\n\t\t}\n\n\t\tpublic void setLabel(String label) {\n\t\t\tthis.label = label;\n\t\t}\n\n\t\tpublic String getValue() {\n\t\t\treturn value;\n\t\t}\n\n\t\tpublic void setValue(String value) {\n\t\t\tthis.value = value;\n\t\t}\n\n\t}\n\n\t/**\n\t * User-submitted form data containing list of input items and description.\n\t */\n\tpublic static class UserFormInput {\n\n\t\tprivate List<InputItem> inputs;\n\n\t\tprivate String description;\n\n\t\tpublic UserFormInput() {\n\t\t}\n\n\t\tpublic UserFormInput(List<InputItem> inputs, String description) {\n\t\t\tthis.inputs = inputs;\n\t\t\tthis.description = description;\n\t\t}\n\n\t\tpublic List<InputItem> getInputs() {\n\t\t\treturn inputs;\n\t\t}\n\n\t\tpublic void setInputs(List<InputItem> inputs) {\n\t\t\tthis.inputs = inputs;\n\t\t}\n\n\t\tpublic String getDescription() {\n\t\t\treturn description;\n\t\t}\n\n\t\tpublic void setDescription(String description) {\n\t\t\tthis.description = description;\n\t\t}\n\n\t}\n\n\tpublic FormInputTool(ObjectMapper objectMapper) {\n\t\tthis.objectMapper = objectMapper;\n\t}\n\n\tpublic enum InputState {\n\n\t\tAWAITING_USER_INPUT, INPUT_RECEIVED, INPUT_TIMEOUT\n\n\t}\n\n\tprivate InputState inputState = InputState.INPUT_RECEIVED; // Default state\n\n\tprivate UserFormInput currentFormDefinition; // Stores the form structure defined by\n\t\t\t\t\t\t\t\t\t\t\t\t\t// LLM and its current values\n\n\tpublic InputState getInputState() {\n\t\treturn inputState;\n\t}\n\n\tpublic void setInputState(InputState inputState) {\n\t\tthis.inputState = inputState;\n\t}\n\n\t@Override\n\tpublic ToolExecuteResult run(UserFormInput formInput) {\n\t\tlog.info(\"FormInputTool input: {}\", formInput);\n\n\t\tthis.currentFormDefinition = formInput;\n\t\t// Initialize values to empty string if null, to ensure they are present for\n\t\t// form binding\n\t\tif (this.currentFormDefinition != null && this.currentFormDefinition.getInputs() != null) {\n\t\t\tfor (InputItem item : this.currentFormDefinition.getInputs()) {\n\t\t\t\tif (item.getValue() == null) {\n\t\t\t\t\titem.setValue(\"\"); // Initialize with empty string\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tsetInputState(InputState.AWAITING_USER_INPUT);\n\n\t\t// Return form definition as a structured result\n\t\ttry {\n\t\t\tString formJson = objectMapper.writeValueAsString(formInput);\n\t\t\treturn new ToolExecuteResult(formJson);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlog.error(\"Error serializing form input\", e);\n\t\t\treturn new ToolExecuteResult(\"{\\\"error\\\": \\\"Failed to process form input: \" + e.getMessage() + \"\\\"}\");\n\t\t}\n\t}\n\n\t/**\n\t * Get the latest form structure defined by LLM (including description and input item\n\t * labels and current values). This form structure will be used to present to users in\n\t * the frontend.\n\t * @return latest UserFormInput object, or null if not yet defined.\n\t */\n\tpublic UserFormInput getLatestUserFormInput() {\n\t\treturn this.currentFormDefinition;\n\t}\n\n\t/**\n\t * Set user-submitted form input values. These values will update the value of\n\t * corresponding input items in currentFormDefinition.\n\t * @param submittedItems list of input items submitted by user (label-value pairs).\n\t */\n\tpublic void setUserFormInputValues(List<InputItem> submittedItems) {\n\t\tif (this.currentFormDefinition == null || this.currentFormDefinition.getInputs() == null) {\n\t\t\tlog.warn(\"Cannot set user form input values: form definition is missing or has no inputs.\");\n\t\t\treturn;\n\t\t}\n\t\tif (submittedItems == null) {\n\t\t\tlog.warn(\"Submitted items are null. No values to update.\");\n\t\t\treturn;\n\t\t}\n\n\t\tMap<String, String> submittedValuesMap = new HashMap<>();\n\t\tfor (InputItem submittedItem : submittedItems) {\n\t\t\tif (submittedItem.getLabel() != null) {\n\t\t\t\tsubmittedValuesMap.put(submittedItem.getLabel(), submittedItem.getValue());\n\t\t\t}\n\t\t}\n\n\t\tfor (InputItem definitionItem : this.currentFormDefinition.getInputs()) {\n\t\t\tif (definitionItem.getLabel() != null && submittedValuesMap.containsKey(definitionItem.getLabel())) {\n\t\t\t\tdefinitionItem.setValue(submittedValuesMap.get(definitionItem.getLabel()));\n\t\t\t}\n\t\t}\n\t\t// The caller (UserInputService) is responsible for calling\n\t\t// markUserInputReceived()\n\t}\n\n\tpublic void markUserInputReceived() {\n\t\tsetInputState(InputState.INPUT_RECEIVED);\n\t}\n\n\tpublic void handleInputTimeout() {\n\t\tlog.warn(\"Input timeout occurred. No input received from the user for form: {}\",\n\t\t\t\tthis.currentFormDefinition != null ? this.currentFormDefinition.getDescription() : \"N/A\");\n\t\tsetInputState(InputState.INPUT_TIMEOUT);\n\t\tthis.currentFormDefinition = null; // Clear form definition on timeout\n\t}\n\n\t@Override\n\tpublic String getName() {\n\t\treturn name;\n\t}\n\n\t@Override\n\tpublic String getDescription() {\n\t\treturn getToolDescription();\n\t}\n\n\t@Override\n\tpublic String getParameters() {\n\t\treturn getToolParameters();\n\t}\n\n\t@Override\n\tpublic Class<UserFormInput> getInputType() {\n\t\treturn UserFormInput.class;\n\t}\n\n\t@Override\n\tpublic boolean isReturnDirect() {\n\t\treturn true;\n\t}\n\n\t@Override\n\tpublic void cleanup(String planId) {\n\t\t// Optional implementation\n\t}\n\n\t@Override\n\tpublic String getServiceGroup() {\n\t\treturn \"default-service-group\";\n\t}\n\n\t/**\n\t * Get current tool state, including form description and input items (including\n\t * user-entered values if any)\n\t */\n\t@Override\n\tpublic String getCurrentToolStateString() {\n\t\tif (currentFormDefinition == null) {\n\t\t\treturn String.format(\"FormInputTool Status: No form defined. Current input state: %s\",\n\t\t\t\t\tinputState.toString());\n\t\t}\n\t\ttry {\n\t\t\tStringBuilder stateBuilder = new StringBuilder(\"FormInputTool Status:\\n\");\n\t\t\tstateBuilder\n\t\t\t\t.append(String.format(\"Description: %s\\nInput Items: %s\\n\", currentFormDefinition.getDescription(),\n\t\t\t\t\t\tobjectMapper.writeValueAsString(currentFormDefinition.getInputs())));\n\t\t\tstateBuilder.append(String.format(\"Current input state: %s\\n\", inputState.toString()));\n\t\t\treturn stateBuilder.toString();\n\t\t}\n\t\tcatch (JsonProcessingException e) {\n\t\t\tlog.error(\"Error serializing currentFormDefinition for state string\", e);\n\t\t\treturn String.format(\"FormInputTool Status: Error serializing input items. Current input state: %s\",\n\t\t\t\t\tinputState.toString());\n\t\t}\n\t}\n\n}", "output": "/*\n * Copyright 2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.alibaba.cloud.ai.example.manus.tool;\n\nimport com.alibaba.cloud.ai.example.manus.dynamic.prompt.service.PromptService;\nimport com.alibaba.cloud.ai.example.manus.tool.code.ToolExecuteResult;\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport com.fasterxml.jackson.databind.ObjectMapper;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.ai.openai.api.OpenAiApi;\nimport org.springframework.stereotype.Component;\n\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\n\n/**\n * LLM form input tool: supports multiple input items with labels and descriptions.\n */\n@Component\npublic class FormInputTool extends AbstractBaseTool<FormInputTool.UserFormInput> {\n\n\tprivate final ObjectMapper objectMapper;\n\n\tprivate final PromptService promptService;\n\n\tprivate static final Logger log = LoggerFactory.getLogger(FormInputTool.class);\n\n\tprivate String getToolParameters() {\n\t\ttry {\n\t\t\treturn promptService.getPromptByName(\"FORM_INPUT_TOOL_PARAMETERS\").getPromptContent();\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlog.warn(\"Failed to load prompt-based tool parameters, using legacy configuration\", e);\n\t\t\treturn LEGACY_PARAMETERS;\n\t\t}\n\t}\n\n\tprivate String getToolDescription() {\n\t\ttry {\n\t\t\treturn promptService.getPromptByName(\"FORM_INPUT_TOOL_DESCRIPTION\").getPromptContent();\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlog.warn(\"Failed to load prompt-based tool description, using legacy configuration\", e);\n\t\t\treturn LEGACY_DESCRIPTION;\n\t\t}\n\t}\n\n\tprivate static final String LEGACY_PARAMETERS = \"\"\"\n\t\t\t{\n\t\t\t  \"type\": \"object\",\n\t\t\t  \"properties\": {\n\t\t\t    \"inputs\": {\n\t\t\t      \"type\": \"array\",\n\t\t\t      \"description\": \"List of input items, each containing label and value fields\",\n\t\t\t      \"items\": {\n\t\t\t        \"type\": \"object\",\n\t\t\t        \"properties\": {\n\t\t\t          \"label\": { \"type\": \"string\", \"description\": \"Input item label\" },\n\t\t\t          \"value\": { \"type\": \"string\", \"description\": \"Input content\" }\n\t\t\t        },\n\t\t\t        \"required\": [\"label\"]\n\t\t\t      }\n\t\t\t    },\n\t\t\t    \"description\": {\n\t\t\t      \"type\": \"string\",\n\t\t\t      \"description\": \"Instructions on how to fill these input items\"\n\t\t\t    }\n\t\t\t  },\n\t\t\t  \"required\": [ \"description\"]\n\t\t\t}\n\t\t\t\"\"\";\n\n\tpublic static final String name = \"form_input\";\n\n\tprivate static final String LEGACY_DESCRIPTION = \"\"\"\n\t\t\tProvides a labeled multi-input form tool.\n\n\t\t\tLLM can use this tool to let users submit 0 or more input items (each with label and content), along with filling instructions.\n\t\t\tAllows users to submit 0 input items.\n\t\t\tSuitable for scenarios requiring structured input and can also be used when the model needs to wait for user input before continuing.\n\t\t\t\"\"\";\n\n\tpublic OpenAiApi.FunctionTool getToolDefinition() {\n\t\ttry {\n\t\t\tOpenAiApi.FunctionTool.Function function = new OpenAiApi.FunctionTool.Function(getToolDescription(), name,\n\t\t\t\t\tgetToolParameters());\n\t\t\treturn new OpenAiApi.FunctionTool(function);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlog.warn(\"Failed to load prompt-based tool definition, using legacy configuration\", e);\n\t\t\tOpenAiApi.FunctionTool.Function function = new OpenAiApi.FunctionTool.Function(LEGACY_DESCRIPTION, name,\n\t\t\t\t\tLEGACY_PARAMETERS);\n\t\t\treturn new OpenAiApi.FunctionTool(function);\n\t\t}\n\t}\n\n\t// Data structures:\n\t/**\n\t * Form input item containing label and corresponding value.\n\t */\n\tpublic static class InputItem {\n\n\t\tprivate String label;\n\n\t\tprivate String value;\n\n\t\tpublic InputItem() {\n\t\t}\n\n\t\tpublic InputItem(String label, String value) {\n\t\t\tthis.label = label;\n\t\t\tthis.value = value;\n\t\t}\n\n\t\tpublic String getLabel() {\n\t\t\treturn label;\n\t\t}\n\n\t\tpublic void setLabel(String label) {\n\t\t\tthis.label = label;\n\t\t}\n\n\t\tpublic String getValue() {\n\t\t\treturn value;\n\t\t}\n\n\t\tpublic void setValue(String value) {\n\t\t\tthis.value = value;\n\t\t}\n\n\t}\n\n\t/**\n\t * User-submitted form data containing list of input items and description.\n\t */\n\tpublic static class UserFormInput {\n\n\t\tprivate List<InputItem> inputs;\n\n\t\tprivate String description;\n\n\t\tpublic UserFormInput() {\n\t\t}\n\n\t\tpublic UserFormInput(List<InputItem> inputs, String description) {\n\t\t\tthis.inputs = inputs;\n\t\t\tthis.description = description;\n\t\t}\n\n\t\tpublic List<InputItem> getInputs() {\n\t\t\treturn inputs;\n\t\t}\n\n\t\tpublic void setInputs(List<InputItem> inputs) {\n\t\t\tthis.inputs = inputs;\n\t\t}\n\n\t\tpublic String getDescription() {\n\t\t\treturn description;\n\t\t}\n\n\t\tpublic void setDescription(String description) {\n\t\t\tthis.description = description;\n\t\t}\n\n\t}\n\n\tpublic FormInputTool(ObjectMapper objectMapper, PromptService promptService) {\n\t\tthis.objectMapper = objectMapper;\n\t\tthis.promptService = promptService;\n\t}\n\n\tpublic enum InputState {\n\n\t\tAWAITING_USER_INPUT, INPUT_RECEIVED, INPUT_TIMEOUT\n\n\t}\n\n\tprivate InputState inputState = InputState.INPUT_RECEIVED; // Default state\n\n\tprivate UserFormInput currentFormDefinition; // Stores the form structure defined by\n\t\t\t\t\t\t\t\t\t\t\t\t\t// LLM and its current values\n\n\tpublic InputState getInputState() {\n\t\treturn inputState;\n\t}\n\n\tpublic void setInputState(InputState inputState) {\n\t\tthis.inputState = inputState;\n\t}\n\n\t@Override\n\tpublic ToolExecuteResult run(UserFormInput formInput) {\n\t\tlog.info(\"FormInputTool input: {}\", formInput);\n\n\t\tthis.currentFormDefinition = formInput;\n\t\t// Initialize values to empty string if null, to ensure they are present for\n\t\t// form binding\n\t\tif (this.currentFormDefinition != null && this.currentFormDefinition.getInputs() != null) {\n\t\t\tfor (InputItem item : this.currentFormDefinition.getInputs()) {\n\t\t\t\tif (item.getValue() == null) {\n\t\t\t\t\titem.setValue(\"\"); // Initialize with empty string\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tsetInputState(InputState.AWAITING_USER_INPUT);\n\n\t\t// Return form definition as a structured result\n\t\ttry {\n\t\t\tString formJson = objectMapper.writeValueAsString(formInput);\n\t\t\treturn new ToolExecuteResult(formJson);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlog.error(\"Error serializing form input\", e);\n\t\t\treturn new ToolExecuteResult(\"{\\\"error\\\": \\\"Failed to process form input: \" + e.getMessage() + \"\\\"}\");\n\t\t}\n\t}\n\n\t/**\n\t * Get the latest form structure defined by LLM (including description and input item\n\t * labels and current values). This form structure will be used to present to users in\n\t * the frontend.\n\t * @return latest UserFormInput object, or null if not yet defined.\n\t */\n\tpublic UserFormInput getLatestUserFormInput() {\n\t\treturn this.currentFormDefinition;\n\t}\n\n\t/**\n\t * Set user-submitted form input values. These values will update the value of\n\t * corresponding input items in currentFormDefinition.\n\t * @param submittedItems list of input items submitted by user (label-value pairs).\n\t */\n\tpublic void setUserFormInputValues(List<InputItem> submittedItems) {\n\t\tif (this.currentFormDefinition == null || this.currentFormDefinition.getInputs() == null) {\n\t\t\tlog.warn(\"Cannot set user form input values: form definition is missing or has no inputs.\");\n\t\t\treturn;\n\t\t}\n\t\tif (submittedItems == null) {\n\t\t\tlog.warn(\"Submitted items are null. No values to update.\");\n\t\t\treturn;\n\t\t}\n\n\t\tMap<String, String> submittedValuesMap = new HashMap<>();\n\t\tfor (InputItem submittedItem : submittedItems) {\n\t\t\tif (submittedItem.getLabel() != null) {\n\t\t\t\tsubmittedValuesMap.put(submittedItem.getLabel(), submittedItem.getValue());\n\t\t\t}\n\t\t}\n\n\t\tfor (InputItem definitionItem : this.currentFormDefinition.getInputs()) {\n\t\t\tif (definitionItem.getLabel() != null && submittedValuesMap.containsKey(definitionItem.getLabel())) {\n\t\t\t\tdefinitionItem.setValue(submittedValuesMap.get(definitionItem.getLabel()));\n\t\t\t}\n\t\t}\n\t\t// The caller (UserInputService) is responsible for calling\n\t\t// markUserInputReceived()\n\t}\n\n\tpublic void markUserInputReceived() {\n\t\tsetInputState(InputState.INPUT_RECEIVED);\n\t}\n\n\tpublic void handleInputTimeout() {\n\t\tlog.warn(\"Input timeout occurred. No input received from the user for form: {}\",\n\t\t\t\tthis.currentFormDefinition != null ? this.currentFormDefinition.getDescription() : \"N/A\");\n\t\tsetInputState(InputState.INPUT_TIMEOUT);\n\t\tthis.currentFormDefinition = null; // Clear form definition on timeout\n\t}\n\n\t@Override\n\tpublic String getName() {\n\t\treturn name;\n\t}\n\n\t@Override\n\tpublic String getDescription() {\n\t\treturn getToolDescription();\n\t}\n\n\t@Override\n\tpublic String getParameters() {\n\t\treturn getToolParameters();\n\t}\n\n\t@Override\n\tpublic Class<UserFormInput> getInputType() {\n\t\treturn UserFormInput.class;\n\t}\n\n\t@Override\n\tpublic boolean isReturnDirect() {\n\t\treturn true;\n\t}\n\n\t@Override\n\tpublic void cleanup(String planId) {\n\t\t// Optional implementation\n\t}\n\n\t@Override\n\tpublic String getServiceGroup() {\n\t\treturn \"default-service-group\";\n\t}\n\n\t/**\n\t * Get current tool state, including form description and input items (including\n\t * user-entered values if any)\n\t */\n\t@Override\n\tpublic String getCurrentToolStateString() {\n\t\tif (currentFormDefinition == null) {\n\t\t\treturn String.format(\"FormInputTool Status: No form defined. Current input state: %s\",\n\t\t\t\t\tinputState.toString());\n\t\t}\n\t\ttry {\n\t\t\tStringBuilder stateBuilder = new StringBuilder(\"FormInputTool Status:\\n\");\n\t\t\tstateBuilder\n\t\t\t\t.append(String.format(\"Description: %s\\nInput Items: %s\\n\", currentFormDefinition.getDescription(),\n\t\t\t\t\t\tobjectMapper.writeValueAsString(currentFormDefinition.getInputs())));\n\t\t\tstateBuilder.append(String.format(\"Current input state: %s\\n\", inputState.toString()));\n\t\t\treturn stateBuilder.toString();\n\t\t}\n\t\tcatch (JsonProcessingException e) {\n\t\t\tlog.error(\"Error serializing currentFormDefinition for state string\", e);\n\t\t\treturn String.format(\"FormInputTool Status: Error serializing input items. Current input state: %s\",\n\t\t\t\t\tinputState.toString());\n\t\t}\n\t}\n\n}", "metadata": {"commit_sha": "92276951", "lines_added": 4, "lines_deleted": 5, "total_changes": 9, "chunks": 2}}
{"id": 150, "pattern_type": "other", "file_path": "spring-ai-alibaba-nl2sql/spring-ai-alibaba-nl2sql-chat/src/main/java/com/alibaba/cloud/ai/tool/PythonReplTool.java", "file_extension": "java", "input": "/*\n * Copyright 2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage com.alibaba.cloud.ai.tool;\n\nimport com.alibaba.cloud.ai.config.PythonCoderProperties;\nimport com.github.dockerjava.api.DockerClient;\nimport com.github.dockerjava.api.async.ResultCallback;\nimport com.github.dockerjava.api.command.CreateContainerResponse;\nimport com.github.dockerjava.api.command.InspectContainerResponse;\nimport com.github.dockerjava.api.command.LogContainerCmd;\nimport com.github.dockerjava.api.model.*;\nimport com.github.dockerjava.core.DefaultDockerClientConfig;\nimport com.github.dockerjava.core.DockerClientConfig;\nimport com.github.dockerjava.core.DockerClientImpl;\nimport com.github.dockerjava.zerodep.ZerodepDockerHttpClient;\nimport org.jetbrains.annotations.NotNull;\nimport org.jetbrains.annotations.Nullable;\nimport org.springframework.ai.tool.annotation.Tool;\nimport org.springframework.ai.tool.annotation.ToolParam;\nimport org.springframework.stereotype.Service;\nimport org.springframework.util.StringUtils;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.nio.charset.Charset;\nimport java.nio.file.FileVisitResult;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.nio.file.SimpleFileVisitor;\nimport java.nio.file.attribute.BasicFileAttributes;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Objects;\nimport java.util.concurrent.TimeUnit;\nimport java.util.logging.Logger;\n\nimport static com.github.dockerjava.api.model.HostConfig.newHostConfig;\n\n@Service\npublic class PythonReplTool {\n\n\tprivate static final Logger logger = Logger.getLogger(PythonReplTool.class.getName());\n\n\tprivate final PythonCoderProperties coderProperties;\n\n\tpublic PythonReplTool(PythonCoderProperties coderProperties) {\n\t\tthis.coderProperties = coderProperties;\n\t}\n\n\t@Tool(description = \"Execute Python code and return the result.\")\n\tpublic String executePythonCode(@ToolParam(description = \"python code\") String code,\n\t\t\t@ToolParam(description = \"requirements.txt\", required = false) String requirements,\n\t\t\t@ToolParam(description = \"input data for the python script\", required = false) String data) {\n\t\tif (code == null || code.trim().isEmpty()) {\n\t\t\treturn \"Error: Code must be a non-empty string.\";\n\t\t}\n\t\tif (!StringUtils.hasText(coderProperties.getContainNamePrefix())\n\t\t\t\t|| !StringUtils.hasText(coderProperties.getDockerHost())\n\t\t\t\t|| (coderProperties.getCpuCore() == null || coderProperties.getCpuCore() <= 0)\n\t\t\t\t|| (coderProperties.getLimitMemory() == null || coderProperties.getLimitMemory() <= 0)\n\t\t\t\t|| !StringUtils.hasText(coderProperties.getCodeTimeout())\n\t\t\t\t|| !StringUtils.hasText(coderProperties.getImageName())) {\n\t\t\treturn \"Error: Some Config is not set. You should reporter it to developer.\";\n\t\t}\n\n\t\t// 自动检测操作系统并设置合适的Docker Host\n\t\tString dockerHost = getDockerHostForCurrentOS();\n\n\t\tDockerClientConfig config = DefaultDockerClientConfig.createDefaultConfigBuilder()\n\t\t\t.withDockerHost(dockerHost)\n\t\t\t.withDockerTlsVerify(false)\n\t\t\t.build();\n\n\t\tPath tempDir = null; // Declare tempDir outside try-with-resources for finally\n\t\t\t\t\t\t\t\t// block\n\t\tString volumeName = null; // Declare volumeName outside try-with-resources for\n\t\t\t\t\t\t\t\t\t// finally block\n\t\tDockerClient dockerClient = null; // Declare dockerClient outside\n\t\t\t\t\t\t\t\t\t\t\t// try-with-resources\n\n\t\ttry {\n\t\t\t// 使用带回退机制的Docker客户端创建方法\n\t\t\tdockerClient = createDockerClientWithFallback(config);\n\n\t\t\t// Create temp dir and files\n\t\t\ttempDir = Files.createTempDirectory(coderProperties.getContainNamePrefix());\n\t\t\tFiles.createFile(tempDir.resolve(\"requirements.txt\"));\n\t\t\tFiles.createFile(tempDir.resolve(\"script.py\"));\n\t\t\tFiles.write(tempDir.resolve(\"requirements.txt\"),\n\t\t\t\t\tStringUtils.hasText(requirements) ? requirements.getBytes() : \"\".getBytes());\n\t\t\tFiles.write(tempDir.resolve(\"script.py\"), code.getBytes());\n\n\t\t\tboolean hasData = StringUtils.hasText(data);\n\t\t\tif (hasData) {\n\t\t\t\tFiles.createFile(tempDir.resolve(\"input_data.txt\"));\n\t\t\t\tFiles.write(tempDir.resolve(\"input_data.txt\"), data.getBytes());\n\t\t\t}\n\n\t\t\t// Build a docker to run\n\t\t\tString containName = generateUniqueContainerName();\n\n\t\t\t// create a volume to save third-party dependencies\n\t\t\tvolumeName = containName.concat(\"-volume\");\n\n\t\t\t// 先清理可能存在的同名容器和卷\n\t\t\tcleanupExistingResources(dockerClient, containName, volumeName);\n\n\t\t\tdockerClient.createVolumeCmd().withName(volumeName).withDriver(\"local\").exec();\n\n\t\t\tif (!coderProperties.isEnableNetwork() && StringUtils.hasText(requirements)) {\n\t\t\t\t// If Python code is restricted from network access but requires\n\t\t\t\t// third-party dependencies, we need to provision a docker for pip to\n\t\t\t\t// install the dependencies.\n\t\t\t\tHostConfig hostConfig = createHostConfig(tempDir, volumeName, hasData);\n\n\t\t\t\tString pipContainerName = containName + \"-pip\";\n\t\t\t\tCreateContainerResponse pipContainer = dockerClient.createContainerCmd(coderProperties.getImageName())\n\t\t\t\t\t.withName(pipContainerName)\n\t\t\t\t\t.withWorkingDir(\"/app\")\n\t\t\t\t\t.withHostConfig(hostConfig)\n\t\t\t\t\t.withCmd(\"sh\", \"-c\",\n\t\t\t\t\t\t\t\"pip3 install --target=/app/dependency --no-cache-dir -r requirements.txt > /dev/null\")\n\t\t\t\t\t.exec();\n\t\t\t\ttry {\n\t\t\t\t\tthis.execDockerContainer(dockerClient, pipContainer);\n\t\t\t\t}\n\t\t\t\tcatch (Exception e) {\n\t\t\t\t\treturn \"Error installing requirements: \" + e.getMessage();\n\t\t\t\t}\n\t\t\t\tfinally {\n\t\t\t\t\t// 立即清理pip容器\n\t\t\t\t\ttry {\n\t\t\t\t\t\tdockerClient.removeContainerCmd(pipContainer.getId()).withForce(true).exec();\n\t\t\t\t\t\tlogger.info(\"Removed pip container: \" + pipContainerName);\n\t\t\t\t\t}\n\t\t\t\t\tcatch (Exception ignore) {\n\t\t\t\t\t\t// Ignore cleanup errors\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// run python code in docker\n\t\t\tHostConfig hostConfig = createHostConfig(tempDir, volumeName, hasData)\n\t\t\t\t.withNetworkMode(coderProperties.isEnableNetwork() ? \"bridge\" : \"none\");\n\n\t\t\tString execContainerName = containName + \"-exec\";\n\t\t\tCreateContainerResponse container = dockerClient.createContainerCmd(coderProperties.getImageName())\n\t\t\t\t.withName(execContainerName)\n\t\t\t\t.withWorkingDir(\"/app\")\n\t\t\t\t.withHostConfig(hostConfig)\n\t\t\t\t.withCmd(\"sh\", \"-c\", String.format(((coderProperties.isEnableNetwork() && StringUtils\n\t\t\t\t\t.hasText(requirements))\n\t\t\t\t\t\t\t? \"pip3 install --target=/app/dependency --no-cache-dir -r requirements.txt > /dev/null && \"\n\t\t\t\t\t\t\t: \"\")\n\t\t\t\t\t\t+ \"export PYTHONPATH=\\\"/app/dependency:$PYTHONPATH\\\" && timeout -s SIGKILL %s python3 script.py\",\n\t\t\t\t\t\tcoderProperties.getCodeTimeout()))\n\t\t\t\t.exec();\n\t\t\ttry {\n\t\t\t\tString output = this.execDockerContainer(dockerClient, container);\n\t\t\t\tlogger.info(\"Python code executed successfully.\");\n\t\t\t\treturn \"Successfully executed:\\n```\\n\" + code + \"\\n```\\nStdout:\\n\" + output;\n\t\t\t}\n\t\t\tcatch (Exception e) {\n\t\t\t\tlogger.warning(\"Python code execution failed.\");\n\t\t\t\treturn \"Error executing code:\\n```\\n\" + code + \"\\n```\\nError:\\n\" + e.getMessage();\n\t\t\t}\n\t\t\tfinally {\n\t\t\t\t// This finally block will execute before the outer one, ensuring\n\t\t\t\t// container is removed\n\t\t\t\t// before tempDir and volume are cleaned up.\n\t\t\t\ttry {\n\t\t\t\t\tdockerClient.removeContainerCmd(container.getId()).withForce(true).exec();\n\t\t\t\t}\n\t\t\t\tcatch (Exception ignore) {\n\t\t\t\t\t// Ignore exceptions during container removal\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlogger.warning(\"Exception during execution: \" + e.getMessage());\n\t\t\treturn \"Error executing code:\\n```\\n\" + code + \"\\n```\\nError:\\n\" + e.getMessage();\n\t\t}\n\t\tfinally {\n\t\t\t// Ensure temp resources are cleaned up even if an exception occurs earlier\n\t\t\tif (tempDir != null && volumeName != null && dockerClient != null) {\n\t\t\t\tthis.clearTempResource(tempDir, dockerClient, volumeName);\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * clean some temp resource before return\n\t */\n\tprivate void clearTempResource(Path tempDir, DockerClient dockerClient, String volumeName) {\n\t\ttry {\n\t\t\tFiles.walkFileTree(tempDir, new SimpleFileVisitor<>() {\n\t\t\t\t@NotNull\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult visitFile(@NotNull Path file, @NotNull BasicFileAttributes attrs)\n\t\t\t\t\t\tthrows IOException {\n\t\t\t\t\tFiles.delete(file);\n\t\t\t\t\treturn super.visitFile(file, attrs);\n\t\t\t\t}\n\n\t\t\t\t@NotNull\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult postVisitDirectory(@NotNull Path dir, @Nullable IOException exc)\n\t\t\t\t\t\tthrows IOException {\n\t\t\t\t\tif (exc != null)\n\t\t\t\t\t\tthrow exc;\n\t\t\t\t\tFiles.delete(dir);\n\t\t\t\t\treturn super.postVisitDirectory(dir, exc);\n\t\t\t\t}\n\t\t\t});\n\t\t\tlogger.info(\"Temp directory has been deleted.\");\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlogger.warning(\"Exception in clean temp directory: \" + e.getMessage());\n\t\t}\n\t\ttry {\n\t\t\t// remove volume before return\n\t\t\tdockerClient.removeVolumeCmd(volumeName).exec();\n\t\t}\n\t\tcatch (Exception ignore) {\n\t\t}\n\t}\n\n\t/**\n\t * Create container's HostConfig\n\t */\n\tprivate HostConfig createHostConfig(Path tempDir, String volumeName, boolean hasData) {\n\t\tList<Bind> binds = new ArrayList<>();\n\t\tbinds.add(new Bind(tempDir.resolve(\"script.py\").toAbsolutePath().toString(), new Volume(\"/app/script.py\"),\n\t\t\t\tAccessMode.ro));\n\t\tbinds.add(new Bind(tempDir.resolve(\"requirements.txt\").toAbsolutePath().toString(),\n\t\t\t\tnew Volume(\"/app/requirements.txt\"), AccessMode.ro));\n\t\tbinds.add(new Bind(volumeName, new Volume(\"/app/dependency\")));\n\n\t\tif (hasData) {\n\t\t\tbinds.add(new Bind(tempDir.resolve(\"input_data.txt\").toAbsolutePath().toString(),\n\t\t\t\t\tnew Volume(\"/app/input_data.txt\"), AccessMode.ro));\n\t\t}\n\n\t\treturn newHostConfig().withMemory(coderProperties.getLimitMemory() * 1024L * 1024L)\n\t\t\t.withCpuCount(coderProperties.getCpuCore())\n\t\t\t.withCapDrop(Capability.ALL)\n\t\t\t.withAutoRemove(false)\n\t\t\t.withBinds(binds.toArray(new Bind[0]))\n\t\t\t.withTmpFs(Map.of(\"/tmp\", \"\"));\n\t}\n\n\t/**\n\t * Run a Docker container and return its stdout. Throw a RuntimeException if errors\n\t * occur.\n\t */\n\tprivate String execDockerContainer(DockerClient dockerClient, CreateContainerResponse container)\n\t\t\tthrows RuntimeException {\n\t\t// catch stdout and stderr\n\t\tByteArrayOutputStream stdout = new ByteArrayOutputStream();\n\t\tByteArrayOutputStream stderr = new ByteArrayOutputStream();\n\n\t\ttry {\n\t\t\t// start docker\n\t\t\tdockerClient.startContainerCmd(container.getId()).exec();\n\t\t\tLogContainerCmd logContainerCmd = dockerClient.logContainerCmd(container.getId())\n\t\t\t\t.withStdOut(true)\n\t\t\t\t.withStdErr(true)\n\t\t\t\t.withFollowStream(true)\n\t\t\t\t.withTailAll();\n\t\t\tdockerClient.waitContainerCmd(container.getId())\n\t\t\t\t.start()\n\t\t\t\t.awaitCompletion(coderProperties.getDockerTimeout(), TimeUnit.SECONDS);\n\n\t\t\t// get stdout and stderr\n\t\t\tlogContainerCmd.exec(new ResultCallback.Adapter<Frame>() {\n\t\t\t\t@Override\n\t\t\t\tpublic void onNext(Frame frame) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tif (frame.getStreamType() == StreamType.STDOUT) {\n\t\t\t\t\t\t\tstdout.write(frame.getPayload());\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse if (frame.getStreamType() == StreamType.STDERR) {\n\t\t\t\t\t\t\tstderr.write(frame.getPayload());\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tcatch (Exception ignore) {\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}).awaitCompletion();\n\n\t\t\t// get exit code\n\t\t\tInspectContainerResponse inspectResponse = dockerClient.inspectContainerCmd(container.getId()).exec();\n\t\t\tint exitCode = Objects.requireNonNull(inspectResponse.getState().getExitCodeLong()).intValue();\n\t\t\tif (exitCode != 0) {\n\t\t\t\tString errorMessage = \"Docker exit code \" + exitCode + \". Stderr: \"\n\t\t\t\t\t\t+ stderr.toString(Charset.defaultCharset()) + \". Stdout: \"\n\t\t\t\t\t\t+ stdout.toString(Charset.defaultCharset());\n\t\t\t\tthrow new RuntimeException(errorMessage);\n\t\t\t}\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlogger.severe(\"Error when creating container in docker: {}\" + e.getMessage());\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t\tfinally {\n\t\t\t// Container removal is now handled in the outer try-catch-finally block\n\t\t\t// to ensure it's removed even if execDockerContainer throws an exception.\n\t\t}\n\t\treturn stdout.toString(Charset.defaultCharset());\n\t}\n\n\t/**\n\t * 根据当前操作系统自动选择合适的Docker Host地址\n\t * @return Docker Host URI\n\t */\n\tprivate String getDockerHostForCurrentOS() {\n\t\tString osName = System.getProperty(\"os.name\").toLowerCase();\n\t\tlogger.info(\"Detected operating system: \" + osName);\n\n\t\tif (osName.contains(\"win\")) {\n\t\t\t// Windows系统\n\t\t\tlogger.info(\"Using Windows Docker configuration\");\n\t\t\t// 在Windows上优先尝试TCP连接，更稳定\n\t\t\treturn \"tcp://localhost:2375\";\n\t\t}\n\t\telse if (osName.contains(\"nix\") || osName.contains(\"nux\") || osName.contains(\"aix\")) {\n\t\t\t// Linux/Unix系统\n\t\t\tlogger.info(\"Using Linux/Unix Docker configuration\");\n\t\t\treturn \"unix:///var/run/docker.sock\";\n\t\t}\n\t\telse if (osName.contains(\"mac\")) {\n\t\t\t// macOS系统\n\t\t\tlogger.info(\"Using macOS Docker configuration\");\n\t\t\treturn \"unix:///var/run/docker.sock\";\n\t\t}\n\t\telse {\n\t\t\t// 未知系统，使用配置文件中的默认值\n\t\t\tlogger.warning(\"Unknown operating system: \" + osName + \", using configured docker host\");\n\t\t\treturn coderProperties.getDockerHost();\n\t\t}\n\t}\n\n\t/**\n\t * 创建Docker客户端，支持多种连接方式的回退机制\n\t * @param config Docker客户端配置\n\t * @return DockerClient实例\n\t * @throws Exception 如果所有连接方式都失败\n\t */\n\tprivate DockerClient createDockerClientWithFallback(DockerClientConfig config) throws Exception {\n\t\tString osName = System.getProperty(\"os.name\").toLowerCase();\n\n\t\tif (osName.contains(\"win\")) {\n\t\t\t// Windows系统：尝试多种连接方式\n\t\t\tString[] windowsHosts = { \"tcp://localhost:2375\", // TCP方式（需要在Docker\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// Desktop中启用）\n\t\t\t\t\t\"npipe://./pipe/docker_engine\" // 命名管道方式\n\t\t\t};\n\n\t\t\tfor (String dockerHost : windowsHosts) {\n\t\t\t\ttry {\n\t\t\t\t\tlogger.info(\"Attempting to connect to Docker using: \" + dockerHost);\n\n\t\t\t\t\tDockerClientConfig testConfig = DefaultDockerClientConfig.createDefaultConfigBuilder()\n\t\t\t\t\t\t.withDockerHost(dockerHost)\n\t\t\t\t\t\t.withDockerTlsVerify(false)\n\t\t\t\t\t\t.build();\n\n\t\t\t\t\tZerodepDockerHttpClient httpClient = new ZerodepDockerHttpClient.Builder()\n\t\t\t\t\t\t.dockerHost(testConfig.getDockerHost())\n\t\t\t\t\t\t.sslConfig(testConfig.getSSLConfig())\n\t\t\t\t\t\t.build();\n\n\t\t\t\t\tDockerClient dockerClient = DockerClientImpl.getInstance(testConfig, httpClient);\n\n\t\t\t\t\t// 测试连接是否正常\n\t\t\t\t\tdockerClient.pingCmd().exec();\n\t\t\t\t\tlogger.info(\"Successfully connected to Docker using: \" + dockerHost);\n\t\t\t\t\treturn dockerClient;\n\n\t\t\t\t}\n\t\t\t\tcatch (Exception e) {\n\t\t\t\t\tlogger.warning(\"Failed to connect using \" + dockerHost + \": \" + e.getMessage());\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// 如果所有Windows连接方式都失败\n\t\t\tthrow new Exception(\n\t\t\t\t\t\"Failed to connect to Docker on Windows. Please ensure Docker Desktop is running and either:\\n\"\n\t\t\t\t\t\t\t+ \"1. Enable 'Expose daemon on tcp://localhost:2375 without TLS' in Docker Desktop settings, or\\n\"\n\t\t\t\t\t\t\t+ \"2. Ensure Docker Desktop's named pipe is available\");\n\n\t\t}\n\t\telse {\n\t\t\t// Linux/Unix/macOS系统：使用标准Unix socket\n\t\t\ttry {\n\t\t\t\tZerodepDockerHttpClient httpClient = new ZerodepDockerHttpClient.Builder()\n\t\t\t\t\t.dockerHost(config.getDockerHost())\n\t\t\t\t\t.sslConfig(config.getSSLConfig())\n\t\t\t\t\t.build();\n\n\t\t\t\tDockerClient dockerClient = DockerClientImpl.getInstance(config, httpClient);\n\t\t\t\tdockerClient.pingCmd().exec(); // 测试连接\n\t\t\t\tlogger.info(\"Successfully connected to Docker using: \" + config.getDockerHost());\n\t\t\t\treturn dockerClient;\n\n\t\t\t}\n\t\t\tcatch (Exception e) {\n\t\t\t\tthrow new Exception(\"Failed to connect to Docker on \" + osName + \": \" + e.getMessage()\n\t\t\t\t\t\t+ \"\\nPlease ensure Docker is running and accessible at: \" + config.getDockerHost());\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * 清理已存在的同名容器和卷\n\t */\n\tprivate void cleanupExistingResources(DockerClient dockerClient, String containName, String volumeName) {\n\t\ttry {\n\t\t\t// 尝试删除同名容器\n\t\t\tdockerClient.removeContainerCmd(containName).withForce(true).exec();\n\t\t\tlogger.info(\"Removed existing container: \" + containName);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlogger.warning(\"Failed to remove container \" + containName + \": \" + e.getMessage());\n\t\t}\n\n\t\ttry {\n\t\t\t// 尝试删除同名卷\n\t\t\tdockerClient.removeVolumeCmd(volumeName).exec();\n\t\t\tlogger.info(\"Removed existing volume: \" + volumeName);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlogger.warning(\"Failed to remove volume \" + volumeName + \": \" + e.getMessage());\n\t\t}\n\t}\n\n\t/**\n\t * 生成唯一的容器名称\n\t */\n\tprivate String generateUniqueContainerName() {\n\t\treturn coderProperties.getContainNamePrefix() + \"_\" + System.currentTimeMillis();\n\t}\n\n}", "output": "/*\n * Copyright 2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage com.alibaba.cloud.ai.tool;\n\nimport com.alibaba.cloud.ai.config.PythonCoderProperties;\nimport com.github.dockerjava.api.DockerClient;\nimport com.github.dockerjava.api.async.ResultCallback;\nimport com.github.dockerjava.api.command.CreateContainerResponse;\nimport com.github.dockerjava.api.command.InspectContainerResponse;\nimport com.github.dockerjava.api.command.LogContainerCmd;\nimport com.github.dockerjava.api.model.*;\nimport com.github.dockerjava.core.DefaultDockerClientConfig;\nimport com.github.dockerjava.core.DockerClientConfig;\nimport com.github.dockerjava.core.DockerClientImpl;\nimport com.github.dockerjava.zerodep.ZerodepDockerHttpClient;\nimport org.jetbrains.annotations.NotNull;\nimport org.jetbrains.annotations.Nullable;\nimport org.springframework.ai.tool.annotation.Tool;\nimport org.springframework.ai.tool.annotation.ToolParam;\nimport org.springframework.util.StringUtils;\n\nimport java.io.ByteArrayOutputStream;\nimport java.io.IOException;\nimport java.nio.charset.Charset;\nimport java.nio.file.FileVisitResult;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.nio.file.SimpleFileVisitor;\nimport java.nio.file.attribute.BasicFileAttributes;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Objects;\nimport java.util.concurrent.TimeUnit;\nimport java.util.logging.Logger;\n\nimport static com.github.dockerjava.api.model.HostConfig.newHostConfig;\n\n//@Service\npublic class PythonReplTool {\n\n\tprivate static final Logger logger = Logger.getLogger(PythonReplTool.class.getName());\n\n\tprivate final PythonCoderProperties coderProperties;\n\n\tpublic PythonReplTool(PythonCoderProperties coderProperties) {\n\t\tthis.coderProperties = coderProperties;\n\t}\n\n\t@Tool(description = \"Execute Python code and return the result.\")\n\tpublic String executePythonCode(@ToolParam(description = \"python code\") String code,\n\t\t\t@ToolParam(description = \"requirements.txt\", required = false) String requirements,\n\t\t\t@ToolParam(description = \"input data for the python script\", required = false) String data) {\n\t\tif (code == null || code.trim().isEmpty()) {\n\t\t\treturn \"Error: Code must be a non-empty string.\";\n\t\t}\n\t\tif (!StringUtils.hasText(coderProperties.getContainNamePrefix())\n\t\t\t\t|| !StringUtils.hasText(coderProperties.getDockerHost())\n\t\t\t\t|| (coderProperties.getCpuCore() == null || coderProperties.getCpuCore() <= 0)\n\t\t\t\t|| (coderProperties.getLimitMemory() == null || coderProperties.getLimitMemory() <= 0)\n\t\t\t\t|| !StringUtils.hasText(coderProperties.getCodeTimeout())\n\t\t\t\t|| !StringUtils.hasText(coderProperties.getImageName())) {\n\t\t\treturn \"Error: Some Config is not set. You should reporter it to developer.\";\n\t\t}\n\n\t\t// 自动检测操作系统并设置合适的Docker Host\n\t\tString dockerHost = getDockerHostForCurrentOS();\n\n\t\tDockerClientConfig config = DefaultDockerClientConfig.createDefaultConfigBuilder()\n\t\t\t.withDockerHost(dockerHost)\n\t\t\t.withDockerTlsVerify(false)\n\t\t\t.build();\n\n\t\tPath tempDir = null; // Declare tempDir outside try-with-resources for finally\n\t\t\t\t\t\t\t\t// block\n\t\tString volumeName = null; // Declare volumeName outside try-with-resources for\n\t\t\t\t\t\t\t\t\t// finally block\n\t\tDockerClient dockerClient = null; // Declare dockerClient outside\n\t\t\t\t\t\t\t\t\t\t\t// try-with-resources\n\n\t\ttry {\n\t\t\t// 使用带回退机制的Docker客户端创建方法\n\t\t\tdockerClient = createDockerClientWithFallback(config);\n\n\t\t\t// Create temp dir and files\n\t\t\ttempDir = Files.createTempDirectory(coderProperties.getContainNamePrefix());\n\t\t\tFiles.createFile(tempDir.resolve(\"requirements.txt\"));\n\t\t\tFiles.createFile(tempDir.resolve(\"script.py\"));\n\t\t\tFiles.write(tempDir.resolve(\"requirements.txt\"),\n\t\t\t\t\tStringUtils.hasText(requirements) ? requirements.getBytes() : \"\".getBytes());\n\t\t\tFiles.write(tempDir.resolve(\"script.py\"), code.getBytes());\n\n\t\t\tboolean hasData = StringUtils.hasText(data);\n\t\t\tif (hasData) {\n\t\t\t\tFiles.createFile(tempDir.resolve(\"input_data.txt\"));\n\t\t\t\tFiles.write(tempDir.resolve(\"input_data.txt\"), data.getBytes());\n\t\t\t}\n\n\t\t\t// Build a docker to run\n\t\t\tString containName = generateUniqueContainerName();\n\n\t\t\t// create a volume to save third-party dependencies\n\t\t\tvolumeName = containName.concat(\"-volume\");\n\n\t\t\t// 先清理可能存在的同名容器和卷\n\t\t\tcleanupExistingResources(dockerClient, containName, volumeName);\n\n\t\t\tdockerClient.createVolumeCmd().withName(volumeName).withDriver(\"local\").exec();\n\n\t\t\tif (!coderProperties.isEnableNetwork() && StringUtils.hasText(requirements)) {\n\t\t\t\t// If Python code is restricted from network access but requires\n\t\t\t\t// third-party dependencies, we need to provision a docker for pip to\n\t\t\t\t// install the dependencies.\n\t\t\t\tHostConfig hostConfig = createHostConfig(tempDir, volumeName, hasData);\n\n\t\t\t\tString pipContainerName = containName + \"-pip\";\n\t\t\t\tCreateContainerResponse pipContainer = dockerClient.createContainerCmd(coderProperties.getImageName())\n\t\t\t\t\t.withName(pipContainerName)\n\t\t\t\t\t.withWorkingDir(\"/app\")\n\t\t\t\t\t.withHostConfig(hostConfig)\n\t\t\t\t\t.withCmd(\"sh\", \"-c\",\n\t\t\t\t\t\t\t\"pip3 install --target=/app/dependency --no-cache-dir -r requirements.txt > /dev/null\")\n\t\t\t\t\t.exec();\n\t\t\t\ttry {\n\t\t\t\t\tthis.execDockerContainer(dockerClient, pipContainer);\n\t\t\t\t}\n\t\t\t\tcatch (Exception e) {\n\t\t\t\t\treturn \"Error installing requirements: \" + e.getMessage();\n\t\t\t\t}\n\t\t\t\tfinally {\n\t\t\t\t\t// 立即清理pip容器\n\t\t\t\t\ttry {\n\t\t\t\t\t\tdockerClient.removeContainerCmd(pipContainer.getId()).withForce(true).exec();\n\t\t\t\t\t\tlogger.info(\"Removed pip container: \" + pipContainerName);\n\t\t\t\t\t}\n\t\t\t\t\tcatch (Exception ignore) {\n\t\t\t\t\t\t// Ignore cleanup errors\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// run python code in docker\n\t\t\tHostConfig hostConfig = createHostConfig(tempDir, volumeName, hasData)\n\t\t\t\t.withNetworkMode(coderProperties.isEnableNetwork() ? \"bridge\" : \"none\");\n\n\t\t\tString execContainerName = containName + \"-exec\";\n\t\t\tCreateContainerResponse container = dockerClient.createContainerCmd(coderProperties.getImageName())\n\t\t\t\t.withName(execContainerName)\n\t\t\t\t.withWorkingDir(\"/app\")\n\t\t\t\t.withHostConfig(hostConfig)\n\t\t\t\t.withCmd(\"sh\", \"-c\", String.format(((coderProperties.isEnableNetwork() && StringUtils\n\t\t\t\t\t.hasText(requirements))\n\t\t\t\t\t\t\t? \"pip3 install --target=/app/dependency --no-cache-dir -r requirements.txt > /dev/null && \"\n\t\t\t\t\t\t\t: \"\")\n\t\t\t\t\t\t+ \"export PYTHONPATH=\\\"/app/dependency:$PYTHONPATH\\\" && timeout -s SIGKILL %s python3 script.py\",\n\t\t\t\t\t\tcoderProperties.getCodeTimeout()))\n\t\t\t\t.exec();\n\t\t\ttry {\n\t\t\t\tString output = this.execDockerContainer(dockerClient, container);\n\t\t\t\tlogger.info(\"Python code executed successfully.\");\n\t\t\t\treturn \"Successfully executed:\\n```\\n\" + code + \"\\n```\\nStdout:\\n\" + output;\n\t\t\t}\n\t\t\tcatch (Exception e) {\n\t\t\t\tlogger.warning(\"Python code execution failed.\");\n\t\t\t\treturn \"Error executing code:\\n```\\n\" + code + \"\\n```\\nError:\\n\" + e.getMessage();\n\t\t\t}\n\t\t\tfinally {\n\t\t\t\t// This finally block will execute before the outer one, ensuring\n\t\t\t\t// container is removed\n\t\t\t\t// before tempDir and volume are cleaned up.\n\t\t\t\ttry {\n\t\t\t\t\tdockerClient.removeContainerCmd(container.getId()).withForce(true).exec();\n\t\t\t\t}\n\t\t\t\tcatch (Exception ignore) {\n\t\t\t\t\t// Ignore exceptions during container removal\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlogger.warning(\"Exception during execution: \" + e.getMessage());\n\t\t\treturn \"Error executing code:\\n```\\n\" + code + \"\\n```\\nError:\\n\" + e.getMessage();\n\t\t}\n\t\tfinally {\n\t\t\t// Ensure temp resources are cleaned up even if an exception occurs earlier\n\t\t\tif (tempDir != null && volumeName != null && dockerClient != null) {\n\t\t\t\tthis.clearTempResource(tempDir, dockerClient, volumeName);\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * clean some temp resource before return\n\t */\n\tprivate void clearTempResource(Path tempDir, DockerClient dockerClient, String volumeName) {\n\t\ttry {\n\t\t\tFiles.walkFileTree(tempDir, new SimpleFileVisitor<>() {\n\t\t\t\t@NotNull\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult visitFile(@NotNull Path file, @NotNull BasicFileAttributes attrs)\n\t\t\t\t\t\tthrows IOException {\n\t\t\t\t\tFiles.delete(file);\n\t\t\t\t\treturn super.visitFile(file, attrs);\n\t\t\t\t}\n\n\t\t\t\t@NotNull\n\t\t\t\t@Override\n\t\t\t\tpublic FileVisitResult postVisitDirectory(@NotNull Path dir, @Nullable IOException exc)\n\t\t\t\t\t\tthrows IOException {\n\t\t\t\t\tif (exc != null)\n\t\t\t\t\t\tthrow exc;\n\t\t\t\t\tFiles.delete(dir);\n\t\t\t\t\treturn super.postVisitDirectory(dir, exc);\n\t\t\t\t}\n\t\t\t});\n\t\t\tlogger.info(\"Temp directory has been deleted.\");\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlogger.warning(\"Exception in clean temp directory: \" + e.getMessage());\n\t\t}\n\t\ttry {\n\t\t\t// remove volume before return\n\t\t\tdockerClient.removeVolumeCmd(volumeName).exec();\n\t\t}\n\t\tcatch (Exception ignore) {\n\t\t}\n\t}\n\n\t/**\n\t * Create container's HostConfig\n\t */\n\tprivate HostConfig createHostConfig(Path tempDir, String volumeName, boolean hasData) {\n\t\tList<Bind> binds = new ArrayList<>();\n\t\tbinds.add(new Bind(tempDir.resolve(\"script.py\").toAbsolutePath().toString(), new Volume(\"/app/script.py\"),\n\t\t\t\tAccessMode.ro));\n\t\tbinds.add(new Bind(tempDir.resolve(\"requirements.txt\").toAbsolutePath().toString(),\n\t\t\t\tnew Volume(\"/app/requirements.txt\"), AccessMode.ro));\n\t\tbinds.add(new Bind(volumeName, new Volume(\"/app/dependency\")));\n\n\t\tif (hasData) {\n\t\t\tbinds.add(new Bind(tempDir.resolve(\"input_data.txt\").toAbsolutePath().toString(),\n\t\t\t\t\tnew Volume(\"/app/input_data.txt\"), AccessMode.ro));\n\t\t}\n\n\t\treturn newHostConfig().withMemory(coderProperties.getLimitMemory() * 1024L * 1024L)\n\t\t\t.withCpuCount(coderProperties.getCpuCore())\n\t\t\t.withCapDrop(Capability.ALL)\n\t\t\t.withAutoRemove(false)\n\t\t\t.withBinds(binds.toArray(new Bind[0]))\n\t\t\t.withTmpFs(Map.of(\"/tmp\", \"\"));\n\t}\n\n\t/**\n\t * Run a Docker container and return its stdout. Throw a RuntimeException if errors\n\t * occur.\n\t */\n\tprivate String execDockerContainer(DockerClient dockerClient, CreateContainerResponse container)\n\t\t\tthrows RuntimeException {\n\t\t// catch stdout and stderr\n\t\tByteArrayOutputStream stdout = new ByteArrayOutputStream();\n\t\tByteArrayOutputStream stderr = new ByteArrayOutputStream();\n\n\t\ttry {\n\t\t\t// start docker\n\t\t\tdockerClient.startContainerCmd(container.getId()).exec();\n\t\t\tLogContainerCmd logContainerCmd = dockerClient.logContainerCmd(container.getId())\n\t\t\t\t.withStdOut(true)\n\t\t\t\t.withStdErr(true)\n\t\t\t\t.withFollowStream(true)\n\t\t\t\t.withTailAll();\n\t\t\tdockerClient.waitContainerCmd(container.getId())\n\t\t\t\t.start()\n\t\t\t\t.awaitCompletion(coderProperties.getDockerTimeout(), TimeUnit.SECONDS);\n\n\t\t\t// get stdout and stderr\n\t\t\tlogContainerCmd.exec(new ResultCallback.Adapter<Frame>() {\n\t\t\t\t@Override\n\t\t\t\tpublic void onNext(Frame frame) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tif (frame.getStreamType() == StreamType.STDOUT) {\n\t\t\t\t\t\t\tstdout.write(frame.getPayload());\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse if (frame.getStreamType() == StreamType.STDERR) {\n\t\t\t\t\t\t\tstderr.write(frame.getPayload());\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tcatch (Exception ignore) {\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}).awaitCompletion();\n\n\t\t\t// get exit code\n\t\t\tInspectContainerResponse inspectResponse = dockerClient.inspectContainerCmd(container.getId()).exec();\n\t\t\tint exitCode = Objects.requireNonNull(inspectResponse.getState().getExitCodeLong()).intValue();\n\t\t\tif (exitCode != 0) {\n\t\t\t\tString errorMessage = \"Docker exit code \" + exitCode + \". Stderr: \"\n\t\t\t\t\t\t+ stderr.toString(Charset.defaultCharset()) + \". Stdout: \"\n\t\t\t\t\t\t+ stdout.toString(Charset.defaultCharset());\n\t\t\t\tthrow new RuntimeException(errorMessage);\n\t\t\t}\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlogger.severe(\"Error when creating container in docker: {}\" + e.getMessage());\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t\tfinally {\n\t\t\t// Container removal is now handled in the outer try-catch-finally block\n\t\t\t// to ensure it's removed even if execDockerContainer throws an exception.\n\t\t}\n\t\treturn stdout.toString(Charset.defaultCharset());\n\t}\n\n\t/**\n\t * 根据当前操作系统自动选择合适的Docker Host地址\n\t * @return Docker Host URI\n\t */\n\tprivate String getDockerHostForCurrentOS() {\n\t\tString osName = System.getProperty(\"os.name\").toLowerCase();\n\t\tlogger.info(\"Detected operating system: \" + osName);\n\n\t\tif (osName.contains(\"win\")) {\n\t\t\t// Windows系统\n\t\t\tlogger.info(\"Using Windows Docker configuration\");\n\t\t\t// 在Windows上优先尝试TCP连接，更稳定\n\t\t\treturn \"tcp://localhost:2375\";\n\t\t}\n\t\telse if (osName.contains(\"nix\") || osName.contains(\"nux\") || osName.contains(\"aix\")) {\n\t\t\t// Linux/Unix系统\n\t\t\tlogger.info(\"Using Linux/Unix Docker configuration\");\n\t\t\treturn \"unix:///var/run/docker.sock\";\n\t\t}\n\t\telse if (osName.contains(\"mac\")) {\n\t\t\t// macOS系统\n\t\t\tlogger.info(\"Using macOS Docker configuration\");\n\t\t\treturn \"unix:///var/run/docker.sock\";\n\t\t}\n\t\telse {\n\t\t\t// 未知系统，使用配置文件中的默认值\n\t\t\tlogger.warning(\"Unknown operating system: \" + osName + \", using configured docker host\");\n\t\t\treturn coderProperties.getDockerHost();\n\t\t}\n\t}\n\n\t/**\n\t * 创建Docker客户端，支持多种连接方式的回退机制\n\t * @param config Docker客户端配置\n\t * @return DockerClient实例\n\t * @throws Exception 如果所有连接方式都失败\n\t */\n\tprivate DockerClient createDockerClientWithFallback(DockerClientConfig config) throws Exception {\n\t\tString osName = System.getProperty(\"os.name\").toLowerCase();\n\n\t\tif (osName.contains(\"win\")) {\n\t\t\t// Windows系统：尝试多种连接方式\n\t\t\tString[] windowsHosts = { \"tcp://localhost:2375\", // TCP方式（需要在Docker\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// Desktop中启用）\n\t\t\t\t\t\"npipe://./pipe/docker_engine\" // 命名管道方式\n\t\t\t};\n\n\t\t\tfor (String dockerHost : windowsHosts) {\n\t\t\t\ttry {\n\t\t\t\t\tlogger.info(\"Attempting to connect to Docker using: \" + dockerHost);\n\n\t\t\t\t\tDockerClientConfig testConfig = DefaultDockerClientConfig.createDefaultConfigBuilder()\n\t\t\t\t\t\t.withDockerHost(dockerHost)\n\t\t\t\t\t\t.withDockerTlsVerify(false)\n\t\t\t\t\t\t.build();\n\n\t\t\t\t\tZerodepDockerHttpClient httpClient = new ZerodepDockerHttpClient.Builder()\n\t\t\t\t\t\t.dockerHost(testConfig.getDockerHost())\n\t\t\t\t\t\t.sslConfig(testConfig.getSSLConfig())\n\t\t\t\t\t\t.build();\n\n\t\t\t\t\tDockerClient dockerClient = DockerClientImpl.getInstance(testConfig, httpClient);\n\n\t\t\t\t\t// 测试连接是否正常\n\t\t\t\t\tdockerClient.pingCmd().exec();\n\t\t\t\t\tlogger.info(\"Successfully connected to Docker using: \" + dockerHost);\n\t\t\t\t\treturn dockerClient;\n\n\t\t\t\t}\n\t\t\t\tcatch (Exception e) {\n\t\t\t\t\tlogger.warning(\"Failed to connect using \" + dockerHost + \": \" + e.getMessage());\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// 如果所有Windows连接方式都失败\n\t\t\tthrow new Exception(\n\t\t\t\t\t\"Failed to connect to Docker on Windows. Please ensure Docker Desktop is running and either:\\n\"\n\t\t\t\t\t\t\t+ \"1. Enable 'Expose daemon on tcp://localhost:2375 without TLS' in Docker Desktop settings, or\\n\"\n\t\t\t\t\t\t\t+ \"2. Ensure Docker Desktop's named pipe is available\");\n\n\t\t}\n\t\telse {\n\t\t\t// Linux/Unix/macOS系统：使用标准Unix socket\n\t\t\ttry {\n\t\t\t\tZerodepDockerHttpClient httpClient = new ZerodepDockerHttpClient.Builder()\n\t\t\t\t\t.dockerHost(config.getDockerHost())\n\t\t\t\t\t.sslConfig(config.getSSLConfig())\n\t\t\t\t\t.build();\n\n\t\t\t\tDockerClient dockerClient = DockerClientImpl.getInstance(config, httpClient);\n\t\t\t\tdockerClient.pingCmd().exec(); // 测试连接\n\t\t\t\tlogger.info(\"Successfully connected to Docker using: \" + config.getDockerHost());\n\t\t\t\treturn dockerClient;\n\n\t\t\t}\n\t\t\tcatch (Exception e) {\n\t\t\t\tthrow new Exception(\"Failed to connect to Docker on \" + osName + \": \" + e.getMessage()\n\t\t\t\t\t\t+ \"\\nPlease ensure Docker is running and accessible at: \" + config.getDockerHost());\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * 清理已存在的同名容器和卷\n\t */\n\tprivate void cleanupExistingResources(DockerClient dockerClient, String containName, String volumeName) {\n\t\ttry {\n\t\t\t// 尝试删除同名容器\n\t\t\tdockerClient.removeContainerCmd(containName).withForce(true).exec();\n\t\t\tlogger.info(\"Removed existing container: \" + containName);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlogger.warning(\"Failed to remove container \" + containName + \": \" + e.getMessage());\n\t\t}\n\n\t\ttry {\n\t\t\t// 尝试删除同名卷\n\t\t\tdockerClient.removeVolumeCmd(volumeName).exec();\n\t\t\tlogger.info(\"Removed existing volume: \" + volumeName);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlogger.warning(\"Failed to remove volume \" + volumeName + \": \" + e.getMessage());\n\t\t}\n\t}\n\n\t/**\n\t * 生成唯一的容器名称\n\t */\n\tprivate String generateUniqueContainerName() {\n\t\treturn coderProperties.getContainNamePrefix() + \"_\" + System.currentTimeMillis();\n\t}\n\n}", "metadata": {"commit_sha": "b2c09961", "lines_added": 1, "lines_deleted": 2, "total_changes": 3, "chunks": 2}}
{"id": 13, "pattern_type": "refactoring", "file_path": "spring-ai-alibaba-graph/spring-ai-alibaba-graph-core/src/test/java/com/alibaba/cloud/ai/graph/StateGraphTest.java", "file_extension": "java", "input": "package com.alibaba.cloud.ai.graph;\n\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi;\nimport com.alibaba.cloud.ai.dashscope.chat.DashScopeChatModel;\nimport com.alibaba.cloud.ai.graph.action.AsyncEdgeAction;\nimport com.alibaba.cloud.ai.graph.action.AsyncNodeAction;\nimport com.alibaba.cloud.ai.graph.action.NodeAction;\nimport com.alibaba.cloud.ai.graph.action.llm.LLMNodeAction;\nimport com.alibaba.cloud.ai.graph.state.AgentState;\nimport com.alibaba.cloud.ai.graph.state.AppendableValue;\nimport com.alibaba.cloud.ai.graph.state.AppenderChannel;\nimport com.alibaba.cloud.ai.graph.state.Channel;\nimport com.alibaba.cloud.ai.graph.utils.CollectionsUtils;\nimport lombok.extern.slf4j.Slf4j;\n\nimport org.junit.jupiter.api.Test;\nimport org.springframework.ai.chat.messages.UserMessage;\n\nimport java.util.*;\nimport java.util.stream.Collectors;\n\nimport static com.alibaba.cloud.ai.graph.utils.CollectionsUtils.listOf;\nimport static org.junit.jupiter.api.Assertions.*;\n\n/**\n * Unit test for simple App.\n */\n@Slf4j\npublic class StateGraphTest {\n\n\tpublic static <T> List<Map.Entry<String, T>> sortMap(Map<String, T> map) {\n\t\treturn map.entrySet().stream().sorted(Map.Entry.comparingByKey()).collect(Collectors.toList());\n\t}\n\n\t@Test\n\tvoid testValidation() throws Exception {\n\n\t\tStateGraph<AgentState> workflow = new StateGraph<>(AgentState::new);\n\t\tGraphStateException exception = assertThrows(GraphStateException.class, workflow::compile);\n\t\tSystem.out.println(exception.getMessage());\n\t\tassertEquals(\"missing Entry Point\", exception.getMessage());\n\n\t\tworkflow.addEdge(StateGraph.START, \"agent_1\");\n\n\t\texception = assertThrows(GraphStateException.class, workflow::compile);\n\t\tSystem.out.println(exception.getMessage());\n\t\tassertEquals(\"entryPoint: agent_1 doesn't exist!\", exception.getMessage());\n\n\t\tworkflow.addNode(\"agent_1\", AsyncNodeAction.node_async((state) -> {\n\t\t\tSystem.out.print(\"agent_1 \");\n\t\t\tSystem.out.println(state);\n\t\t\treturn CollectionsUtils.mapOf(\"prop1\", \"test\");\n\t\t}));\n\n\t\tassertNotNull(workflow.compile());\n\n\t\tworkflow.addEdge(\"agent_1\", StateGraph.END);\n\n\t\tassertNotNull(workflow.compile());\n\n\t\texception = assertThrows(GraphStateException.class, () -> workflow.addEdge(StateGraph.END, \"agent_1\"));\n\t\tSystem.out.println(exception.getMessage());\n\n\t\texception = assertThrows(GraphStateException.class, () -> workflow.addEdge(\"agent_1\", \"agent_2\"));\n\t\tSystem.out.println(exception.getMessage());\n\n\t\tworkflow.addNode(\"agent_2\", AsyncNodeAction.node_async(state -> {\n\n\t\t\tSystem.out.print(\"agent_2: \");\n\t\t\tSystem.out.println(state);\n\n\t\t\treturn CollectionsUtils.mapOf(\"prop2\", \"test\");\n\t\t}));\n\n\t\tworkflow.addEdge(\"agent_2\", \"agent_3\");\n\n\t\texception = assertThrows(GraphStateException.class, workflow::compile);\n\t\tSystem.out.println(exception.getMessage());\n\n\t\texception = assertThrows(GraphStateException.class, () -> workflow.addConditionalEdges(\"agent_1\",\n\t\t\t\tAsyncEdgeAction.edge_async(state -> \"agent_3\"), CollectionsUtils.mapOf()));\n\t\tSystem.out.println(exception.getMessage());\n\n\t}\n\n\t@Test\n\tpublic void testRunningOneNode() throws Exception {\n\n\t\tStateGraph<AgentState> workflow = new StateGraph<>(AgentState::new).addEdge(StateGraph.START, \"agent_1\")\n\t\t\t.addNode(\"agent_1\", AsyncNodeAction.node_async(state -> {\n\t\t\t\tSystem.out.print(\"agent_1\");\n\t\t\t\tSystem.out.println(state);\n\t\t\t\treturn CollectionsUtils.mapOf(\"prop1\", \"test\");\n\t\t\t}))\n\t\t\t.addEdge(\"agent_1\", StateGraph.END);\n\n\t\tCompiledGraph<AgentState> app = workflow.compile();\n\n\t\tOptional<AgentState> result = app.invoke(CollectionsUtils.mapOf(\"input\", \"test1\"));\n\t\tassertTrue(result.isPresent());\n\n\t\tMap<String, String> expected = CollectionsUtils.mapOf(\"input\", \"test1\", \"prop1\", \"test\");\n\n\t\tassertIterableEquals(sortMap(expected), sortMap(result.get().data()));\n\t\t// assertDictionaryOfAnyEqual( expected, result.data )\n\n\t}\n\n\tstatic class MessagesState extends AgentState {\n\n\t\tstatic Map<String, Channel<?>> SCHEMA = CollectionsUtils.mapOf(\"messages\",\n\t\t\t\tAppenderChannel.<String>of(ArrayList::new));\n\n\t\tpublic MessagesState(Map<String, Object> initData) {\n\t\t\tsuper(initData);\n\t\t}\n\n\t\tint steps() {\n\t\t\treturn value(\"steps\", 0);\n\t\t}\n\n\t\tList<String> messages() {\n\t\t\treturn this.<List<String>>value(\"messages\").orElseThrow(() -> new RuntimeException(\"messages not found\"));\n\t\t}\n\n\t}\n\n\t@Test\n\tvoid testWithAppender() throws Exception {\n\n\t\tStateGraph<MessagesState> workflow = new StateGraph<>(MessagesState.SCHEMA, MessagesState::new)\n\t\t\t.addNode(\"agent_1\", AsyncNodeAction.node_async(state -> {\n\t\t\t\tSystem.out.println(\"agent_1\");\n\t\t\t\treturn CollectionsUtils.mapOf(\"messages\", \"message1\");\n\t\t\t}))\n\t\t\t.addNode(\"agent_2\", AsyncNodeAction.node_async(state -> {\n\t\t\t\tSystem.out.println(\"agent_2\");\n\t\t\t\treturn CollectionsUtils.mapOf(\"messages\", new String[] { \"message2\" });\n\t\t\t}))\n\t\t\t.addNode(\"agent_3\", AsyncNodeAction.node_async(state -> {\n\t\t\t\tSystem.out.println(\"agent_3\");\n\t\t\t\tint steps = state.messages().size() + 1;\n\t\t\t\treturn CollectionsUtils.mapOf(\"messages\", \"message3\", \"steps\", steps);\n\t\t\t}))\n\t\t\t.addEdge(\"agent_1\", \"agent_2\")\n\t\t\t.addEdge(\"agent_2\", \"agent_3\")\n\t\t\t.addEdge(StateGraph.START, \"agent_1\")\n\t\t\t.addEdge(\"agent_3\", StateGraph.END);\n\n\t\tCompiledGraph<MessagesState> app = workflow.compile();\n\n\t\tOptional<MessagesState> result = app.invoke(CollectionsUtils.mapOf());\n\n\t\tassertTrue(result.isPresent());\n\t\tSystem.out.println(result.get().data());\n\t\tassertEquals(3, result.get().steps());\n\t\tassertEquals(3, result.get().messages().size());\n\t\tassertIterableEquals(CollectionsUtils.listOf(\"message1\", \"message2\", \"message3\"), result.get().messages());\n\n\t}\n\n\tstatic class MessagesStateDeprecated extends AgentState {\n\n\t\tpublic MessagesStateDeprecated(Map<String, Object> initData) {\n\t\t\tsuper(initData);\n\t\t\tappendableValue(\"messages\"); // tip: initialize messages\n\t\t}\n\n\t\tint steps() {\n\t\t\treturn value(\"steps\").map(Integer.class::cast).orElse(0);\n\t\t}\n\n\t\tAppendableValue<String> messages() {\n\t\t\treturn appendableValue(\"messages\");\n\t\t}\n\n\t}\n\n\t@Test\n\tvoid testWithAppenderDeprecated() throws Exception {\n\n\t\tStateGraph<MessagesStateDeprecated> workflow = new StateGraph<>(MessagesStateDeprecated::new)\n\t\t\t.addNode(\"agent_1\", AsyncNodeAction.node_async(state -> {\n\t\t\t\tSystem.out.println(\"agent_1\");\n\t\t\t\treturn CollectionsUtils.mapOf(\"messages\", \"message1\");\n\t\t\t}))\n\t\t\t.addNode(\"agent_2\", AsyncNodeAction.node_async(state -> {\n\t\t\t\tSystem.out.println(\"agent_2\");\n\t\t\t\treturn CollectionsUtils.mapOf(\"messages\", \"message2\");\n\t\t\t}))\n\t\t\t.addNode(\"agent_3\", AsyncNodeAction.node_async(state -> {\n\t\t\t\tSystem.out.println(\"agent_3\");\n\t\t\t\tAppendableValue<String> messages = state.messages();\n\t\t\t\tint steps = messages.size() + 1;\n\t\t\t\treturn CollectionsUtils.mapOf(\"messages\", \"message3\", \"steps\", steps);\n\t\t\t}))\n\t\t\t.addEdge(\"agent_1\", \"agent_2\")\n\t\t\t.addEdge(\"agent_2\", \"agent_3\")\n\t\t\t.addEdge(StateGraph.START, \"agent_1\")\n\t\t\t.addEdge(\"agent_3\", StateGraph.END);\n\n\t\tCompiledGraph<MessagesStateDeprecated> app = workflow.compile();\n\n\t\tOptional<MessagesStateDeprecated> result = app.invoke(CollectionsUtils.mapOf());\n\n\t\tassertTrue(result.isPresent());\n\t\tassertEquals(3, result.get().messages().size());\n\t\tassertEquals(3, result.get().steps());\n\t\tassertIterableEquals(CollectionsUtils.listOf(\"message1\", \"message2\", \"message3\"),\n\t\t\t\tresult.get().messages().values());\n\n\t}\n\n\t@Test\n\tvoid testWithLLMNodeAction() throws Exception {\n\t\tNodeAction<MessagesState> llmNode = LLMNodeAction.builder(new DashScopeChatModel(new DashScopeApi(\"sk-ec5a3fdc7796473a8c96e87b00b03453\")))\n\t\t\t\t.systemMessage(\"You're a code writer with strong language skills and coding skills\")\n\t\t\t\t.build();\n\t\tStateGraph<MessagesState> workflow = new StateGraph<>(MessagesState.SCHEMA, MessagesState::new)\n\t\t\t\t.addNode(\"code-writer\", AsyncNodeAction.node_async(llmNode))\n\t\t\t\t.addEdge(StateGraph.START, \"code-writer\")\n\t\t\t\t.addEdge(\"code-writer\", StateGraph.END);\n\n\t\tCompiledGraph<MessagesState> compiledGraph = workflow.compile();\n\t\t//FIXME message serialize error\n\t\tOptional<MessagesState> result = compiledGraph.invoke(Map.of(\"messages\", List.of(new UserMessage(\"请你给我一个使用spring ai的最佳实践\"))));\n\t\tSystem.out.println(result);\n\t}\n\n\n}", "output": "package com.alibaba.cloud.ai.graph;\n\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi;\nimport com.alibaba.cloud.ai.dashscope.chat.DashScopeChatModel;\nimport com.alibaba.cloud.ai.graph.action.AsyncEdgeAction;\nimport com.alibaba.cloud.ai.graph.action.AsyncNodeAction;\nimport com.alibaba.cloud.ai.graph.action.NodeAction;\nimport com.alibaba.cloud.ai.graph.action.llm.LLMNodeAction;\nimport com.alibaba.cloud.ai.graph.state.AgentState;\nimport com.alibaba.cloud.ai.graph.state.AppendableValue;\nimport com.alibaba.cloud.ai.graph.state.AppenderChannel;\nimport com.alibaba.cloud.ai.graph.state.Channel;\nimport com.alibaba.cloud.ai.graph.utils.CollectionsUtils;\nimport lombok.extern.slf4j.Slf4j;\n\nimport org.junit.jupiter.api.Test;\nimport org.springframework.ai.chat.messages.Message;\nimport org.springframework.ai.chat.messages.UserMessage;\n\nimport java.util.*;\nimport java.util.stream.Collectors;\n\nimport static com.alibaba.cloud.ai.graph.action.llm.LLMNodeAction.MESSAGES_KEY;\nimport static com.alibaba.cloud.ai.graph.utils.CollectionsUtils.listOf;\nimport static org.junit.jupiter.api.Assertions.*;\n\n/**\n * Unit test for simple App.\n */\n@Slf4j\npublic class StateGraphTest {\n\n\tpublic static <T> List<Map.Entry<String, T>> sortMap(Map<String, T> map) {\n\t\treturn map.entrySet().stream().sorted(Map.Entry.comparingByKey()).collect(Collectors.toList());\n\t}\n\n\t@Test\n\tvoid testValidation() throws Exception {\n\n\t\tStateGraph<AgentState> workflow = new StateGraph<>(AgentState::new);\n\t\tGraphStateException exception = assertThrows(GraphStateException.class, workflow::compile);\n\t\tSystem.out.println(exception.getMessage());\n\t\tassertEquals(\"missing Entry Point\", exception.getMessage());\n\n\t\tworkflow.addEdge(StateGraph.START, \"agent_1\");\n\n\t\texception = assertThrows(GraphStateException.class, workflow::compile);\n\t\tSystem.out.println(exception.getMessage());\n\t\tassertEquals(\"entryPoint: agent_1 doesn't exist!\", exception.getMessage());\n\n\t\tworkflow.addNode(\"agent_1\", AsyncNodeAction.node_async((state) -> {\n\t\t\tSystem.out.print(\"agent_1 \");\n\t\t\tSystem.out.println(state);\n\t\t\treturn CollectionsUtils.mapOf(\"prop1\", \"test\");\n\t\t}));\n\n\t\tassertNotNull(workflow.compile());\n\n\t\tworkflow.addEdge(\"agent_1\", StateGraph.END);\n\n\t\tassertNotNull(workflow.compile());\n\n\t\texception = assertThrows(GraphStateException.class, () -> workflow.addEdge(StateGraph.END, \"agent_1\"));\n\t\tSystem.out.println(exception.getMessage());\n\n\t\texception = assertThrows(GraphStateException.class, () -> workflow.addEdge(\"agent_1\", \"agent_2\"));\n\t\tSystem.out.println(exception.getMessage());\n\n\t\tworkflow.addNode(\"agent_2\", AsyncNodeAction.node_async(state -> {\n\n\t\t\tSystem.out.print(\"agent_2: \");\n\t\t\tSystem.out.println(state);\n\n\t\t\treturn CollectionsUtils.mapOf(\"prop2\", \"test\");\n\t\t}));\n\n\t\tworkflow.addEdge(\"agent_2\", \"agent_3\");\n\n\t\texception = assertThrows(GraphStateException.class, workflow::compile);\n\t\tSystem.out.println(exception.getMessage());\n\n\t\texception = assertThrows(GraphStateException.class, () -> workflow.addConditionalEdges(\"agent_1\",\n\t\t\t\tAsyncEdgeAction.edge_async(state -> \"agent_3\"), CollectionsUtils.mapOf()));\n\t\tSystem.out.println(exception.getMessage());\n\n\t}\n\n\t@Test\n\tpublic void testRunningOneNode() throws Exception {\n\n\t\tStateGraph<AgentState> workflow = new StateGraph<>(AgentState::new).addEdge(StateGraph.START, \"agent_1\")\n\t\t\t.addNode(\"agent_1\", AsyncNodeAction.node_async(state -> {\n\t\t\t\tSystem.out.print(\"agent_1\");\n\t\t\t\tSystem.out.println(state);\n\t\t\t\treturn CollectionsUtils.mapOf(\"prop1\", \"test\");\n\t\t\t}))\n\t\t\t.addEdge(\"agent_1\", StateGraph.END);\n\n\t\tCompiledGraph<AgentState> app = workflow.compile();\n\n\t\tOptional<AgentState> result = app.invoke(CollectionsUtils.mapOf(\"input\", \"test1\"));\n\t\tassertTrue(result.isPresent());\n\n\t\tMap<String, String> expected = CollectionsUtils.mapOf(\"input\", \"test1\", \"prop1\", \"test\");\n\n\t\tassertIterableEquals(sortMap(expected), sortMap(result.get().data()));\n\t\t// assertDictionaryOfAnyEqual( expected, result.data )\n\n\t}\n\n\tstatic class MessagesState extends AgentState {\n\n\t\tstatic Map<String, Channel<?>> SCHEMA = CollectionsUtils.mapOf(\"messages\",\n\t\t\t\tAppenderChannel.<String>of(ArrayList::new));\n\n\t\tpublic MessagesState(Map<String, Object> initData) {\n\t\t\tsuper(initData);\n\t\t}\n\n\t\tint steps() {\n\t\t\treturn value(\"steps\", 0);\n\t\t}\n\n\t\tList<String> messages() {\n\t\t\treturn this.<List<String>>value(\"messages\").orElseThrow(() -> new RuntimeException(\"messages not found\"));\n\t\t}\n\n\t}\n\n\t@Test\n\tvoid testWithAppender() throws Exception {\n\n\t\tStateGraph<MessagesState> workflow = new StateGraph<>(MessagesState.SCHEMA, MessagesState::new)\n\t\t\t.addNode(\"agent_1\", AsyncNodeAction.node_async(state -> {\n\t\t\t\tSystem.out.println(\"agent_1\");\n\t\t\t\treturn CollectionsUtils.mapOf(\"messages\", \"message1\");\n\t\t\t}))\n\t\t\t.addNode(\"agent_2\", AsyncNodeAction.node_async(state -> {\n\t\t\t\tSystem.out.println(\"agent_2\");\n\t\t\t\treturn CollectionsUtils.mapOf(\"messages\", new String[] { \"message2\" });\n\t\t\t}))\n\t\t\t.addNode(\"agent_3\", AsyncNodeAction.node_async(state -> {\n\t\t\t\tSystem.out.println(\"agent_3\");\n\t\t\t\tint steps = state.messages().size() + 1;\n\t\t\t\treturn CollectionsUtils.mapOf(\"messages\", \"message3\", \"steps\", steps);\n\t\t\t}))\n\t\t\t.addEdge(\"agent_1\", \"agent_2\")\n\t\t\t.addEdge(\"agent_2\", \"agent_3\")\n\t\t\t.addEdge(StateGraph.START, \"agent_1\")\n\t\t\t.addEdge(\"agent_3\", StateGraph.END);\n\n\t\tCompiledGraph<MessagesState> app = workflow.compile();\n\n\t\tOptional<MessagesState> result = app.invoke(CollectionsUtils.mapOf());\n\n\t\tassertTrue(result.isPresent());\n\t\tSystem.out.println(result.get().data());\n\t\tassertEquals(3, result.get().steps());\n\t\tassertEquals(3, result.get().messages().size());\n\t\tassertIterableEquals(CollectionsUtils.listOf(\"message1\", \"message2\", \"message3\"), result.get().messages());\n\n\t}\n\n\tstatic class MessagesStateDeprecated extends AgentState {\n\n\t\tpublic MessagesStateDeprecated(Map<String, Object> initData) {\n\t\t\tsuper(initData);\n\t\t\tappendableValue(\"messages\"); // tip: initialize messages\n\t\t}\n\n\t\tint steps() {\n\t\t\treturn value(\"steps\").map(Integer.class::cast).orElse(0);\n\t\t}\n\n\t\tAppendableValue<String> messages() {\n\t\t\treturn appendableValue(\"messages\");\n\t\t}\n\n\t}\n\n\t@Test\n\tvoid testWithAppenderDeprecated() throws Exception {\n\n\t\tStateGraph<MessagesStateDeprecated> workflow = new StateGraph<>(MessagesStateDeprecated::new)\n\t\t\t.addNode(\"agent_1\", AsyncNodeAction.node_async(state -> {\n\t\t\t\tSystem.out.println(\"agent_1\");\n\t\t\t\treturn CollectionsUtils.mapOf(\"messages\", \"message1\");\n\t\t\t}))\n\t\t\t.addNode(\"agent_2\", AsyncNodeAction.node_async(state -> {\n\t\t\t\tSystem.out.println(\"agent_2\");\n\t\t\t\treturn CollectionsUtils.mapOf(\"messages\", \"message2\");\n\t\t\t}))\n\t\t\t.addNode(\"agent_3\", AsyncNodeAction.node_async(state -> {\n\t\t\t\tSystem.out.println(\"agent_3\");\n\t\t\t\tAppendableValue<String> messages = state.messages();\n\t\t\t\tint steps = messages.size() + 1;\n\t\t\t\treturn CollectionsUtils.mapOf(\"messages\", \"message3\", \"steps\", steps);\n\t\t\t}))\n\t\t\t.addEdge(\"agent_1\", \"agent_2\")\n\t\t\t.addEdge(\"agent_2\", \"agent_3\")\n\t\t\t.addEdge(StateGraph.START, \"agent_1\")\n\t\t\t.addEdge(\"agent_3\", StateGraph.END);\n\n\t\tCompiledGraph<MessagesStateDeprecated> app = workflow.compile();\n\n\t\tOptional<MessagesStateDeprecated> result = app.invoke(CollectionsUtils.mapOf());\n\n\t\tassertTrue(result.isPresent());\n\t\tassertEquals(3, result.get().messages().size());\n\t\tassertEquals(3, result.get().steps());\n\t\tassertIterableEquals(CollectionsUtils.listOf(\"message1\", \"message2\", \"message3\"),\n\t\t\t\tresult.get().messages().values());\n\n\t}\n\n\t@Test\n\tvoid testWithLLMNodeAction() throws Exception {\n\t\tNodeAction<MessagesState> llmNode = LLMNodeAction.builder(new DashScopeChatModel(new DashScopeApi(\"${DASHSCOPE_API_KEY}\")))\n\t\t\t\t.systemMessage(\"You're a code writer with strong language skills and coding skills\")\n\t\t\t\t.build();\n\t\tMap<String,Object> stateData = llmNode.apply(new MessagesState(Map.of(MESSAGES_KEY, List.of(new UserMessage(\"can you provide a best practice using spring ai?\")))));\n\t\tassertEquals(1, stateData.size());\n\t\tSystem.out.println(stateData);\n\n\t}\n\n\n}", "metadata": {"commit_sha": "6f85049e", "lines_added": 7, "lines_deleted": 10, "total_changes": 17, "chunks": 2}}
{"id": 76, "pattern_type": "import_statement", "file_path": "community/openmanus/src/main/java/com/alibaba/cloud/ai/example/manus/service/ChromeDriverService.java", "file_extension": "java", "input": "/*\n * Copyright 2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.alibaba.cloud.ai.example.manus.service;\n\nimport java.net.URISyntaxException;\nimport java.net.URL;\nimport java.nio.file.Paths;\nimport java.util.Arrays;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Objects;\nimport java.util.Random;\nimport java.util.Set;\nimport java.util.concurrent.ConcurrentHashMap;\n\nimport com.alibaba.cloud.ai.example.manus.OpenManusSpringBootApplication;\nimport com.alibaba.cloud.ai.example.manus.config.ManusProperties;\nimport jakarta.annotation.PreDestroy;\nimport org.openqa.selenium.Dimension;\nimport org.openqa.selenium.JavascriptExecutor;\nimport org.openqa.selenium.WebDriver;\nimport org.openqa.selenium.chrome.ChromeDriver;\nimport org.openqa.selenium.chrome.ChromeOptions;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport org.springframework.boot.ApplicationArguments;\nimport org.springframework.boot.ApplicationRunner;\nimport org.springframework.context.annotation.Primary;\nimport org.springframework.stereotype.Service;\n\n@Service\n@Primary\npublic class ChromeDriverService implements ApplicationRunner {\n\n\tprivate static final Logger log = LoggerFactory.getLogger(ChromeDriverService.class);\n\n\tprivate final ConcurrentHashMap<String, ChromeDriver> drivers = new ConcurrentHashMap<>();\n\n\tprivate final ManusProperties manusProperties;\n\n\tprivate final ConcurrentHashMap<String, Object> driverLocks = new ConcurrentHashMap<>();\n\n\tpublic ChromeDriverService(ManusProperties manusProperties) {\n\t\tthis.manusProperties = manusProperties;\n\t\tRuntime.getRuntime().addShutdownHook(new Thread(() -> {\n\t\t\tlog.info(\"JVM shutting down - cleaning up Chrome processes\");\n\t\t\tcleanupAllChromeProcesses();\n\t\t}));\n\t}\n\n\tprivate Object getDriverLock(String planId) {\n\t\treturn driverLocks.computeIfAbsent(planId, k -> new Object());\n\t}\n\n\tpublic ChromeDriver getDriver(String planId) {\n\t\tif (planId == null) {\n\t\t\tthrow new IllegalArgumentException(\"planId cannot be null\");\n\t\t}\n\n\t\tChromeDriver currentDriver = drivers.get(planId);\n\t\tif (currentDriver != null && isDriverActive(currentDriver)) {\n\t\t\treturn currentDriver;\n\t\t}\n\n\t\tsynchronized (getDriverLock(planId)) {\n\t\t\tcurrentDriver = drivers.get(planId);\n\t\t\tif (currentDriver != null && isDriverActive(currentDriver)) {\n\t\t\t\treturn currentDriver;\n\t\t\t}\n\n\t\t\tChromeDriver newDriver = createNewDriver();\n\t\t\tdrivers.put(planId, newDriver);\n\t\t\treturn newDriver;\n\t\t}\n\t}\n\n\tprivate void cleanupAllChromeProcesses() {\n\t\ttry {\n\t\t\t// 关闭所有 driver\n\t\t\tfor (Map.Entry<String, ChromeDriver> entry : drivers.entrySet()) {\n\t\t\t\ttry {\n\t\t\t\t\tChromeDriver driver = entry.getValue();\n\t\t\t\t\tif (driver != null) {\n\t\t\t\t\t\tcloseDriver(driver);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tcatch (Exception e) {\n\t\t\t\t\tlog.error(\"Error closing ChromeDriver for planId: {}\", entry.getKey(), e);\n\t\t\t\t}\n\t\t\t}\n\t\t\tdrivers.clear();\n\t\t\tdriverLocks.clear();\n\t\t\tlog.info(\"Successfully cleaned up all Chrome drivers\");\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlog.error(\"Error cleaning up Chrome processes\", e);\n\t\t}\n\t}\n\n\tpublic void closeDriverForPlan(String planId) {\n\t\tChromeDriver driver = drivers.remove(planId);\n\t\tif (driver != null) {\n\t\t\tcloseDriver(driver);\n\t\t\tdriverLocks.remove(planId);\n\t\t}\n\t}\n\n\t@Override\n\tpublic void run(ApplicationArguments args) throws Exception {\n\n\t\tMap<OsType, String> chromeDriverMap = checkOS();\n\t\tif (Objects.isNull(chromeDriverMap)) {\n\t\t\tthrow new UnsupportedOperationException(\"不受支持的操作系统，当前仅支持 Windows、MacOS 和 Linux 系统\");\n\t\t}\n\n\t\tString chromeDriverPath = getChromeDriverPath(chromeDriverMap);\n\n\t\tSystem.setProperty(\"webdriver.chrome.driver\", chromeDriverPath);\n\t\tlog.info(\"ChromeDriver path initialized: {}\", chromeDriverPath);\n\t}\n\n\tprivate String getChromeDriverPath(Map<OsType, String> chromeDriverMap) throws URISyntaxException {\n\n\t\tif (chromeDriverMap.size() != 1) {\n\t\t\tthrow new IllegalArgumentException(\"Chrome Driver Map 中的元素数量非法，必须且只能包含一个元素\");\n\t\t}\n\t\tString chromeDriverPath = chromeDriverMap.values().iterator().next();\n\n\t\tURL resource = OpenManusSpringBootApplication.class.getClassLoader().getResource(chromeDriverPath);\n\t\tif (resource == null) {\n\t\t\tthrow new IllegalStateException(\"ChromeDriver not found: \" + chromeDriverPath);\n\t\t}\n\n\t\treturn Paths.get(resource.toURI()).toFile().getAbsolutePath();\n\t}\n\n\tprivate enum OsType {\n\n\t\tWINDOWS, MAC, LINUX, UNSUPPORTED\n\n\t}\n\n\tprivate static Map<OsType, String> checkOS() {\n\n\t\tString os = System.getProperty(\"os.name\").toLowerCase();\n\t\tMap<OsType, String> resMap = new HashMap<>();\n\n\t\tif (os.contains(\"win\")) {\n\t\t\tresMap.put(OsType.WINDOWS, \"chromedriver/win64/chromedriver.exe\");\n\t\t}\n\t\telse if (os.contains(\"mac\")) {\n\t\t\tresMap.put(OsType.MAC, \"chromedriver/mac-arm/chromedriver\");\n\t\t}\n\t\telse if (os.contains(\"nix\") || os.contains(\"nux\") || os.contains(\"aix\")) {\n\t\t\tresMap.put(OsType.LINUX, \"chromedriver/linux64/chromedriver\");\n\t\t}\n\t\telse {\n\t\t\tlog.warn(\"不支持的操作系统类型: {}\", os);\n\t\t\treturn null;\n\t\t}\n\n\t\treturn resMap;\n\t}\n\n\tprivate ChromeDriver createNewDriver() {\n\t\tChromeDriver newDriver = null;\n\t\ttry {\n\t\t\tChromeOptions options = new ChromeOptions();\n\n\t\t\t// 基础配置\n\t\t\toptions.addArguments(\"--remote-allow-origins=*\");\n\t\t\toptions.addArguments(\"--disable-blink-features=AutomationControlled\");\n\n\t\t\t// 根据配置决定是否使用 headless 模式\n\t\t\tif (manusProperties.getBrowserHeadless()) {\n\t\t\t\tlog.info(\"启用 Chrome headless 模式\");\n\t\t\t\toptions.addArguments(\"--headless=true\");\n\t\t\t}\n\n\t\t\t// 模拟真实浏览器环境\n\t\t\toptions.addArguments(\"--disable-infobars\");\n\t\t\toptions.addArguments(\"--disable-notifications\");\n\t\t\toptions.addArguments(\"--disable-dev-shm-usage\");\n\t\t\toptions.addArguments(\"--lang=zh-CN,zh,en-US,en\");\n\n\t\t\t// 添加随机化的用户代理\n\t\t\toptions.addArguments(\"--user-agent=\" + getRandomUserAgent());\n\n\t\t\t// 添加随机化的浏览器窗口大小\n\t\t\tDimension randomSize = getRandomWindowSize();\n\t\t\toptions.addArguments(\"--window-size=\" + randomSize.width + \",\" + randomSize.height);\n\n\t\t\t// 禁用自动化标志\n\t\t\tMap<String, Object> prefs = new HashMap<>();\n\t\t\tprefs.put(\"credentials_enable_service\", false);\n\t\t\tprefs.put(\"profile.password_manager_enabled\", false);\n\t\t\toptions.setExperimentalOption(\"prefs\", prefs);\n\n\t\t\t// 设置 webdriver 属性\n\t\t\tMap<String, Object> properties = new HashMap<>();\n\t\t\tproperties.put(\"navigator.webdriver\", false);\n\t\t\toptions.setExperimentalOption(\"excludeSwitches\", Arrays.asList(\"enable-automation\"));\n\n\t\t\tnewDriver = new ChromeDriver(options);\n\t\t\texecuteAntiDetectionScript(newDriver);\n\t\t\tlog.info(\"Created new ChromeDriver instance with anti-detection\");\n\t\t\treturn newDriver;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tif (newDriver != null) {\n\t\t\t\ttry {\n\t\t\t\t\tnewDriver.quit();\n\t\t\t\t}\n\t\t\t\tcatch (Exception ex) {\n\t\t\t\t\tlog.warn(\"Failed to quit failed driver instance\", ex);\n\t\t\t\t}\n\t\t\t}\n\t\t\tlog.error(\"Failed to create ChromeDriver instance\", e);\n\t\t\tthrow new RuntimeException(\"Failed to initialize ChromeDriver\", e);\n\t\t}\n\t}\n\n\tprivate String getRandomUserAgent() {\n\t\tList<String> userAgents = Arrays.asList(\n\t\t\t\t\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n\t\t\t\t\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n\t\t\t\t\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36 Edg/119.0.0.0\");\n\t\treturn userAgents.get(new Random().nextInt(userAgents.size()));\n\t}\n\n\tprivate Dimension getRandomWindowSize() {\n\t\tList<Dimension> sizes = Arrays.asList(new Dimension(1920, 1080), new Dimension(1366, 768),\n\t\t\t\tnew Dimension(1440, 900));\n\t\treturn sizes.get(new Random().nextInt(sizes.size()));\n\t}\n\n\tprivate void executeAntiDetectionScript(WebDriver driver) {\n\t\t((JavascriptExecutor) driver).executeScript(\"\"\"\n\t\t\t\tObject.defineProperty(navigator, 'webdriver', {\n\t\t\t\t    get: () => undefined\n\t\t\t\t});\n\n\t\t\t\t// 覆盖 navigator 属性\n\t\t\t\tconst newProto = navigator.__proto__;\n\t\t\t\tdelete newProto.webdriver;\n\n\t\t\t\t// 模拟真实的 plugins\n\t\t\t\tObject.defineProperty(navigator, 'plugins', {\n\t\t\t\t    get: () => [1, 2, 3, 4, 5],\n\t\t\t\t});\n\n\t\t\t\t// 模拟真实的语言\n\t\t\t\tObject.defineProperty(navigator, 'languages', {\n\t\t\t\t    get: () => ['zh-CN', 'zh', 'en-US', 'en'],\n\t\t\t\t});\n\t\t\t\t\"\"\");\n\t}\n\n\tprivate boolean isDriverActive(ChromeDriver driver) {\n\t\ttry {\n\t\t\tdriver.getCurrentUrl();\n\t\t\treturn true;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlog.warn(\"Existing ChromeDriver is not active\", e);\n\t\t\tcloseDriver(driver);\n\t\t\treturn false;\n\t\t}\n\t}\n\n\tprivate void closeDriver(WebDriver driver) {\n\t\ttry {\n\t\t\tif (driver != null) {\n\t\t\t\t// 首先关闭所有窗口\n\t\t\t\tSet<String> windowHandles = driver.getWindowHandles();\n\t\t\t\tfor (String handle : windowHandles) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tdriver.switchTo().window(handle);\n\t\t\t\t\t\tdriver.close();\n\t\t\t\t\t}\n\t\t\t\t\tcatch (Exception e) {\n\t\t\t\t\t\tlog.warn(\"Error closing window: {}\", e.getMessage());\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// 然后退出driver\n\t\t\t\tdriver.quit();\n\t\t\t\tlog.info(\"ChromeDriver closed successfully\");\n\t\t\t}\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlog.error(\"Error closing ChromeDriver\", e);\n\t\t}\n\t}\n\n\tpublic void cleanup(String planId) {\n\t\tif (planId != null) {\n\t\t\tlog.info(\"Cleaning up Chrome resources for plan: {}\", planId);\n\t\t\tcloseDriverForPlan(planId);\n\t\t}\n\t}\n\n\t@PreDestroy\n\tpublic void cleanup() {\n\t\tlog.info(\"Spring container shutting down - cleaning up Chrome resources\");\n\t\tcleanupAllChromeProcesses();\n\t}\n\n}", "output": "/*\n * Copyright 2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.alibaba.cloud.ai.example.manus.service;\n\nimport java.net.URISyntaxException;\nimport java.net.URL;\nimport java.nio.file.Paths;\nimport java.util.Arrays;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Objects;\nimport java.util.Random;\nimport java.util.Set;\nimport java.util.concurrent.ConcurrentHashMap;\n\nimport com.alibaba.cloud.ai.example.manus.OpenManusSpringBootApplication;\nimport com.alibaba.cloud.ai.example.manus.config.ManusProperties;\nimport io.github.bonigarcia.wdm.WebDriverManager;\nimport jakarta.annotation.PreDestroy;\nimport org.openqa.selenium.Dimension;\nimport org.openqa.selenium.JavascriptExecutor;\nimport org.openqa.selenium.WebDriver;\nimport org.openqa.selenium.chrome.ChromeDriver;\nimport org.openqa.selenium.chrome.ChromeOptions;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\nimport org.springframework.boot.ApplicationArguments;\nimport org.springframework.boot.ApplicationRunner;\nimport org.springframework.context.annotation.Primary;\nimport org.springframework.stereotype.Service;\n\n@Service\n@Primary\npublic class ChromeDriverService implements ApplicationRunner {\n\n\tprivate static final Logger log = LoggerFactory.getLogger(ChromeDriverService.class);\n\n\tprivate final ConcurrentHashMap<String, ChromeDriver> drivers = new ConcurrentHashMap<>();\n\n\tprivate final ManusProperties manusProperties;\n\n\tprivate final ConcurrentHashMap<String, Object> driverLocks = new ConcurrentHashMap<>();\n\n\tpublic ChromeDriverService(ManusProperties manusProperties) {\n\t\tthis.manusProperties = manusProperties;\n\t\tRuntime.getRuntime().addShutdownHook(new Thread(() -> {\n\t\t\tlog.info(\"JVM shutting down - cleaning up Chrome processes\");\n\t\t\tcleanupAllChromeProcesses();\n\t\t}));\n\t}\n\n\tprivate Object getDriverLock(String planId) {\n\t\treturn driverLocks.computeIfAbsent(planId, k -> new Object());\n\t}\n\n\tpublic ChromeDriver getDriver(String planId) {\n\t\tif (planId == null) {\n\t\t\tthrow new IllegalArgumentException(\"planId cannot be null\");\n\t\t}\n\n\t\tChromeDriver currentDriver = drivers.get(planId);\n\t\tif (currentDriver != null && isDriverActive(currentDriver)) {\n\t\t\treturn currentDriver;\n\t\t}\n\n\t\tsynchronized (getDriverLock(planId)) {\n\t\t\tcurrentDriver = drivers.get(planId);\n\t\t\tif (currentDriver != null && isDriverActive(currentDriver)) {\n\t\t\t\treturn currentDriver;\n\t\t\t}\n\n\t\t\tChromeDriver newDriver = createNewDriver();\n\t\t\tdrivers.put(planId, newDriver);\n\t\t\treturn newDriver;\n\t\t}\n\t}\n\n\tprivate void cleanupAllChromeProcesses() {\n\t\ttry {\n\t\t\t// 关闭所有 driver\n\t\t\tfor (Map.Entry<String, ChromeDriver> entry : drivers.entrySet()) {\n\t\t\t\ttry {\n\t\t\t\t\tChromeDriver driver = entry.getValue();\n\t\t\t\t\tif (driver != null) {\n\t\t\t\t\t\tcloseDriver(driver);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tcatch (Exception e) {\n\t\t\t\t\tlog.error(\"Error closing ChromeDriver for planId: {}\", entry.getKey(), e);\n\t\t\t\t}\n\t\t\t}\n\t\t\tdrivers.clear();\n\t\t\tdriverLocks.clear();\n\t\t\tlog.info(\"Successfully cleaned up all Chrome drivers\");\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlog.error(\"Error cleaning up Chrome processes\", e);\n\t\t}\n\t}\n\n\tpublic void closeDriverForPlan(String planId) {\n\t\tChromeDriver driver = drivers.remove(planId);\n\t\tif (driver != null) {\n\t\t\tcloseDriver(driver);\n\t\t\tdriverLocks.remove(planId);\n\t\t}\n\t}\n\n\t@Override\n\tpublic void run(ApplicationArguments args) throws Exception {\n\n\t\tMap<OsType, String> chromeDriverMap = checkOS();\n\t\tif (Objects.isNull(chromeDriverMap)) {\n\t\t\tthrow new UnsupportedOperationException(\"不受支持的操作系统，当前仅支持 Windows、MacOS 和 Linux 系统\");\n\t\t}\n\n\t\tString chromeDriverPath = getChromeDriverPath(chromeDriverMap);\n\n\t\tSystem.setProperty(\"webdriver.chrome.driver\", chromeDriverPath);\n\t\tlog.info(\"ChromeDriver path initialized: {}\", chromeDriverPath);\n\t}\n\n\tprivate String getChromeDriverPath(Map<OsType, String> chromeDriverMap) throws URISyntaxException {\n\n\t\tif (chromeDriverMap.size() != 1) {\n\t\t\tthrow new IllegalArgumentException(\"Chrome Driver Map 中的元素数量非法，必须且只能包含一个元素\");\n\t\t}\n\t\tString chromeDriverPath = chromeDriverMap.values().iterator().next();\n\n\t\tURL resource = OpenManusSpringBootApplication.class.getClassLoader().getResource(chromeDriverPath);\n\t\tif (resource == null) {\n\t\t\tthrow new IllegalStateException(\"ChromeDriver not found: \" + chromeDriverPath);\n\t\t}\n\n\t\treturn Paths.get(resource.toURI()).toFile().getAbsolutePath();\n\t}\n\n\tprivate enum OsType {\n\n\t\tWINDOWS, MAC, LINUX, UNSUPPORTED\n\n\t}\n\n\tprivate static Map<OsType, String> checkOS() {\n\n\t\tString os = System.getProperty(\"os.name\").toLowerCase();\n\t\tMap<OsType, String> resMap = new HashMap<>();\n\n\t\tif (os.contains(\"win\")) {\n\t\t\tresMap.put(OsType.WINDOWS, \"chromedriver/win64/chromedriver.exe\");\n\t\t}\n\t\telse if (os.contains(\"mac\")) {\n\t\t\tresMap.put(OsType.MAC, \"chromedriver/mac-arm/chromedriver\");\n\t\t}\n\t\telse if (os.contains(\"nix\") || os.contains(\"nux\") || os.contains(\"aix\")) {\n\t\t\tresMap.put(OsType.LINUX, \"chromedriver/linux64/chromedriver\");\n\t\t}\n\t\telse {\n\t\t\tlog.warn(\"不支持的操作系统类型: {}\", os);\n\t\t\treturn null;\n\t\t}\n\n\t\treturn resMap;\n\t}\n\n\tprivate ChromeDriver createNewDriver() {\n\t\tChromeDriver newDriver = null;\n\t\ttry {\n\t\t\tChromeOptions options = new ChromeOptions();\n\n\t\t\t// 基础配置\n\t\t\toptions.addArguments(\"--remote-allow-origins=*\");\n\t\t\toptions.addArguments(\"--disable-blink-features=AutomationControlled\");\n\n\t\t\t// 根据配置决定是否使用 headless 模式\n\t\t\tif (manusProperties.getBrowserHeadless()) {\n\t\t\t\tlog.info(\"启用 Chrome headless 模式\");\n\t\t\t\toptions.addArguments(\"--headless=true\");\n\t\t\t}\n\n\t\t\t// 模拟真实浏览器环境\n\t\t\toptions.addArguments(\"--disable-infobars\");\n\t\t\toptions.addArguments(\"--disable-notifications\");\n\t\t\toptions.addArguments(\"--disable-dev-shm-usage\");\n\t\t\toptions.addArguments(\"--lang=zh-CN,zh,en-US,en\");\n\n\t\t\t// 添加随机化的用户代理\n\t\t\toptions.addArguments(\"--user-agent=\" + getRandomUserAgent());\n\n\t\t\t// 添加随机化的浏览器窗口大小\n\t\t\tDimension randomSize = getRandomWindowSize();\n\t\t\toptions.addArguments(\"--window-size=\" + randomSize.width + \",\" + randomSize.height);\n\n\t\t\t// 禁用自动化标志\n\t\t\tMap<String, Object> prefs = new HashMap<>();\n\t\t\tprefs.put(\"credentials_enable_service\", false);\n\t\t\tprefs.put(\"profile.password_manager_enabled\", false);\n\t\t\toptions.setExperimentalOption(\"prefs\", prefs);\n\n\t\t\t// 设置 webdriver 属性\n\t\t\tMap<String, Object> properties = new HashMap<>();\n\t\t\tproperties.put(\"navigator.webdriver\", false);\n\t\t\toptions.setExperimentalOption(\"excludeSwitches\", Arrays.asList(\"enable-automation\"));\n\n\t\t\t// 自动匹配版本\n\t\t\tWebDriverManager.chromedriver().setup();\n\t\t\tnewDriver = new ChromeDriver(options);\n\t\t\texecuteAntiDetectionScript(newDriver);\n\t\t\tlog.info(\"Created new ChromeDriver instance with anti-detection\");\n\t\t\treturn newDriver;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tif (newDriver != null) {\n\t\t\t\ttry {\n\t\t\t\t\tnewDriver.quit();\n\t\t\t\t}\n\t\t\t\tcatch (Exception ex) {\n\t\t\t\t\tlog.warn(\"Failed to quit failed driver instance\", ex);\n\t\t\t\t}\n\t\t\t}\n\t\t\tlog.error(\"Failed to create ChromeDriver instance\", e);\n\t\t\tthrow new RuntimeException(\"Failed to initialize ChromeDriver\", e);\n\t\t}\n\t}\n\n\tprivate String getRandomUserAgent() {\n\t\tList<String> userAgents = Arrays.asList(\n\t\t\t\t\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n\t\t\t\t\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n\t\t\t\t\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36 Edg/119.0.0.0\");\n\t\treturn userAgents.get(new Random().nextInt(userAgents.size()));\n\t}\n\n\tprivate Dimension getRandomWindowSize() {\n\t\tList<Dimension> sizes = Arrays.asList(new Dimension(1920, 1080), new Dimension(1366, 768),\n\t\t\t\tnew Dimension(1440, 900));\n\t\treturn sizes.get(new Random().nextInt(sizes.size()));\n\t}\n\n\tprivate void executeAntiDetectionScript(WebDriver driver) {\n\t\t((JavascriptExecutor) driver).executeScript(\"\"\"\n\t\t\t\tObject.defineProperty(navigator, 'webdriver', {\n\t\t\t\t    get: () => undefined\n\t\t\t\t});\n\n\t\t\t\t// 覆盖 navigator 属性\n\t\t\t\tconst newProto = navigator.__proto__;\n\t\t\t\tdelete newProto.webdriver;\n\n\t\t\t\t// 模拟真实的 plugins\n\t\t\t\tObject.defineProperty(navigator, 'plugins', {\n\t\t\t\t    get: () => [1, 2, 3, 4, 5],\n\t\t\t\t});\n\n\t\t\t\t// 模拟真实的语言\n\t\t\t\tObject.defineProperty(navigator, 'languages', {\n\t\t\t\t    get: () => ['zh-CN', 'zh', 'en-US', 'en'],\n\t\t\t\t});\n\t\t\t\t\"\"\");\n\t}\n\n\tprivate boolean isDriverActive(ChromeDriver driver) {\n\t\ttry {\n\t\t\tdriver.getCurrentUrl();\n\t\t\treturn true;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlog.warn(\"Existing ChromeDriver is not active\", e);\n\t\t\tcloseDriver(driver);\n\t\t\treturn false;\n\t\t}\n\t}\n\n\tprivate void closeDriver(WebDriver driver) {\n\t\ttry {\n\t\t\tif (driver != null) {\n\t\t\t\t// 首先关闭所有窗口\n\t\t\t\tSet<String> windowHandles = driver.getWindowHandles();\n\t\t\t\tfor (String handle : windowHandles) {\n\t\t\t\t\ttry {\n\t\t\t\t\t\tdriver.switchTo().window(handle);\n\t\t\t\t\t\tdriver.close();\n\t\t\t\t\t}\n\t\t\t\t\tcatch (Exception e) {\n\t\t\t\t\t\tlog.warn(\"Error closing window: {}\", e.getMessage());\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// 然后退出driver\n\t\t\t\tdriver.quit();\n\t\t\t\tlog.info(\"ChromeDriver closed successfully\");\n\t\t\t}\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlog.error(\"Error closing ChromeDriver\", e);\n\t\t}\n\t}\n\n\tpublic void cleanup(String planId) {\n\t\tif (planId != null) {\n\t\t\tlog.info(\"Cleaning up Chrome resources for plan: {}\", planId);\n\t\t\tcloseDriverForPlan(planId);\n\t\t}\n\t}\n\n\t@PreDestroy\n\tpublic void cleanup() {\n\t\tlog.info(\"Spring container shutting down - cleaning up Chrome resources\");\n\t\tcleanupAllChromeProcesses();\n\t}\n\n}", "metadata": {"commit_sha": "7c6eab6e", "lines_added": 3, "lines_deleted": 0, "total_changes": 3, "chunks": 2}}
{"id": 44, "pattern_type": "import_statement", "file_path": "community/document-readers/es-document-reader/src/main/java/com/alibaba/cloud/ai/document/reader/es/ElasticsearchDocumentReader.java", "file_extension": "java", "input": "/*\n * Copyright 2024-2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.alibaba.cloud.ai.document.reader.es;\n\nimport co.elastic.clients.elasticsearch.ElasticsearchClient;\nimport co.elastic.clients.elasticsearch._types.query_dsl.MatchQuery;\nimport co.elastic.clients.elasticsearch.core.SearchResponse;\nimport co.elastic.clients.json.jackson.JacksonJsonpMapper;\nimport co.elastic.clients.transport.ElasticsearchTransport;\nimport co.elastic.clients.transport.rest_client.RestClientTransport;\nimport org.apache.http.HttpHost;\nimport org.apache.http.auth.AuthScope;\nimport org.apache.http.auth.UsernamePasswordCredentials;\nimport org.apache.http.client.CredentialsProvider;\nimport org.apache.http.impl.client.BasicCredentialsProvider;\nimport org.elasticsearch.client.RestClient;\nimport org.springframework.ai.document.Document;\nimport org.springframework.ai.document.DocumentReader;\nimport org.springframework.util.StringUtils;\n\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Map;\n\n/**\n * A DocumentReader implementation that reads documents from Elasticsearch.\n * Supports basic authentication and customizable query field.\n *\n * @author xiadong\n * @since 0.0.1\n */\npublic class ElasticsearchDocumentReader implements DocumentReader {\n\n    private final ElasticsearchConfig config;\n    private final ElasticsearchClient client;\n\n    /**\n     * Constructor that initializes the Elasticsearch client with the provided configuration.\n     *\n     * @param config The Elasticsearch configuration\n     */\n    public ElasticsearchDocumentReader(ElasticsearchConfig config) {\n        this.config = config;\n        this.client = createClient();\n    }\n\n    @Override\n    public List<Document> get() {\n        try {\n            // Get all documents\n            SearchResponse<Map> response = client.search(s -> s\n                    .index(config.getIndex())\n                    .query(q -> q\n                            .matchAll(m -> m))\n                    .size(config.getMaxResults()), Map.class);\n\n            List<Document> documents = new ArrayList<>();\n            response.hits().hits().forEach(hit -> {\n                Map<String, Object> source = hit.source();\n                if (source != null) {\n                    Document document = new Document(\n                            source.getOrDefault(config.getQueryField(), \"\").toString(),\n                            source\n                    );\n                    documents.add(document);\n                }\n            });\n            return documents;\n        }\n        catch (IOException e) {\n            throw new RuntimeException(\"Failed to get documents from Elasticsearch\", e);\n        }\n    }\n\n    /**\n     * Get a document by its ID.\n     *\n     * @param id The document ID\n     * @return The document if found, null otherwise\n     */\n    public Document getById(String id) {\n        try {\n            var response = client.get(g -> g\n                    .index(config.getIndex())\n                    .id(id), Map.class);\n\n            if (!response.found() || response.source() == null) {\n                return null;\n            }\n\n            return new Document(\n                    response.source().getOrDefault(config.getQueryField(), \"\").toString(),\n                    response.source()\n            );\n        }\n        catch (IOException e) {\n            throw new RuntimeException(\"Failed to get document from Elasticsearch with id: \" + id, e);\n        }\n    }\n\n    /**\n     * Read documents matching the specified query.\n     *\n     * @param query The search query\n     * @return List of matching documents\n     */\n    public List<Document> readWithQuery(String query) {\n        try {\n            // Build the search request with query\n            SearchResponse<Map> response = client.search(s -> s\n                    .index(config.getIndex())\n                    .query(q -> q\n                            .match(new MatchQuery.Builder()\n                                    .field(config.getQueryField())\n                                    .query(query)\n                                    .build()))\n                    .size(config.getMaxResults()), Map.class);\n\n            List<Document> documents = new ArrayList<>();\n            response.hits().hits().forEach(hit -> {\n                Map<String, Object> source = hit.source();\n                if (source != null) {\n                    Document document = new Document(\n                            source.getOrDefault(config.getQueryField(), \"\").toString(),\n                            source\n                    );\n                    documents.add(document);\n                }\n            });\n            return documents;\n        }\n        catch (IOException e) {\n            throw new RuntimeException(\"Failed to read documents from Elasticsearch with query: \" + query, e);\n        }\n    }\n\n    private ElasticsearchClient createClient() {\n        // Build the REST client with optional authentication\n        RestClient.Builder builder = RestClient.builder(\n                new HttpHost(config.getHost(), config.getPort()));\n\n        // Add authentication if credentials are provided\n        if (StringUtils.hasText(config.getUsername()) && StringUtils.hasText(config.getPassword())) {\n            CredentialsProvider credentialsProvider = new BasicCredentialsProvider();\n            credentialsProvider.setCredentials(AuthScope.ANY,\n                    new UsernamePasswordCredentials(config.getUsername(), config.getPassword()));\n            builder.setHttpClientConfigCallback(httpClientBuilder ->\n                    httpClientBuilder.setDefaultCredentialsProvider(credentialsProvider));\n        }\n\n        // Create the transport and client\n        ElasticsearchTransport transport = new RestClientTransport(\n                builder.build(), new JacksonJsonpMapper());\n        return new ElasticsearchClient(transport);\n    }\n}", "output": "/*\n * Copyright 2024-2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.alibaba.cloud.ai.document.reader.es;\n\nimport co.elastic.clients.elasticsearch.ElasticsearchClient;\nimport co.elastic.clients.elasticsearch._types.query_dsl.MatchQuery;\nimport co.elastic.clients.elasticsearch.core.SearchResponse;\nimport co.elastic.clients.json.jackson.JacksonJsonpMapper;\nimport co.elastic.clients.transport.ElasticsearchTransport;\nimport co.elastic.clients.transport.rest_client.RestClientTransport;\nimport org.apache.http.HttpHost;\nimport org.apache.http.auth.AuthScope;\nimport org.apache.http.auth.UsernamePasswordCredentials;\nimport org.apache.http.client.CredentialsProvider;\nimport org.apache.http.impl.client.BasicCredentialsProvider;\nimport org.apache.http.impl.nio.client.HttpAsyncClientBuilder;\nimport org.elasticsearch.client.RestClient;\nimport org.elasticsearch.client.RestClientBuilder;\nimport org.springframework.ai.document.Document;\nimport org.springframework.ai.document.DocumentReader;\nimport org.springframework.util.StringUtils;\n\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Map;\n\n/**\n * A DocumentReader implementation that reads documents from Elasticsearch.\n * Supports basic authentication and customizable query field.\n *\n * @author xiadong\n * @since 0.0.1\n */\npublic class ElasticsearchDocumentReader implements DocumentReader {\n\n    private final ElasticsearchConfig config;\n    private final ElasticsearchClient client;\n\n    /**\n     * Constructor that initializes the Elasticsearch client with the provided configuration.\n     *\n     * @param config The Elasticsearch configuration\n     */\n    public ElasticsearchDocumentReader(ElasticsearchConfig config) {\n        this.config = config;\n        this.client = createClient();\n    }\n\n    @Override\n    public List<Document> get() {\n        try {\n            // Get all documents\n            SearchResponse<Map> response = client.search(s -> s\n                    .index(config.getIndex())\n                    .query(q -> q\n                            .matchAll(m -> m))\n                    .size(config.getMaxResults()), Map.class);\n\n            List<Document> documents = new ArrayList<>();\n            response.hits().hits().forEach(hit -> {\n                Map<String, Object> source = hit.source();\n                if (source != null) {\n                    Document document = new Document(\n                            source.getOrDefault(config.getQueryField(), \"\").toString(),\n                            source\n                    );\n                    documents.add(document);\n                }\n            });\n            return documents;\n        }\n        catch (IOException e) {\n            throw new RuntimeException(\"Failed to get documents from Elasticsearch\", e);\n        }\n    }\n\n    /**\n     * Get a document by its ID.\n     *\n     * @param id The document ID\n     * @return The document if found, null otherwise\n     */\n    public Document getById(String id) {\n        try {\n            var response = client.get(g -> g\n                    .index(config.getIndex())\n                    .id(id), Map.class);\n\n            if (!response.found() || response.source() == null) {\n                return null;\n            }\n\n            return new Document(\n                    response.source().getOrDefault(config.getQueryField(), \"\").toString(),\n                    response.source()\n            );\n        }\n        catch (IOException e) {\n            throw new RuntimeException(\"Failed to get document from Elasticsearch with id: \" + id, e);\n        }\n    }\n\n    /**\n     * Read documents matching the specified query.\n     *\n     * @param query The search query\n     * @return List of matching documents\n     */\n    public List<Document> readWithQuery(String query) {\n        try {\n            // Build the search request with query\n            SearchResponse<Map> response = client.search(s -> s\n                    .index(config.getIndex())\n                    .query(q -> q\n                            .match(new MatchQuery.Builder()\n                                    .field(config.getQueryField())\n                                    .query(query)\n                                    .build()))\n                    .size(config.getMaxResults()), Map.class);\n\n            List<Document> documents = new ArrayList<>();\n            response.hits().hits().forEach(hit -> {\n                Map<String, Object> source = hit.source();\n                if (source != null) {\n                    Document document = new Document(\n                            source.getOrDefault(config.getQueryField(), \"\").toString(),\n                            source\n                    );\n                    documents.add(document);\n                }\n            });\n            return documents;\n        }\n        catch (IOException e) {\n            throw new RuntimeException(\"Failed to read documents from Elasticsearch with query: \" + query, e);\n        }\n    }\n\n    private ElasticsearchClient createClient() {\n        // Create RestClient configuration\n        HttpHost httpHost = new HttpHost(config.getHost(), config.getPort());\n        RestClientBuilder restClientBuilder = RestClient.builder(httpHost);\n\n        // Add authentication if credentials are provided\n        if (StringUtils.hasText(config.getUsername()) && StringUtils.hasText(config.getPassword())) {\n            CredentialsProvider credentialsProvider = new BasicCredentialsProvider();\n            credentialsProvider.setCredentials(AuthScope.ANY,\n                    new UsernamePasswordCredentials(config.getUsername(), config.getPassword()));\n\n            restClientBuilder.setHttpClientConfigCallback(\n                    (HttpAsyncClientBuilder clientBuilder) -> clientBuilder\n                            .setDefaultCredentialsProvider(credentialsProvider));\n        }\n\n        // Create the transport and client\n        ElasticsearchTransport transport = new RestClientTransport(\n                restClientBuilder.build(), new JacksonJsonpMapper());\n        return new ElasticsearchClient(transport);\n    }\n}", "metadata": {"commit_sha": "22cfbc32", "lines_added": 10, "lines_deleted": 6, "total_changes": 16, "chunks": 2}}
{"id": 180, "pattern_type": "function_signature_change", "file_path": "spring-ai-alibaba-nl2sql/spring-ai-alibaba-nl2sql-chat/src/main/java/com/alibaba/cloud/ai/node/SqlExecuteNode.java", "file_extension": "java", "input": "/*\n * Copyright 2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage com.alibaba.cloud.ai.node;\n\nimport com.alibaba.cloud.ai.connector.accessor.Accessor;\nimport com.alibaba.cloud.ai.connector.bo.DbQueryParameter;\nimport com.alibaba.cloud.ai.connector.bo.ResultSetBO;\nimport com.alibaba.cloud.ai.connector.config.DbConfig;\nimport com.alibaba.cloud.ai.constant.Constant;\n\nimport com.alibaba.cloud.ai.enums.StreamResponseType;\nimport com.alibaba.cloud.ai.graph.OverAllState;\nimport com.alibaba.cloud.ai.model.execution.ExecutionStep;\nimport com.alibaba.cloud.ai.service.DatasourceService;\nimport com.alibaba.cloud.ai.entity.AgentDatasource;\nimport com.alibaba.cloud.ai.entity.Datasource;\nimport com.alibaba.cloud.ai.util.ChatResponseUtil;\nimport com.alibaba.cloud.ai.util.StateUtils;\nimport com.alibaba.cloud.ai.util.StepResultUtils;\nimport com.alibaba.cloud.ai.util.StreamingChatGeneratorUtil;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.ai.chat.model.ChatResponse;\nimport reactor.core.publisher.Flux;\n\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\n\nimport static com.alibaba.cloud.ai.constant.Constant.SQL_EXECUTE_NODE_EXCEPTION_OUTPUT;\nimport static com.alibaba.cloud.ai.constant.Constant.SQL_EXECUTE_NODE_OUTPUT;\n\n/**\n * SQL execution node that executes SQL queries against the database.\n *\n * This node is responsible for: - Executing SQL queries generated by previous nodes -\n * Handling query results and errors - Providing streaming feedback to users during\n * execution - Managing step-by-step result accumulation\n *\n * @author zhangshenghang\n */\npublic class SqlExecuteNode extends AbstractPlanBasedNode {\n\n\tprivate static final Logger logger = LoggerFactory.getLogger(SqlExecuteNode.class);\n\n\tprivate final Accessor dbAccessor;\n\n\tprivate final DatasourceService datasourceService;\n\n\tpublic SqlExecuteNode(Accessor dbAccessor, DatasourceService datasourceService) {\n\t\tsuper();\n\t\tthis.dbAccessor = dbAccessor;\n\t\tthis.datasourceService = datasourceService;\n\t}\n\n\t@Override\n\tpublic Map<String, Object> apply(OverAllState state) throws Exception {\n\t\tlogNodeEntry();\n\n\t\tExecutionStep executionStep = getCurrentExecutionStep(state);\n\t\tInteger currentStep = getCurrentStepNumber(state);\n\n\t\tExecutionStep.ToolParameters toolParameters = executionStep.getToolParameters();\n\t\tString sqlQuery = toolParameters.getSqlQuery();\n\n\t\tlogger.info(\"Executing SQL query: {}\", sqlQuery);\n\t\tlogger.info(\"Step description: {}\", toolParameters.getDescription());\n\n\t\t// Dynamically get the data source configuration for an agent\n\t\tDbConfig dbConfig = getAgentDbConfig(state);\n\n\t\treturn executeSqlQuery(state, currentStep, sqlQuery, dbConfig);\n\t}\n\n\t/**\n\t * Dynamically get the data source configuration for an agent\n\t * @param state The state object containing the agent ID\n\t * @return The database configuration corresponding to the agent\n\t * @throws RuntimeException If the agent has no enabled data source configured\n\t */\n\tprivate DbConfig getAgentDbConfig(OverAllState state) {\n\t\ttry {\n\t\t\t// Get the agent ID from the state\n\t\t\tString agentIdStr = StateUtils.getStringValue(state, Constant.AGENT_ID);\n\t\t\tif (agentIdStr == null || agentIdStr.trim().isEmpty()) {\n\t\t\t\tthrow new RuntimeException(\"未找到智能体ID，无法获取数据源配置\");\n\t\t\t}\n\n\t\t\tInteger agentId = Integer.valueOf(agentIdStr);\n\t\t\tlogger.info(\"Getting datasource config for agent: {}\", agentId);\n\n\t\t\t// Get the enabled data source for the agent\n\t\t\tList<AgentDatasource> agentDatasources = datasourceService.getAgentDatasources(agentId);\n\t\t\tif (agentDatasources.size() == 0) {\n\t\t\t\t// TODO 调试AgentID不一致，暂时手动处理\n\t\t\t\tagentDatasources = datasourceService.getAgentDatasources(agentId - 999999);\n\t\t\t}\n\t\t\tAgentDatasource activeDatasource = agentDatasources.stream()\n\t\t\t\t.filter(ad -> ad.getIsActive() == 1)\n\t\t\t\t.findFirst()\n\t\t\t\t.orElseThrow(() -> new RuntimeException(\"智能体 \" + agentId + \" 未配置启用的数据源\"));\n\n\t\t\t// Convert to DbConfig\n\t\t\tDbConfig dbConfig = createDbConfigFromDatasource(activeDatasource.getDatasource());\n\t\t\tlogger.info(\"Successfully created DbConfig for agent {}: url={}, schema={}, type={}\", agentId,\n\t\t\t\t\tdbConfig.getUrl(), dbConfig.getSchema(), dbConfig.getDialectType());\n\n\t\t\treturn dbConfig;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlogger.error(\"Failed to get agent datasource config\", e);\n\t\t\tthrow new RuntimeException(\"获取智能体数据源配置失败: \" + e.getMessage(), e);\n\t\t}\n\t}\n\n\t/**\n\t * Create database configuration from data source entity\n\t * @param datasource The data source entity\n\t * @return The database configuration object\n\t */\n\tprivate DbConfig createDbConfigFromDatasource(Datasource datasource) {\n\t\tDbConfig dbConfig = new DbConfig();\n\n\t\t// Set basic connection information\n\t\tdbConfig.setUrl(datasource.getConnectionUrl());\n\t\tdbConfig.setUsername(datasource.getUsername());\n\t\tdbConfig.setPassword(datasource.getPassword());\n\n\t\t// Set database type\n\t\tif (\"mysql\".equalsIgnoreCase(datasource.getType())) {\n\t\t\tdbConfig.setConnectionType(\"jdbc\");\n\t\t\tdbConfig.setDialectType(\"mysql\");\n\t\t}\n\t\telse if (\"postgresql\".equalsIgnoreCase(datasource.getType())) {\n\t\t\tdbConfig.setConnectionType(\"jdbc\");\n\t\t\tdbConfig.setDialectType(\"postgresql\");\n\t\t}\n\t\telse {\n\t\t\tthrow new RuntimeException(\"不支持的数据库类型: \" + datasource.getType());\n\t\t}\n\n\t\t// Set Schema to the database name of the data source\n\t\tdbConfig.setSchema(datasource.getDatabaseName());\n\n\t\treturn dbConfig;\n\t}\n\n\t/**\n\t * Executes the SQL query against the database and handles the results.\n\t *\n\t * This method follows the business-logic-first pattern: 1. Execute the actual SQL\n\t * query immediately 2. Process and store the results 3. Create streaming output for\n\t * user experience only\n\t * @param state The overall state containing execution context\n\t * @param currentStep The current step number in the execution plan\n\t * @param sqlQuery The SQL query to execute\n\t * @param dbConfig The database configuration to use for execution\n\t * @return Map containing the generator for streaming output\n\t */\n\t@SuppressWarnings(\"unchecked\")\n\tprivate Map<String, Object> executeSqlQuery(OverAllState state, Integer currentStep, String sqlQuery,\n\t\t\tDbConfig dbConfig) {\n\t\t// Execute business logic first - actual SQL execution\n\t\tDbQueryParameter dbQueryParameter = new DbQueryParameter();\n\t\tdbQueryParameter.setSql(sqlQuery);\n\n\t\ttry {\n\t\t\t// Execute SQL query and get results immediately\n\t\t\tResultSetBO resultSetBO = dbAccessor.executeSqlAndReturnObject(dbConfig, dbQueryParameter);\n\t\t\tString jsonStr = resultSetBO.toJsonStr();\n\n\t\t\t// Update step results with the query output\n\t\t\tMap<String, String> existingResults = StateUtils.getObjectValue(state, SQL_EXECUTE_NODE_OUTPUT, Map.class,\n\t\t\t\t\tnew HashMap<>());\n\t\t\tMap<String, String> updatedResults = StepResultUtils.addStepResult(existingResults, currentStep, jsonStr);\n\n\t\t\tlogger.info(\"SQL execution successful, result count: {}\",\n\t\t\t\t\tresultSetBO.getData() != null ? resultSetBO.getData().size() : 0);\n\n\t\t\t// Prepare the final result object\n\t\t\t// Store List of SQL query results for use by code execution node\n\t\t\tMap<String, Object> result = Map.of(SQL_EXECUTE_NODE_OUTPUT, updatedResults,\n\t\t\t\t\tSQL_EXECUTE_NODE_EXCEPTION_OUTPUT, \"\", Constant.SQL_RESULT_LIST_MEMORY, resultSetBO.getData());\n\n\t\t\t// Create display flux for user experience only\n\t\t\tFlux<ChatResponse> displayFlux = Flux.create(emitter -> {\n\t\t\t\temitter.next(ChatResponseUtil.createStatusResponse(\"开始执行SQL...\"));\n\t\t\t\temitter.next(ChatResponseUtil.createStatusResponse(\"执行SQL查询\"));\n\t\t\t\temitter.next(ChatResponseUtil.createStatusResponse(\"```\" + sqlQuery + \"```\"));\n\t\t\t\temitter.next(ChatResponseUtil.createStatusResponse(\"执行SQL完成\"));\n\t\t\t\temitter.complete();\n\t\t\t});\n\n\t\t\t// Create generator using utility class, returning pre-computed business logic\n\t\t\t// result\n\t\t\tvar generator = StreamingChatGeneratorUtil.createStreamingGeneratorWithMessages(this.getClass(), state,\n\t\t\t\t\tv -> result, displayFlux, StreamResponseType.EXECUTE_SQL);\n\n\t\t\treturn Map.of(SQL_EXECUTE_NODE_OUTPUT, generator);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tString errorMessage = e.getMessage();\n\t\t\tlogger.error(\"SQL execution failed - SQL: [{}] \", sqlQuery, e);\n\n\t\t\t// Prepare error result\n\t\t\tMap<String, Object> errorResult = Map.of(SQL_EXECUTE_NODE_EXCEPTION_OUTPUT, errorMessage);\n\n\t\t\t// Create error display flux\n\t\t\tFlux<ChatResponse> errorDisplayFlux = Flux.create(emitter -> {\n\t\t\t\temitter.next(ChatResponseUtil.createStatusResponse(\"开始执行SQL...\"));\n\t\t\t\temitter.next(ChatResponseUtil.createStatusResponse(\"执行SQL查询\"));\n\t\t\t\temitter.next(ChatResponseUtil.createStatusResponse(\"SQL执行失败: \" + errorMessage));\n\t\t\t\temitter.complete();\n\t\t\t});\n\n\t\t\t// Create error generator using utility class\n\t\t\tvar generator = StreamingChatGeneratorUtil.createStreamingGeneratorWithMessages(this.getClass(), state,\n\t\t\t\t\tv -> errorResult, errorDisplayFlux, StreamResponseType.EXECUTE_SQL);\n\n\t\t\treturn Map.of(SQL_EXECUTE_NODE_EXCEPTION_OUTPUT, generator);\n\t\t}\n\t}\n\n}", "output": "/*\n * Copyright 2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage com.alibaba.cloud.ai.node;\n\nimport com.alibaba.cloud.ai.connector.accessor.Accessor;\nimport com.alibaba.cloud.ai.connector.bo.DbQueryParameter;\nimport com.alibaba.cloud.ai.connector.bo.ResultSetBO;\nimport com.alibaba.cloud.ai.connector.config.DbConfig;\nimport com.alibaba.cloud.ai.constant.Constant;\n\nimport com.alibaba.cloud.ai.enums.StreamResponseType;\nimport com.alibaba.cloud.ai.graph.OverAllState;\nimport com.alibaba.cloud.ai.model.execution.ExecutionStep;\nimport com.alibaba.cloud.ai.service.DatasourceService;\nimport com.alibaba.cloud.ai.entity.AgentDatasource;\nimport com.alibaba.cloud.ai.entity.Datasource;\nimport com.alibaba.cloud.ai.util.ChatResponseUtil;\nimport com.alibaba.cloud.ai.util.StateUtils;\nimport com.alibaba.cloud.ai.util.StepResultUtils;\nimport com.alibaba.cloud.ai.util.StreamingChatGeneratorUtil;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.ai.chat.model.ChatResponse;\nimport reactor.core.publisher.Flux;\n\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\n\nimport static com.alibaba.cloud.ai.constant.Constant.SQL_EXECUTE_NODE_EXCEPTION_OUTPUT;\nimport static com.alibaba.cloud.ai.constant.Constant.SQL_EXECUTE_NODE_OUTPUT;\n\n/**\n * SQL execution node that executes SQL queries against the database.\n *\n * This node is responsible for: - Executing SQL queries generated by previous nodes -\n * Handling query results and errors - Providing streaming feedback to users during\n * execution - Managing step-by-step result accumulation\n *\n * @author zhangshenghang\n */\npublic class SqlExecuteNode extends AbstractPlanBasedNode {\n\n\tprivate static final Logger logger = LoggerFactory.getLogger(SqlExecuteNode.class);\n\n\tprivate final Accessor dbAccessor;\n\n\tprivate final DatasourceService datasourceService;\n\n\tprivate final DbConfig dbConfig;\n\n\tpublic SqlExecuteNode(Accessor dbAccessor, DatasourceService datasourceService, DbConfig dbConfig) {\n\t\tsuper();\n\t\tthis.dbAccessor = dbAccessor;\n\t\tthis.datasourceService = datasourceService;\n\t\tthis.dbConfig = dbConfig;\n\t}\n\n\t@Override\n\tpublic Map<String, Object> apply(OverAllState state) throws Exception {\n\t\tlogNodeEntry();\n\n\t\tExecutionStep executionStep = getCurrentExecutionStep(state);\n\t\tInteger currentStep = getCurrentStepNumber(state);\n\n\t\tExecutionStep.ToolParameters toolParameters = executionStep.getToolParameters();\n\t\tString sqlQuery = toolParameters.getSqlQuery();\n\n\t\tlogger.info(\"Executing SQL query: {}\", sqlQuery);\n\t\tlogger.info(\"Step description: {}\", toolParameters.getDescription());\n\n\t\t// Dynamically get the data source configuration for an agent\n\t\tDbConfig dbConfig = getAgentDbConfig(state);\n\n\t\treturn executeSqlQuery(state, currentStep, sqlQuery, dbConfig);\n\t}\n\n\t/**\n\t * Dynamically get the data source configuration for an agent\n\t * @param state The state object containing the agent ID\n\t * @return The database configuration corresponding to the agent\n\t * @throws RuntimeException If the agent has no enabled data source configured\n\t */\n\tprivate DbConfig getAgentDbConfig(OverAllState state) {\n\t\ttry {\n\t\t\t// Get the agent ID from the state\n\t\t\tString agentIdStr = StateUtils.getStringValue(state, Constant.AGENT_ID);\n\t\t\tif (agentIdStr == null || agentIdStr.trim().isEmpty()) {\n\t\t\t\t// 返回默认数据源\n\t\t\t\treturn dbConfig;\n\t\t\t}\n\n\t\t\tInteger agentId = Integer.valueOf(agentIdStr);\n\t\t\tlogger.info(\"Getting datasource config for agent: {}\", agentId);\n\n\t\t\t// Get the enabled data source for the agent\n\t\t\tList<AgentDatasource> agentDatasources = datasourceService.getAgentDatasources(agentId);\n\t\t\tif (agentDatasources.size() == 0) {\n\t\t\t\t// TODO 调试AgentID不一致，暂时手动处理\n\t\t\t\tagentDatasources = datasourceService.getAgentDatasources(agentId - 999999);\n\t\t\t}\n\t\t\tAgentDatasource activeDatasource = agentDatasources.stream()\n\t\t\t\t.filter(ad -> ad.getIsActive() == 1)\n\t\t\t\t.findFirst()\n\t\t\t\t.orElseThrow(() -> new RuntimeException(\"智能体 \" + agentId + \" 未配置启用的数据源\"));\n\n\t\t\t// Convert to DbConfig\n\t\t\tDbConfig dbConfig = createDbConfigFromDatasource(activeDatasource.getDatasource());\n\t\t\tlogger.info(\"Successfully created DbConfig for agent {}: url={}, schema={}, type={}\", agentId,\n\t\t\t\t\tdbConfig.getUrl(), dbConfig.getSchema(), dbConfig.getDialectType());\n\n\t\t\treturn dbConfig;\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlogger.error(\"Failed to get agent datasource config\", e);\n\t\t\tthrow new RuntimeException(\"获取智能体数据源配置失败: \" + e.getMessage(), e);\n\t\t}\n\t}\n\n\t/**\n\t * Create database configuration from data source entity\n\t * @param datasource The data source entity\n\t * @return The database configuration object\n\t */\n\tprivate DbConfig createDbConfigFromDatasource(Datasource datasource) {\n\t\tDbConfig dbConfig = new DbConfig();\n\n\t\t// Set basic connection information\n\t\tdbConfig.setUrl(datasource.getConnectionUrl());\n\t\tdbConfig.setUsername(datasource.getUsername());\n\t\tdbConfig.setPassword(datasource.getPassword());\n\n\t\t// Set database type\n\t\tif (\"mysql\".equalsIgnoreCase(datasource.getType())) {\n\t\t\tdbConfig.setConnectionType(\"jdbc\");\n\t\t\tdbConfig.setDialectType(\"mysql\");\n\t\t}\n\t\telse if (\"postgresql\".equalsIgnoreCase(datasource.getType())) {\n\t\t\tdbConfig.setConnectionType(\"jdbc\");\n\t\t\tdbConfig.setDialectType(\"postgresql\");\n\t\t}\n\t\telse {\n\t\t\tthrow new RuntimeException(\"不支持的数据库类型: \" + datasource.getType());\n\t\t}\n\n\t\t// Set Schema to the database name of the data source\n\t\tdbConfig.setSchema(datasource.getDatabaseName());\n\n\t\treturn dbConfig;\n\t}\n\n\t/**\n\t * Executes the SQL query against the database and handles the results.\n\t *\n\t * This method follows the business-logic-first pattern: 1. Execute the actual SQL\n\t * query immediately 2. Process and store the results 3. Create streaming output for\n\t * user experience only\n\t * @param state The overall state containing execution context\n\t * @param currentStep The current step number in the execution plan\n\t * @param sqlQuery The SQL query to execute\n\t * @param dbConfig The database configuration to use for execution\n\t * @return Map containing the generator for streaming output\n\t */\n\t@SuppressWarnings(\"unchecked\")\n\tprivate Map<String, Object> executeSqlQuery(OverAllState state, Integer currentStep, String sqlQuery,\n\t\t\tDbConfig dbConfig) {\n\t\t// Execute business logic first - actual SQL execution\n\t\tDbQueryParameter dbQueryParameter = new DbQueryParameter();\n\t\tdbQueryParameter.setSql(sqlQuery);\n\n\t\ttry {\n\t\t\t// Execute SQL query and get results immediately\n\t\t\tResultSetBO resultSetBO = dbAccessor.executeSqlAndReturnObject(dbConfig, dbQueryParameter);\n\t\t\tString jsonStr = resultSetBO.toJsonStr();\n\n\t\t\t// Update step results with the query output\n\t\t\tMap<String, String> existingResults = StateUtils.getObjectValue(state, SQL_EXECUTE_NODE_OUTPUT, Map.class,\n\t\t\t\t\tnew HashMap<>());\n\t\t\tMap<String, String> updatedResults = StepResultUtils.addStepResult(existingResults, currentStep, jsonStr);\n\n\t\t\tlogger.info(\"SQL execution successful, result count: {}\",\n\t\t\t\t\tresultSetBO.getData() != null ? resultSetBO.getData().size() : 0);\n\n\t\t\t// Prepare the final result object\n\t\t\t// Store List of SQL query results for use by code execution node\n\t\t\tMap<String, Object> result = Map.of(SQL_EXECUTE_NODE_OUTPUT, updatedResults,\n\t\t\t\t\tSQL_EXECUTE_NODE_EXCEPTION_OUTPUT, \"\", Constant.SQL_RESULT_LIST_MEMORY, resultSetBO.getData());\n\n\t\t\t// Create display flux for user experience only\n\t\t\tFlux<ChatResponse> displayFlux = Flux.create(emitter -> {\n\t\t\t\temitter.next(ChatResponseUtil.createStatusResponse(\"开始执行SQL...\"));\n\t\t\t\temitter.next(ChatResponseUtil.createStatusResponse(\"执行SQL查询\"));\n\t\t\t\temitter.next(ChatResponseUtil.createStatusResponse(\"```\" + sqlQuery + \"```\"));\n\t\t\t\temitter.next(ChatResponseUtil.createStatusResponse(\"执行SQL完成\"));\n\t\t\t\temitter.complete();\n\t\t\t});\n\n\t\t\t// Create generator using utility class, returning pre-computed business logic\n\t\t\t// result\n\t\t\tvar generator = StreamingChatGeneratorUtil.createStreamingGeneratorWithMessages(this.getClass(), state,\n\t\t\t\t\tv -> result, displayFlux, StreamResponseType.EXECUTE_SQL);\n\n\t\t\treturn Map.of(SQL_EXECUTE_NODE_OUTPUT, generator);\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tString errorMessage = e.getMessage();\n\t\t\tlogger.error(\"SQL execution failed - SQL: [{}] \", sqlQuery, e);\n\n\t\t\t// Prepare error result\n\t\t\tMap<String, Object> errorResult = Map.of(SQL_EXECUTE_NODE_EXCEPTION_OUTPUT, errorMessage);\n\n\t\t\t// Create error display flux\n\t\t\tFlux<ChatResponse> errorDisplayFlux = Flux.create(emitter -> {\n\t\t\t\temitter.next(ChatResponseUtil.createStatusResponse(\"开始执行SQL...\"));\n\t\t\t\temitter.next(ChatResponseUtil.createStatusResponse(\"执行SQL查询\"));\n\t\t\t\temitter.next(ChatResponseUtil.createStatusResponse(\"SQL执行失败: \" + errorMessage));\n\t\t\t\temitter.complete();\n\t\t\t});\n\n\t\t\t// Create error generator using utility class\n\t\t\tvar generator = StreamingChatGeneratorUtil.createStreamingGeneratorWithMessages(this.getClass(), state,\n\t\t\t\t\tv -> errorResult, errorDisplayFlux, StreamResponseType.EXECUTE_SQL);\n\n\t\t\treturn Map.of(SQL_EXECUTE_NODE_EXCEPTION_OUTPUT, generator);\n\t\t}\n\t}\n\n}", "metadata": {"commit_sha": "c9a488cb", "lines_added": 6, "lines_deleted": 2, "total_changes": 8, "chunks": 2}}
{"id": 97, "pattern_type": "import_statement", "file_path": "spring-ai-alibaba-mcp/spring-ai-alibaba-mcp-nacos/src/main/java/com/alibaba/cloud/ai/mcp/nacos/NacosMcpRegister.java", "file_extension": "java", "input": "/*\n * Copyright 2024-2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage com.alibaba.cloud.ai.mcp.nacos;\n\nimport com.alibaba.cloud.ai.mcp.nacos.model.McpServerInfo;\nimport com.alibaba.cloud.ai.mcp.nacos.model.McpToolsInfo;\nimport com.alibaba.cloud.ai.mcp.nacos.model.RemoteServerConfigInfo;\nimport com.alibaba.cloud.ai.mcp.nacos.model.ServiceRefInfo;\nimport com.alibaba.cloud.ai.mcp.nacos.model.ToolMetaInfo;\nimport com.alibaba.cloud.ai.mcp.nacos.utils.JsonUtils;\nimport com.alibaba.nacos.api.PropertyKeyConst;\nimport com.alibaba.nacos.api.config.ConfigService;\nimport com.alibaba.nacos.api.config.listener.Listener;\nimport com.alibaba.nacos.api.exception.NacosException;\nimport com.alibaba.nacos.api.naming.NamingService;\nimport com.alibaba.nacos.api.utils.StringUtils;\nimport com.alibaba.nacos.client.config.NacosConfigService;\nimport com.alibaba.nacos.client.naming.NacosNamingService;\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport io.modelcontextprotocol.server.McpAsyncServer;\nimport io.modelcontextprotocol.server.McpServerFeatures;\nimport io.modelcontextprotocol.spec.DefaultMcpSession;\nimport io.modelcontextprotocol.spec.McpSchema;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.boot.web.context.WebServerInitializedEvent;\nimport org.springframework.context.ApplicationListener;\nimport reactor.core.publisher.Mono;\n\nimport java.lang.reflect.Field;\nimport java.util.ArrayList;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Properties;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.CopyOnWriteArrayList;\nimport java.util.concurrent.Executor;\nimport java.util.stream.Collectors;\n\n/**\n * @author Sunrisea\n */\npublic class NacosMcpRegister implements ApplicationListener<WebServerInitializedEvent> {\n\n\tprivate static final Logger log = LoggerFactory.getLogger(NacosMcpRegister.class);\n\n\tprivate final String toolsGroup = \"mcp-tools\";\n\n\tprivate final String toolsConfigSuffix = \"-mcp-tools.json\";\n\n\tprivate final String configNamespace = \"nacos-default-mcp\";\n\n\tprivate final String serverGroup = \"mcp-server\";\n\n\tprivate String type;\n\n\tprivate NacosMcpRegistryProperties nacosMcpProperties;\n\n\tprivate McpSchema.Implementation serverInfo;\n\n\tprivate McpAsyncServer mcpAsyncServer;\n\n\tprivate CopyOnWriteArrayList<McpServerFeatures.AsyncToolRegistration> tools;\n\n\tprivate Map<String, ToolMetaInfo> toolsMeta;\n\n\tprivate McpSchema.ServerCapabilities serverCapabilities;\n\n\tprivate ConfigService configService;\n\n\tpublic NacosMcpRegister(McpAsyncServer mcpAsyncServer, NacosMcpRegistryProperties nacosMcpProperties, String type) {\n\t\tthis.mcpAsyncServer = mcpAsyncServer;\n\t\tlog.info(\"Mcp server type: \" + type);\n\t\tthis.type = type;\n\t\tthis.nacosMcpProperties = nacosMcpProperties;\n\n\t\ttry {\n\t\t\tClass clazz = McpAsyncServer.class;\n\n\t\t\tField serverInfoField = clazz.getDeclaredField(\"serverInfo\");\n\t\t\tserverInfoField.setAccessible(true);\n\t\t\tthis.serverInfo = (McpSchema.Implementation) serverInfoField.get(mcpAsyncServer);\n\n\t\t\tField serverCapabilitiesField = clazz.getDeclaredField(\"serverCapabilities\");\n\t\t\tserverCapabilitiesField.setAccessible(true);\n\t\t\tthis.serverCapabilities = (McpSchema.ServerCapabilities) serverCapabilitiesField.get(mcpAsyncServer);\n\n\t\t\tField toolsField = clazz.getDeclaredField(\"tools\");\n\t\t\ttoolsField.setAccessible(true);\n\t\t\tthis.tools = (CopyOnWriteArrayList<McpServerFeatures.AsyncToolRegistration>) toolsField.get(mcpAsyncServer);\n\n\t\t\tthis.toolsMeta = new HashMap<>();\n\t\t\tthis.tools.forEach(toolRegistration -> {\n\t\t\t\tToolMetaInfo toolMetaInfo = new ToolMetaInfo();\n\t\t\t\tthis.toolsMeta.put(toolRegistration.tool().name(), toolMetaInfo);\n\t\t\t});\n\n\t\t\tProperties configProperties = nacosMcpProperties.getNacosProperties();\n\t\t\tconfigProperties.put(PropertyKeyConst.NAMESPACE, configNamespace);\n\t\t\tthis.configService = new NacosConfigService(configProperties);\n\t\t\tif (this.serverCapabilities.tools() != null) {\n\t\t\t\tField mcpSessionField = clazz.getDeclaredField(\"mcpSession\");\n\t\t\t\tmcpSessionField.setAccessible(true);\n\t\t\t\tDefaultMcpSession mcpSession = (DefaultMcpSession) mcpSessionField.get(mcpAsyncServer);\n\t\t\t\tField requestHandlersField = DefaultMcpSession.class.getDeclaredField(\"requestHandlers\");\n\t\t\t\trequestHandlersField.setAccessible(true);\n\t\t\t\tConcurrentHashMap<String, DefaultMcpSession.RequestHandler<?>> requestHandlers = (ConcurrentHashMap<String, DefaultMcpSession.RequestHandler<?>>) requestHandlersField\n\t\t\t\t\t.get(mcpSession);\n\t\t\t\trequestHandlers.put(McpSchema.METHOD_TOOLS_LIST, toolsListRequestHandler());\n\n\t\t\t\tString toolsInNacosContent = this.configService.getConfig(this.serverInfo.name() + toolsConfigSuffix,\n\t\t\t\t\t\ttoolsGroup, 3000);\n\t\t\t\tif (toolsInNacosContent != null) {\n\t\t\t\t\tupdateTools(toolsInNacosContent);\n\t\t\t\t}\n\t\t\t\tList<McpSchema.Tool> toolsNeedtoRegister = this.tools.stream()\n\t\t\t\t\t.map(McpServerFeatures.AsyncToolRegistration::tool)\n\t\t\t\t\t.toList();\n\t\t\t\tMcpToolsInfo mcpToolsInfo = new McpToolsInfo();\n\t\t\t\tmcpToolsInfo.setTools(toolsNeedtoRegister);\n\t\t\t\tmcpToolsInfo.setToolsMeta(this.toolsMeta);\n\t\t\t\tString toolsConfigContent = JsonUtils.serialize(mcpToolsInfo);\n\t\t\t\tboolean isPublishSuccess = this.configService.publishConfig(this.serverInfo.name() + toolsConfigSuffix,\n\t\t\t\t\t\ttoolsGroup, toolsConfigContent);\n\t\t\t\tif (!isPublishSuccess) {\n\t\t\t\t\tlog.error(\"Publish tools config to nacos failed.\");\n\t\t\t\t\tthrow new Exception(\"Publish tools config to nacos failed.\");\n\t\t\t\t}\n\t\t\t\tthis.configService.addListener(this.serverInfo.name() + toolsConfigSuffix, toolsGroup, new Listener() {\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void receiveConfigInfo(String configInfo) {\n\t\t\t\t\t\tupdateTools(configInfo);\n\t\t\t\t\t}\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic Executor getExecutor() {\n\t\t\t\t\t\treturn null;\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\n\t\t\tMcpServerInfo mcpServerInfo = new McpServerInfo();\n\t\t\tmcpServerInfo.setName(this.serverInfo.name());\n\t\t\tmcpServerInfo.setVersion(this.serverInfo.version());\n\t\t\tmcpServerInfo.setEnabled(true);\n\t\t\tif (\"stdio\".equals(this.type)) {\n\t\t\t\tmcpServerInfo.setProtocol(\"local\");\n\t\t\t}\n\t\t\telse {\n\t\t\t\tServiceRefInfo serviceRefInfo = new ServiceRefInfo();\n\t\t\t\tserviceRefInfo.setNamespaceId(nacosMcpProperties.getServiceNamespace());\n\t\t\t\tserviceRefInfo.setServiceName(this.serverInfo.name() + \"-mcp-service\");\n\t\t\t\tserviceRefInfo.setGroupName(nacosMcpProperties.getServiceGroup());\n\t\t\t\tRemoteServerConfigInfo remoteServerConfigInfo = new RemoteServerConfigInfo();\n\t\t\t\tremoteServerConfigInfo.setServiceRef(serviceRefInfo);\n\t\t\t\tString contextPath = nacosMcpProperties.getSseExportContextPath();\n\t\t\t\tif (StringUtils.isBlank(contextPath)) {\n\t\t\t\t\tcontextPath = \"\";\n\t\t\t\t}\n\t\t\t\tremoteServerConfigInfo.setExportPath(contextPath + \"/sse\");\n\t\t\t\tmcpServerInfo.setRemoteServerConfig(remoteServerConfigInfo);\n\t\t\t\tmcpServerInfo.setProtocol(\"mcp-sse\");\n\t\t\t}\n\t\t\tif (this.serverCapabilities.tools() != null) {\n\t\t\t\tmcpServerInfo.setToolsDescriptionRef(this.serverInfo.name() + toolsConfigSuffix);\n\t\t\t}\n\t\t\tboolean isPublishSuccess = this.configService.publishConfig(this.serverInfo.name() + \"-mcp-server.json\",\n\t\t\t\t\tserverGroup, JsonUtils.serialize(mcpServerInfo));\n\t\t\tif (!isPublishSuccess) {\n\t\t\t\tlog.error(\"Publish mcp server info to nacos failed.\");\n\t\t\t\tthrow new Exception(\"Publish mcp server info to nacos failed.\");\n\t\t\t}\n\t\t\tlog.info(\"Register mcp server info to nacos successfully\");\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlog.error(\"Failed to register mcp server to nacos\", e);\n\t\t}\n\t}\n\n\tprivate void updateToolDescription(McpServerFeatures.AsyncToolRegistration localToolRegistration,\n\t\t\tMcpSchema.Tool toolInNacos, List<McpServerFeatures.AsyncToolRegistration> toolsRegistrationNeedToUpdate)\n\t\t\tthrows JsonProcessingException {\n\t\tBoolean changed = false;\n\t\tif (localToolRegistration.tool().description() != null\n\t\t\t\t&& !localToolRegistration.tool().description().equals(toolInNacos.description())) {\n\t\t\tchanged = true;\n\t\t}\n\t\tString localInputSchemaString = JsonUtils.serialize(localToolRegistration.tool().inputSchema());\n\t\tMap<String, Object> localInputSchemaMap = JsonUtils.deserialize(localInputSchemaString, Map.class);\n\t\tMap<String, Object> localProperties = (Map<String, Object>) localInputSchemaMap.get(\"properties\");\n\n\t\tString nacosInputSchemaString = JsonUtils.serialize(toolInNacos.inputSchema());\n\t\tMap<Object, Object> nacosInputSchemaMap = JsonUtils.deserialize(nacosInputSchemaString, Map.class);\n\t\tMap<String, Object> nacosProperties = (Map<String, Object>) nacosInputSchemaMap.get(\"properties\");\n\n\t\tfor (String key : localProperties.keySet()) {\n\t\t\tif (nacosProperties.containsKey(key)) {\n\t\t\t\tMap<String, Object> localProperty = (Map<String, Object>) localProperties.get(key);\n\t\t\t\tMap<String, Object> nacosProperty = (Map<String, Object>) nacosProperties.get(key);\n\t\t\t\tString localDescription = (String) localProperty.get(\"description\");\n\t\t\t\tString nacosDescription = (String) nacosProperty.get(\"description\");\n\t\t\t\tif (nacosDescription != null && !nacosDescription.equals(localDescription)) {\n\t\t\t\t\tlocalProperty.put(\"description\", nacosDescription);\n\t\t\t\t\tchanged = true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (changed) {\n\t\t\tMcpSchema.Tool toolNeededUpdate = new McpSchema.Tool(localToolRegistration.tool().name(),\n\t\t\t\t\ttoolInNacos.description(), JsonUtils.serialize(localInputSchemaMap));\n\t\t\ttoolsRegistrationNeedToUpdate\n\t\t\t\t.add(new McpServerFeatures.AsyncToolRegistration(toolNeededUpdate, localToolRegistration.call()));\n\t\t}\n\n\t}\n\n\tprivate void updateTools(String toolsInNacosContent) {\n\t\ttry {\n\t\t\tboolean changed = false;\n\t\t\tMcpToolsInfo toolsInfo = JsonUtils.deserialize(toolsInNacosContent, McpToolsInfo.class);\n\t\t\tList<McpSchema.Tool> toolsInNacos = toolsInfo.getTools();\n\t\t\tif (!this.toolsMeta.equals(toolsInfo.getToolsMeta())) {\n\t\t\t\tchanged = true;\n\t\t\t\tthis.toolsMeta = toolsInfo.getToolsMeta();\n\t\t\t}\n\t\t\tList<McpServerFeatures.AsyncToolRegistration> toolsRegistrationNeedToUpdate = new ArrayList<>();\n\t\t\tMap<String, McpSchema.Tool> toolsInNacosMap = toolsInNacos.stream()\n\t\t\t\t.collect(Collectors.toMap(McpSchema.Tool::name, tool -> tool));\n\t\t\tfor (McpServerFeatures.AsyncToolRegistration toolRegistration : this.tools) {\n\t\t\t\tString name = toolRegistration.tool().name();\n\t\t\t\tif (!toolsInNacosMap.containsKey(name)) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tMcpSchema.Tool toolInNacos = toolsInNacosMap.get(name);\n\t\t\t\tupdateToolDescription(toolRegistration, toolInNacos, toolsRegistrationNeedToUpdate);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tfor (McpServerFeatures.AsyncToolRegistration toolRegistration : toolsRegistrationNeedToUpdate) {\n\t\t\t\tfor (int i = 0; i < this.tools.size(); i++) {\n\t\t\t\t\tif (this.tools.get(i).tool().name().equals(toolRegistration.tool().name())) {\n\t\t\t\t\t\tthis.tools.set(i, toolRegistration);\n\t\t\t\t\t\tchanged = true;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (changed) {\n\t\t\t\tlog.info(\"tools description updated\");\n\t\t\t}\n\t\t\tif (changed && this.serverCapabilities.tools().listChanged()) {\n\t\t\t\tthis.mcpAsyncServer.notifyToolsListChanged().block();\n\t\t\t}\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlog.error(\"Failed to update tools according to nacos\", e);\n\t\t}\n\t}\n\n\t@Override\n\tpublic void onApplicationEvent(WebServerInitializedEvent event) {\n\t\tif (\"stdio\".equals(this.type) || !nacosMcpProperties.isServiceRegister()) {\n\t\t\tlog.info(\"No need to register mcp server service to nacos\");\n\t\t\treturn;\n\t\t}\n\t\ttry {\n\t\t\tint port = event.getWebServer().getPort();\n\t\t\tNamingService namingService = new NacosNamingService(nacosMcpProperties.getNacosProperties());\n\t\t\tnamingService.registerInstance(this.serverInfo.name() + \"-mcp-service\",\n\t\t\t\t\tnacosMcpProperties.getServiceGroup(), nacosMcpProperties.getIp(), port);\n\t\t\tlog.info(\"Register mcp server service to nacos successfully\");\n\t\t}\n\t\tcatch (NacosException e) {\n\t\t\tlog.error(\"Failed to register mcp server service to nacos\", e);\n\t\t}\n\t}\n\n\tprivate DefaultMcpSession.RequestHandler<McpSchema.ListToolsResult> toolsListRequestHandler() {\n\t\treturn params -> {\n\t\t\tList<McpSchema.Tool> toolsAll = this.tools.stream()\n\t\t\t\t.map(McpServerFeatures.AsyncToolRegistration::tool)\n\t\t\t\t.toList();\n\t\t\tList<McpSchema.Tool> toolsEnable = new ArrayList<>();\n\t\t\tfor (McpSchema.Tool tool : toolsAll) {\n\t\t\t\tif (this.toolsMeta.containsKey(tool.name()) && this.toolsMeta.get(tool.name()).getEnabled()) {\n\t\t\t\t\ttoolsEnable.add(tool);\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn Mono.just(new McpSchema.ListToolsResult(toolsEnable, null));\n\t\t};\n\t}\n\n}", "output": "/*\n * Copyright 2024-2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage com.alibaba.cloud.ai.mcp.nacos;\n\nimport com.alibaba.cloud.ai.mcp.nacos.model.McpServerInfo;\nimport com.alibaba.cloud.ai.mcp.nacos.model.McpToolsInfo;\nimport com.alibaba.cloud.ai.mcp.nacos.model.RemoteServerConfigInfo;\nimport com.alibaba.cloud.ai.mcp.nacos.model.ServiceRefInfo;\nimport com.alibaba.cloud.ai.mcp.nacos.model.ToolMetaInfo;\nimport com.alibaba.cloud.ai.mcp.nacos.utils.JsonUtils;\nimport com.alibaba.nacos.api.PropertyKeyConst;\nimport com.alibaba.nacos.api.config.ConfigService;\nimport com.alibaba.nacos.api.config.listener.Listener;\nimport com.alibaba.nacos.api.exception.NacosException;\nimport com.alibaba.nacos.api.naming.NamingService;\nimport com.alibaba.nacos.api.naming.pojo.Instance;\nimport com.alibaba.nacos.api.utils.StringUtils;\nimport com.alibaba.nacos.client.config.NacosConfigService;\nimport com.alibaba.nacos.client.naming.NacosNamingService;\nimport com.fasterxml.jackson.core.JsonProcessingException;\nimport io.modelcontextprotocol.server.McpAsyncServer;\nimport io.modelcontextprotocol.server.McpServerFeatures;\nimport io.modelcontextprotocol.spec.DefaultMcpSession;\nimport io.modelcontextprotocol.spec.McpSchema;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport org.springframework.boot.web.context.WebServerInitializedEvent;\nimport org.springframework.context.ApplicationListener;\nimport reactor.core.publisher.Mono;\n\nimport java.lang.reflect.Field;\nimport java.util.ArrayList;\nimport java.util.HashMap;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Properties;\nimport java.util.concurrent.ConcurrentHashMap;\nimport java.util.concurrent.CopyOnWriteArrayList;\nimport java.util.concurrent.Executor;\nimport java.util.stream.Collectors;\n\n/**\n * @author Sunrisea\n */\npublic class NacosMcpRegister implements ApplicationListener<WebServerInitializedEvent> {\n\n\tprivate static final Logger log = LoggerFactory.getLogger(NacosMcpRegister.class);\n\n\tprivate final String toolsGroup = \"mcp-tools\";\n\n\tprivate final String toolsConfigSuffix = \"-mcp-tools.json\";\n\n\tprivate final String configNamespace = \"nacos-default-mcp\";\n\n\tprivate final String serverGroup = \"mcp-server\";\n\n\tprivate String type;\n\n\tprivate NacosMcpRegistryProperties nacosMcpProperties;\n\n\tprivate McpSchema.Implementation serverInfo;\n\n\tprivate McpAsyncServer mcpAsyncServer;\n\n\tprivate CopyOnWriteArrayList<McpServerFeatures.AsyncToolRegistration> tools;\n\n\tprivate Map<String, ToolMetaInfo> toolsMeta;\n\n\tprivate McpSchema.ServerCapabilities serverCapabilities;\n\n\tprivate ConfigService configService;\n\n\tpublic NacosMcpRegister(McpAsyncServer mcpAsyncServer, NacosMcpRegistryProperties nacosMcpProperties, String type) {\n\t\tthis.mcpAsyncServer = mcpAsyncServer;\n\t\tlog.info(\"Mcp server type: \" + type);\n\t\tthis.type = type;\n\t\tthis.nacosMcpProperties = nacosMcpProperties;\n\n\t\ttry {\n\t\t\tClass clazz = McpAsyncServer.class;\n\n\t\t\tField serverInfoField = clazz.getDeclaredField(\"serverInfo\");\n\t\t\tserverInfoField.setAccessible(true);\n\t\t\tthis.serverInfo = (McpSchema.Implementation) serverInfoField.get(mcpAsyncServer);\n\n\t\t\tField serverCapabilitiesField = clazz.getDeclaredField(\"serverCapabilities\");\n\t\t\tserverCapabilitiesField.setAccessible(true);\n\t\t\tthis.serverCapabilities = (McpSchema.ServerCapabilities) serverCapabilitiesField.get(mcpAsyncServer);\n\n\t\t\tField toolsField = clazz.getDeclaredField(\"tools\");\n\t\t\ttoolsField.setAccessible(true);\n\t\t\tthis.tools = (CopyOnWriteArrayList<McpServerFeatures.AsyncToolRegistration>) toolsField.get(mcpAsyncServer);\n\n\t\t\tthis.toolsMeta = new HashMap<>();\n\t\t\tthis.tools.forEach(toolRegistration -> {\n\t\t\t\tToolMetaInfo toolMetaInfo = new ToolMetaInfo();\n\t\t\t\tthis.toolsMeta.put(toolRegistration.tool().name(), toolMetaInfo);\n\t\t\t});\n\n\t\t\tProperties configProperties = nacosMcpProperties.getNacosProperties();\n\t\t\tconfigProperties.put(PropertyKeyConst.NAMESPACE, configNamespace);\n\t\t\tthis.configService = new NacosConfigService(configProperties);\n\t\t\tif (this.serverCapabilities.tools() != null) {\n\t\t\t\tField mcpSessionField = clazz.getDeclaredField(\"mcpSession\");\n\t\t\t\tmcpSessionField.setAccessible(true);\n\t\t\t\tDefaultMcpSession mcpSession = (DefaultMcpSession) mcpSessionField.get(mcpAsyncServer);\n\t\t\t\tField requestHandlersField = DefaultMcpSession.class.getDeclaredField(\"requestHandlers\");\n\t\t\t\trequestHandlersField.setAccessible(true);\n\t\t\t\tConcurrentHashMap<String, DefaultMcpSession.RequestHandler<?>> requestHandlers = (ConcurrentHashMap<String, DefaultMcpSession.RequestHandler<?>>) requestHandlersField\n\t\t\t\t\t.get(mcpSession);\n\t\t\t\trequestHandlers.put(McpSchema.METHOD_TOOLS_LIST, toolsListRequestHandler());\n\n\t\t\t\tString toolsInNacosContent = this.configService.getConfig(this.serverInfo.name() + toolsConfigSuffix,\n\t\t\t\t\t\ttoolsGroup, 3000);\n\t\t\t\tif (toolsInNacosContent != null) {\n\t\t\t\t\tupdateTools(toolsInNacosContent);\n\t\t\t\t}\n\t\t\t\tList<McpSchema.Tool> toolsNeedtoRegister = this.tools.stream()\n\t\t\t\t\t.map(McpServerFeatures.AsyncToolRegistration::tool)\n\t\t\t\t\t.toList();\n\t\t\t\tMcpToolsInfo mcpToolsInfo = new McpToolsInfo();\n\t\t\t\tmcpToolsInfo.setTools(toolsNeedtoRegister);\n\t\t\t\tmcpToolsInfo.setToolsMeta(this.toolsMeta);\n\t\t\t\tString toolsConfigContent = JsonUtils.serialize(mcpToolsInfo);\n\t\t\t\tboolean isPublishSuccess = this.configService.publishConfig(this.serverInfo.name() + toolsConfigSuffix,\n\t\t\t\t\t\ttoolsGroup, toolsConfigContent);\n\t\t\t\tif (!isPublishSuccess) {\n\t\t\t\t\tlog.error(\"Publish tools config to nacos failed.\");\n\t\t\t\t\tthrow new Exception(\"Publish tools config to nacos failed.\");\n\t\t\t\t}\n\t\t\t\tthis.configService.addListener(this.serverInfo.name() + toolsConfigSuffix, toolsGroup, new Listener() {\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void receiveConfigInfo(String configInfo) {\n\t\t\t\t\t\tupdateTools(configInfo);\n\t\t\t\t\t}\n\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic Executor getExecutor() {\n\t\t\t\t\t\treturn null;\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\n\t\t\tMcpServerInfo mcpServerInfo = new McpServerInfo();\n\t\t\tmcpServerInfo.setName(this.serverInfo.name());\n\t\t\tmcpServerInfo.setVersion(this.serverInfo.version());\n\t\t\tmcpServerInfo.setEnabled(true);\n\t\t\tif (\"stdio\".equals(this.type)) {\n\t\t\t\tmcpServerInfo.setProtocol(\"local\");\n\t\t\t}\n\t\t\telse {\n\t\t\t\tServiceRefInfo serviceRefInfo = new ServiceRefInfo();\n\t\t\t\tserviceRefInfo.setNamespaceId(nacosMcpProperties.getServiceNamespace());\n\t\t\t\tserviceRefInfo.setServiceName(this.serverInfo.name() + \"-mcp-service\");\n\t\t\t\tserviceRefInfo.setGroupName(nacosMcpProperties.getServiceGroup());\n\t\t\t\tRemoteServerConfigInfo remoteServerConfigInfo = new RemoteServerConfigInfo();\n\t\t\t\tremoteServerConfigInfo.setServiceRef(serviceRefInfo);\n\t\t\t\tString contextPath = nacosMcpProperties.getSseExportContextPath();\n\t\t\t\tif (StringUtils.isBlank(contextPath)) {\n\t\t\t\t\tcontextPath = \"\";\n\t\t\t\t}\n\t\t\t\tremoteServerConfigInfo.setExportPath(contextPath + \"/sse\");\n\t\t\t\tmcpServerInfo.setRemoteServerConfig(remoteServerConfigInfo);\n\t\t\t\tmcpServerInfo.setProtocol(\"mcp-sse\");\n\t\t\t}\n\t\t\tif (this.serverCapabilities.tools() != null) {\n\t\t\t\tmcpServerInfo.setToolsDescriptionRef(this.serverInfo.name() + toolsConfigSuffix);\n\t\t\t}\n\t\t\tboolean isPublishSuccess = this.configService.publishConfig(this.serverInfo.name() + \"-mcp-server.json\",\n\t\t\t\t\tserverGroup, JsonUtils.serialize(mcpServerInfo));\n\t\t\tif (!isPublishSuccess) {\n\t\t\t\tlog.error(\"Publish mcp server info to nacos failed.\");\n\t\t\t\tthrow new Exception(\"Publish mcp server info to nacos failed.\");\n\t\t\t}\n\t\t\tlog.info(\"Register mcp server info to nacos successfully\");\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlog.error(\"Failed to register mcp server to nacos\", e);\n\t\t}\n\t}\n\n\tprivate void updateToolDescription(McpServerFeatures.AsyncToolRegistration localToolRegistration,\n\t\t\tMcpSchema.Tool toolInNacos, List<McpServerFeatures.AsyncToolRegistration> toolsRegistrationNeedToUpdate)\n\t\t\tthrows JsonProcessingException {\n\t\tBoolean changed = false;\n\t\tif (localToolRegistration.tool().description() != null\n\t\t\t\t&& !localToolRegistration.tool().description().equals(toolInNacos.description())) {\n\t\t\tchanged = true;\n\t\t}\n\t\tString localInputSchemaString = JsonUtils.serialize(localToolRegistration.tool().inputSchema());\n\t\tMap<String, Object> localInputSchemaMap = JsonUtils.deserialize(localInputSchemaString, Map.class);\n\t\tMap<String, Object> localProperties = (Map<String, Object>) localInputSchemaMap.get(\"properties\");\n\n\t\tString nacosInputSchemaString = JsonUtils.serialize(toolInNacos.inputSchema());\n\t\tMap<Object, Object> nacosInputSchemaMap = JsonUtils.deserialize(nacosInputSchemaString, Map.class);\n\t\tMap<String, Object> nacosProperties = (Map<String, Object>) nacosInputSchemaMap.get(\"properties\");\n\n\t\tfor (String key : localProperties.keySet()) {\n\t\t\tif (nacosProperties.containsKey(key)) {\n\t\t\t\tMap<String, Object> localProperty = (Map<String, Object>) localProperties.get(key);\n\t\t\t\tMap<String, Object> nacosProperty = (Map<String, Object>) nacosProperties.get(key);\n\t\t\t\tString localDescription = (String) localProperty.get(\"description\");\n\t\t\t\tString nacosDescription = (String) nacosProperty.get(\"description\");\n\t\t\t\tif (nacosDescription != null && !nacosDescription.equals(localDescription)) {\n\t\t\t\t\tlocalProperty.put(\"description\", nacosDescription);\n\t\t\t\t\tchanged = true;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (changed) {\n\t\t\tMcpSchema.Tool toolNeededUpdate = new McpSchema.Tool(localToolRegistration.tool().name(),\n\t\t\t\t\ttoolInNacos.description(), JsonUtils.serialize(localInputSchemaMap));\n\t\t\ttoolsRegistrationNeedToUpdate\n\t\t\t\t.add(new McpServerFeatures.AsyncToolRegistration(toolNeededUpdate, localToolRegistration.call()));\n\t\t}\n\n\t}\n\n\tprivate void updateTools(String toolsInNacosContent) {\n\t\ttry {\n\t\t\tboolean changed = false;\n\t\t\tMcpToolsInfo toolsInfo = JsonUtils.deserialize(toolsInNacosContent, McpToolsInfo.class);\n\t\t\tList<McpSchema.Tool> toolsInNacos = toolsInfo.getTools();\n\t\t\tif (!this.toolsMeta.equals(toolsInfo.getToolsMeta())) {\n\t\t\t\tchanged = true;\n\t\t\t\tthis.toolsMeta = toolsInfo.getToolsMeta();\n\t\t\t}\n\t\t\tList<McpServerFeatures.AsyncToolRegistration> toolsRegistrationNeedToUpdate = new ArrayList<>();\n\t\t\tMap<String, McpSchema.Tool> toolsInNacosMap = toolsInNacos.stream()\n\t\t\t\t.collect(Collectors.toMap(McpSchema.Tool::name, tool -> tool));\n\t\t\tfor (McpServerFeatures.AsyncToolRegistration toolRegistration : this.tools) {\n\t\t\t\tString name = toolRegistration.tool().name();\n\t\t\t\tif (!toolsInNacosMap.containsKey(name)) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tMcpSchema.Tool toolInNacos = toolsInNacosMap.get(name);\n\t\t\t\tupdateToolDescription(toolRegistration, toolInNacos, toolsRegistrationNeedToUpdate);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tfor (McpServerFeatures.AsyncToolRegistration toolRegistration : toolsRegistrationNeedToUpdate) {\n\t\t\t\tfor (int i = 0; i < this.tools.size(); i++) {\n\t\t\t\t\tif (this.tools.get(i).tool().name().equals(toolRegistration.tool().name())) {\n\t\t\t\t\t\tthis.tools.set(i, toolRegistration);\n\t\t\t\t\t\tchanged = true;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (changed) {\n\t\t\t\tlog.info(\"tools description updated\");\n\t\t\t}\n\t\t\tif (changed && this.serverCapabilities.tools().listChanged()) {\n\t\t\t\tthis.mcpAsyncServer.notifyToolsListChanged().block();\n\t\t\t}\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tlog.error(\"Failed to update tools according to nacos\", e);\n\t\t}\n\t}\n\n\t@Override\n\tpublic void onApplicationEvent(WebServerInitializedEvent event) {\n\t\tif (\"stdio\".equals(this.type) || !nacosMcpProperties.isServiceRegister()) {\n\t\t\tlog.info(\"No need to register mcp server service to nacos\");\n\t\t\treturn;\n\t\t}\n\t\ttry {\n\t\t\tint port = event.getWebServer().getPort();\n\t\t\tNamingService namingService = new NacosNamingService(nacosMcpProperties.getNacosProperties());\n\t\t\tInstance instance = new Instance();\n\t\t\tinstance.setIp(nacosMcpProperties.getIp());\n\t\t\tinstance.setPort(port);\n\t\t\tinstance.setEphemeral(nacosMcpProperties.isServiceEphemeral());\n\t\t\tnamingService.registerInstance(this.serverInfo.name() + \"-mcp-service\",\n\t\t\t\t\tnacosMcpProperties.getServiceGroup(), instance);\n\t\t\tlog.info(\"Register mcp server service to nacos successfully\");\n\t\t}\n\t\tcatch (NacosException e) {\n\t\t\tlog.error(\"Failed to register mcp server service to nacos\", e);\n\t\t}\n\t}\n\n\tprivate DefaultMcpSession.RequestHandler<McpSchema.ListToolsResult> toolsListRequestHandler() {\n\t\treturn params -> {\n\t\t\tList<McpSchema.Tool> toolsAll = this.tools.stream()\n\t\t\t\t.map(McpServerFeatures.AsyncToolRegistration::tool)\n\t\t\t\t.toList();\n\t\t\tList<McpSchema.Tool> toolsEnable = new ArrayList<>();\n\t\t\tfor (McpSchema.Tool tool : toolsAll) {\n\t\t\t\tif (this.toolsMeta.containsKey(tool.name()) && this.toolsMeta.get(tool.name()).getEnabled()) {\n\t\t\t\t\ttoolsEnable.add(tool);\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn Mono.just(new McpSchema.ListToolsResult(toolsEnable, null));\n\t\t};\n\t}\n\n}", "metadata": {"commit_sha": "561ba1a0", "lines_added": 6, "lines_deleted": 1, "total_changes": 7, "chunks": 2}}
{"id": 152, "pattern_type": "function_signature_change", "file_path": "spring-ai-alibaba-nl2sql/spring-ai-alibaba-nl2sql-chat/src/main/java/com/alibaba/cloud/ai/util/AiConfiguration.java", "file_extension": "java", "input": "/*\n * Copyright 2024-2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.alibaba.cloud.ai.util;\n\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi;\nimport com.alibaba.cloud.ai.dashscope.embedding.DashScopeEmbeddingModel;\nimport com.alibaba.cloud.ai.dashscope.embedding.DashScopeEmbeddingOptions;\nimport org.springframework.ai.chat.client.ChatClient;\nimport org.springframework.ai.chat.model.ChatModel;\nimport org.springframework.ai.document.MetadataMode;\nimport org.springframework.ai.embedding.EmbeddingModel;\nimport org.springframework.ai.openai.OpenAiChatModel;\nimport org.springframework.ai.openai.OpenAiChatOptions;\nimport org.springframework.ai.openai.OpenAiEmbeddingModel;\nimport org.springframework.ai.openai.OpenAiEmbeddingOptions;\nimport org.springframework.ai.openai.api.OpenAiApi;\nimport org.springframework.beans.factory.annotation.Qualifier;\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;\nimport org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.context.annotation.Primary;\nimport org.springframework.util.StringUtils;\n\n/**\n * AI 模型配置类\n *\n * <p>\n * 本配置类提供了 ChatModel 和 EmbeddingModel 的配置。\n *\n * <p>\n * EmbeddingModel 选择策略：\n * <ul>\n * <li>优先使用 DashScope EmbeddingModel（当配置了 spring.ai.dashscope.api-key）</li>\n * <li>备选使用 OpenAI EmbeddingModel（当未配置 DashScope API Key 时）</li>\n * </ul>\n *\n * <p>\n * 为了避免与 Spring Boot 自动配置冲突，建议在 application.yml 中设置： <pre>\n * spring:\n *   ai:\n *     openai:\n *       embedding:\n *         enabled: false  # 禁用 OpenAI EmbeddingModel 自动配置\n * </pre>\n *\n * @author Spring AI Alibaba Team\n */\n@Configuration\npublic class AiConfiguration {\n\n\t@Value(\"${spring.ai.openai.api-key}\")\n\tprivate String openAiApiKey;\n\n\t@Value(\"${spring.ai.openai.base-url}\")\n\tprivate String baseUrl;\n\n\t@Value(\"${spring.ai.openai.model}\")\n\tprivate String model;\n\n\t@Value(\"${spring.ai.dashscope.api-key:}\")\n\tprivate String dashScopeApiKey;\n\n\t@Value(\"${spring.ai.dashscope.embedding.model:text-embedding-v2}\")\n\tprivate String dashScopeEmbeddingModel;\n\n\t@Value(\"${spring.ai.openai.embedding.model:text-embedding-ada-002}\")\n\tprivate String openAiEmbeddingModel;\n\n\t@Bean\n\tpublic ChatModel chatModel() {\n\t\tOpenAiApi openAiApi = OpenAiApi.builder().apiKey(openAiApiKey).baseUrl(baseUrl).build();\n\t\tOpenAiChatOptions openAiChatOptions = OpenAiChatOptions.builder().model(model).temperature(0.7).build();\n\t\treturn OpenAiChatModel.builder().openAiApi(openAiApi).defaultOptions(openAiChatOptions).build();\n\t}\n\n\t@Bean\n\tpublic ChatClient chatClient(@Qualifier(\"chatModel\") ChatModel chatModel) {\n\t\treturn ChatClient.create(chatModel);\n\t}\n\n\t/**\n\t * DashScope EmbeddingModel 配置\n\t * <p>\n\t * 当配置了 spring.ai.dashscope.api-key 时启用，优先级最高\n\t */\n\t@Bean(\"embeddingModel\")\n\t@Primary\n\t@ConditionalOnProperty(name = \"spring.ai.dashscope.api-key\")\n\t@ConditionalOnMissingBean(EmbeddingModel.class)\n\tpublic EmbeddingModel dashScopeEmbeddingModel() {\n\t\tDashScopeApi dashScopeApi = DashScopeApi.builder().apiKey(dashScopeApiKey).build();\n\t\tDashScopeEmbeddingOptions options = DashScopeEmbeddingOptions.builder()\n\t\t\t.withModel(dashScopeEmbeddingModel)\n\t\t\t.build();\n\t\treturn new DashScopeEmbeddingModel(dashScopeApi, MetadataMode.EMBED, options);\n\t}\n\n\t/**\n\t * 自定义 OpenAI EmbeddingModel 配置\n\t * <p>\n\t * 当没有配置 DashScope API Key 时使用\n\t * <p>\n\t * 使用 @ConditionalOnMissingBean 避免与自动配置冲突\n\t */\n\t@Bean(\"embeddingModel\")\n\t@Primary\n\t@ConditionalOnProperty(name = \"spring.ai.dashscope.api-key\", havingValue = \"\", matchIfMissing = true)\n\t@ConditionalOnMissingBean(EmbeddingModel.class)\n\tpublic EmbeddingModel customOpenAiEmbeddingModel() {\n\t\tif (!StringUtils.hasText(openAiApiKey)) {\n\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\"Either spring.ai.dashscope.api-key or spring.ai.openai.api-key must be configured\");\n\t\t}\n\t\tOpenAiApi openAiApi = OpenAiApi.builder().apiKey(openAiApiKey).baseUrl(baseUrl).build();\n\t\tOpenAiEmbeddingOptions options = OpenAiEmbeddingOptions.builder().model(openAiEmbeddingModel).build();\n\t\treturn new OpenAiEmbeddingModel(openAiApi, MetadataMode.EMBED, options);\n\t}\n\n}", "output": "/*\n * Copyright 2024-2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.alibaba.cloud.ai.util;\n\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi;\nimport com.alibaba.cloud.ai.dashscope.embedding.DashScopeEmbeddingModel;\nimport com.alibaba.cloud.ai.dashscope.embedding.DashScopeEmbeddingOptions;\nimport org.springframework.ai.chat.client.ChatClient;\nimport org.springframework.ai.chat.model.ChatModel;\nimport org.springframework.ai.document.MetadataMode;\nimport org.springframework.ai.embedding.EmbeddingModel;\nimport org.springframework.ai.openai.OpenAiChatModel;\nimport org.springframework.ai.openai.OpenAiChatOptions;\nimport org.springframework.ai.openai.OpenAiEmbeddingModel;\nimport org.springframework.ai.openai.OpenAiEmbeddingOptions;\nimport org.springframework.ai.openai.api.OpenAiApi;\nimport org.springframework.beans.factory.annotation.Qualifier;\nimport org.springframework.beans.factory.annotation.Value;\nimport org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;\nimport org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\nimport org.springframework.context.annotation.Primary;\nimport org.springframework.util.StringUtils;\n\n/**\n * AI 模型配置类\n *\n * <p>\n * 本配置类提供了 ChatModel 和 EmbeddingModel 的配置。\n *\n * <p>\n * EmbeddingModel 选择策略：\n * <ul>\n * <li>优先使用 DashScope EmbeddingModel（当配置了 spring.ai.dashscope.api-key）</li>\n * <li>备选使用 OpenAI EmbeddingModel（当未配置 DashScope API Key 时）</li>\n * </ul>\n *\n * <p>\n * 为了避免与 Spring Boot 自动配置冲突，建议在 application.yml 中设置： <pre>\n * spring:\n *   ai:\n *     openai:\n *       embedding:\n *         enabled: false  # 禁用 OpenAI EmbeddingModel 自动配置\n * </pre>\n *\n * @author Spring AI Alibaba Team\n */\n@Configuration\npublic class AiConfiguration {\n\n\t@Value(\"${spring.ai.openai.api-key}\")\n\tprivate String openAiApiKey;\n\n\t@Value(\"${spring.ai.openai.base-url:}\")\n\tprivate String baseUrl;\n\n\t@Value(\"${spring.ai.openai.model:}\")\n\tprivate String model;\n\n\t@Value(\"${spring.ai.dashscope.api-key:}\")\n\tprivate String dashScopeApiKey;\n\n\t@Value(\"${spring.ai.dashscope.embedding.model:text-embedding-v2}\")\n\tprivate String dashScopeEmbeddingModel;\n\n\t@Value(\"${spring.ai.openai.embedding.model:text-embedding-ada-002}\")\n\tprivate String openAiEmbeddingModel;\n\n\t@Value(\"${spring.ai.openai.embedding.embeddings-path:}\")\n\tprivate String openAiEmbeddingsPath;\n\n\t@Value(\"${spring.ai.openai.completions-path:}\")\n\tprivate String openAiCompletionsPath;\n\n\t@Bean\n\tpublic ChatModel chatModel() {\n\t\tOpenAiApi openAiApi = OpenAiApi.builder().apiKey(openAiApiKey).baseUrl(baseUrl).build();\n\t\tOpenAiChatOptions openAiChatOptions = OpenAiChatOptions.builder().model(model).temperature(0.7).build();\n\t\treturn OpenAiChatModel.builder().openAiApi(openAiApi).defaultOptions(openAiChatOptions).build();\n\t}\n\n\t@Bean\n\tpublic ChatClient chatClient(@Qualifier(\"chatModel\") ChatModel chatModel) {\n\t\treturn ChatClient.create(chatModel);\n\t}\n\n\t/**\n\t * DashScope EmbeddingModel 配置\n\t * <p>\n\t * 当配置了 spring.ai.dashscope.api-key 时启用，优先级最高\n\t */\n\t@Bean(\"embeddingModel\")\n\t@Primary\n\t@ConditionalOnProperty(name = \"spring.ai.dashscope.api-key\")\n\t@ConditionalOnMissingBean(EmbeddingModel.class)\n\tpublic EmbeddingModel dashScopeEmbeddingModel() {\n\t\tDashScopeApi dashScopeApi = DashScopeApi.builder().apiKey(dashScopeApiKey).build();\n\t\tDashScopeEmbeddingOptions options = DashScopeEmbeddingOptions.builder()\n\t\t\t.withModel(dashScopeEmbeddingModel)\n\t\t\t.build();\n\t\treturn new DashScopeEmbeddingModel(dashScopeApi, MetadataMode.EMBED, options);\n\t}\n\n\t/**\n\t * 自定义 OpenAI EmbeddingModel 配置\n\t * <p>\n\t * 当没有配置 DashScope API Key 时使用\n\t * <p>\n\t * 使用 @ConditionalOnMissingBean 避免与自动配置冲突\n\t */\n\t@Bean(\"embeddingModel\")\n\t@Primary\n\t@ConditionalOnProperty(name = \"spring.ai.dashscope.api-key\", havingValue = \"\", matchIfMissing = true)\n\t@ConditionalOnMissingBean(EmbeddingModel.class)\n\tpublic EmbeddingModel customOpenAiEmbeddingModel() {\n\t\tif (!StringUtils.hasText(openAiApiKey)) {\n\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\"Either spring.ai.dashscope.api-key or spring.ai.openai.api-key must be configured\");\n\t\t}\n\t\tOpenAiApi.Builder builder = OpenAiApi.builder().apiKey(openAiApiKey).baseUrl(baseUrl);\n\t\tif (StringUtils.hasText(openAiEmbeddingsPath)) {\n\t\t\tbuilder.embeddingsPath(openAiEmbeddingsPath);\n\t\t}\n\t\tif (StringUtils.hasText(openAiCompletionsPath)) {\n\t\t\tbuilder.completionsPath(openAiCompletionsPath);\n\t\t}\n\t\tOpenAiApi openAiApi = builder.build();\n\t\tOpenAiEmbeddingOptions options = OpenAiEmbeddingOptions.builder().model(openAiEmbeddingModel).build();\n\t\treturn new OpenAiEmbeddingModel(openAiApi, MetadataMode.EMBED, options);\n\t}\n\n}", "metadata": {"commit_sha": "79108ae6", "lines_added": 16, "lines_deleted": 3, "total_changes": 19, "chunks": 2}}
{"id": 34, "pattern_type": "import_statement", "file_path": "spring-ai-alibaba-core/src/test/java/com/alibaba/cloud/ai/dashscope/DashscopeAiTestConfiguration.java", "file_extension": "java", "input": "/*\n * Copyright 2024-2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.alibaba.cloud.ai.dashscope;\n\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeImageApi;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeSpeechSynthesisApi;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeAudioTranscriptionApi;\nimport com.alibaba.cloud.ai.dashscope.audio.DashScopeSpeechSynthesisModel;\nimport com.alibaba.cloud.ai.dashscope.audio.DashScopeSpeechSynthesisOptions;\nimport com.alibaba.cloud.ai.dashscope.audio.DashScopeAudioTranscriptionModel;\nimport com.alibaba.cloud.ai.dashscope.chat.DashScopeChatModel;\nimport com.alibaba.cloud.ai.dashscope.chat.DashScopeChatOptions;\nimport com.alibaba.cloud.ai.dashscope.embedding.DashScopeEmbeddingModel;\nimport com.alibaba.cloud.ai.dashscope.image.DashScopeImageModel;\nimport com.alibaba.cloud.ai.dashscope.rerank.DashScopeRerankModel;\nimport com.alibaba.cloud.ai.model.RerankModel;\nimport com.alibaba.dashscope.audio.asr.transcription.Transcription;\nimport com.alibaba.dashscope.audio.tts.SpeechSynthesizer;\n\nimport io.micrometer.observation.tck.TestObservationRegistry;\nimport org.springframework.ai.chat.model.ChatModel;\nimport org.springframework.ai.embedding.EmbeddingModel;\nimport org.springframework.ai.retry.RetryUtils;\nimport org.springframework.boot.SpringBootConfiguration;\nimport org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Scope;\nimport org.springframework.util.StringUtils;\n\nimport static com.alibaba.cloud.ai.dashscope.common.DashScopeApiConstants.DEFAULT_BASE_URL;\n\n@SpringBootConfiguration\npublic class DashscopeAiTestConfiguration {\n\n\t@Bean\n\tpublic DashScopeImageApi dashscopeImageApi() {\n\t\treturn newDashScopeImageApi(getApiKey());\n\t}\n\n\t@Bean\n\tpublic DashScopeApi dashscopeApi() {\n\t\treturn newDashScopeApi(getApiKey());\n\t}\n\n\t@Bean\n\tpublic DashScopeSpeechSynthesisApi dashScopeSpeechSynthesisApi() {\n\t\treturn newDashScopeSpeechSynthesisApi(getApiKey());\n\t}\n\n\t@Bean\n\tpublic DashScopeAudioTranscriptionApi dashScopeAudioTranscriptionApi() {\n\t\treturn newDashScopeAudioTranscriptionApi(getApiKey());\n\t}\n\n\t@Bean\n\tpublic DashScopeApi dashscopeChatApi() {\n\t\treturn newDashScopeChatApi(getApiKey());\n\t}\n\n\tprivate DashScopeApi newDashScopeChatApi(String apiKey) {\n\t\treturn new DashScopeApi(DEFAULT_BASE_URL, apiKey, \"\");\n\t}\n\n\tprivate DashScopeApi newDashScopeApi(String apiKey) {\n\t\treturn new DashScopeApi(apiKey);\n\t}\n\n\tprivate DashScopeSpeechSynthesisApi newDashScopeSpeechSynthesisApi(String apiKey) {\n\t\treturn new DashScopeSpeechSynthesisApi(apiKey);\n\t}\n\n\tprivate DashScopeAudioTranscriptionApi newDashScopeAudioTranscriptionApi(String apiKey) {\n\t\treturn new DashScopeAudioTranscriptionApi(apiKey);\n\t}\n\n\tprivate DashScopeImageApi newDashScopeImageApi(String apiKey) {\n\t\treturn new DashScopeImageApi(apiKey);\n\t}\n\n\tprivate String getApiKey() {\n\t\tString apiKey = System.getenv(\"AI_DASHSCOPE_API_KEY\");\n\t\tif (!StringUtils.hasText(apiKey)) {\n\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\"You must provide an API key.  Put it in an environment variable under the name DASHSCOPE_API_KEY\");\n\t\t}\n\t\treturn apiKey;\n\t}\n\n\t@Bean\n\tpublic ChatModel dashscopeChatModel(DashScopeApi dashscopeChatApi, TestObservationRegistry observationRegistry) {\n\t\treturn new DashScopeChatModel(dashscopeChatApi,\n\t\t\t\tDashScopeChatOptions.builder().withModel(DashScopeApi.DEFAULT_CHAT_MODEL).build(), null,\n\t\t\t\tRetryUtils.DEFAULT_RETRY_TEMPLATE, observationRegistry);\n\t}\n\n\t@Bean\n\tpublic EmbeddingModel dashscopeEmbeddingModel(DashScopeApi dashscopeApi) {\n\t\treturn new DashScopeEmbeddingModel(dashscopeApi);\n\t}\n\n\t@Bean\n\tpublic DashScopeImageModel dashscopeImageModel(DashScopeImageApi dashscopeImageApi) {\n\t\treturn new DashScopeImageModel(dashscopeImageApi);\n\t}\n\n\t@Bean\n\tpublic DashScopeSpeechSynthesisModel dashScopeSpeechSynthesisModel(\n\t\t\tDashScopeSpeechSynthesisApi dashScopeSpeechSynthesisApi) {\n\t\treturn new DashScopeSpeechSynthesisModel(dashScopeSpeechSynthesisApi,\n\t\t\t\tDashScopeSpeechSynthesisOptions.builder().withModel(\"cosyvoice-v1\").withVoice(\"longhua\").build());\n\t}\n\n\t@Bean\n\tpublic DashScopeAudioTranscriptionModel dashScopeAudioTranscriptionModel(\n\t\t\tDashScopeAudioTranscriptionApi dashScopeAudioTranscriptionApi) {\n\t\treturn new DashScopeAudioTranscriptionModel(dashScopeAudioTranscriptionApi);\n\t}\n\n\t@Bean\n\tpublic TestObservationRegistry observationRegistry() {\n\t\treturn TestObservationRegistry.create();\n\t}\n\n\t@Bean\n\t@Scope(\"prototype\")\n\t@ConditionalOnMissingBean\n\tpublic SpeechSynthesizer speechSynthesizer() {\n\t\treturn new SpeechSynthesizer();\n\t}\n\n\t@Bean\n\t@ConditionalOnMissingBean\n\tpublic Transcription transcription() {\n\t\treturn new Transcription();\n\t}\n\n\t@Bean\n\t@ConditionalOnMissingBean\n\tpublic RerankModel dashscopeRerankModel(DashScopeApi dashscopeApi) {\n\t\treturn new DashScopeRerankModel(dashscopeApi);\n\t}\n\n}", "output": "/*\n * Copyright 2024-2025 the original author or authors.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      https://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage com.alibaba.cloud.ai.dashscope;\n\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeApi;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeImageApi;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeSpeechSynthesisApi;\nimport com.alibaba.cloud.ai.dashscope.api.DashScopeAudioTranscriptionApi;\nimport com.alibaba.cloud.ai.dashscope.audio.DashScopeSpeechSynthesisModel;\nimport com.alibaba.cloud.ai.dashscope.audio.DashScopeSpeechSynthesisOptions;\nimport com.alibaba.cloud.ai.dashscope.audio.DashScopeAudioTranscriptionModel;\nimport com.alibaba.cloud.ai.dashscope.chat.DashScopeChatModel;\nimport com.alibaba.cloud.ai.dashscope.chat.DashScopeChatOptions;\nimport com.alibaba.cloud.ai.dashscope.embedding.DashScopeEmbeddingModel;\nimport com.alibaba.cloud.ai.dashscope.image.DashScopeImageModel;\nimport com.alibaba.cloud.ai.dashscope.rerank.DashScopeRerankModel;\nimport com.alibaba.cloud.ai.model.RerankModel;\nimport com.alibaba.dashscope.audio.asr.transcription.Transcription;\nimport com.alibaba.dashscope.audio.tts.SpeechSynthesizer;\n\nimport io.micrometer.observation.tck.TestObservationRegistry;\nimport org.springframework.ai.chat.model.ChatModel;\nimport org.springframework.ai.embedding.EmbeddingModel;\nimport org.springframework.ai.retry.RetryUtils;\nimport org.springframework.boot.SpringBootConfiguration;\nimport org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Scope;\nimport org.springframework.util.StringUtils;\n\nimport static com.alibaba.cloud.ai.dashscope.common.DashScopeApiConstants.DASHSCOPE_API_KEY;\nimport static com.alibaba.cloud.ai.dashscope.common.DashScopeApiConstants.DEFAULT_BASE_URL;\n\n@SpringBootConfiguration\npublic class DashscopeAiTestConfiguration {\n\n\t@Bean\n\tpublic DashScopeImageApi dashscopeImageApi() {\n\t\treturn newDashScopeImageApi(getApiKey());\n\t}\n\n\t@Bean\n\tpublic DashScopeApi dashscopeApi() {\n\t\treturn newDashScopeApi(getApiKey());\n\t}\n\n\t@Bean\n\tpublic DashScopeSpeechSynthesisApi dashScopeSpeechSynthesisApi() {\n\t\treturn newDashScopeSpeechSynthesisApi(getApiKey());\n\t}\n\n\t@Bean\n\tpublic DashScopeAudioTranscriptionApi dashScopeAudioTranscriptionApi() {\n\t\treturn newDashScopeAudioTranscriptionApi(getApiKey());\n\t}\n\n\t@Bean\n\tpublic DashScopeApi dashscopeChatApi() {\n\t\treturn newDashScopeChatApi(getApiKey());\n\t}\n\n\tprivate DashScopeApi newDashScopeChatApi(String apiKey) {\n\t\treturn new DashScopeApi(DEFAULT_BASE_URL, apiKey, \"\");\n\t}\n\n\tprivate DashScopeApi newDashScopeApi(String apiKey) {\n\t\treturn new DashScopeApi(apiKey);\n\t}\n\n\tprivate DashScopeSpeechSynthesisApi newDashScopeSpeechSynthesisApi(String apiKey) {\n\t\treturn new DashScopeSpeechSynthesisApi(apiKey);\n\t}\n\n\tprivate DashScopeAudioTranscriptionApi newDashScopeAudioTranscriptionApi(String apiKey) {\n\t\treturn new DashScopeAudioTranscriptionApi(apiKey);\n\t}\n\n\tprivate DashScopeImageApi newDashScopeImageApi(String apiKey) {\n\t\treturn new DashScopeImageApi(apiKey);\n\t}\n\n\tprivate String getApiKey() {\n\t\tString apiKey = System.getenv(DASHSCOPE_API_KEY);\n\t\tif (!StringUtils.hasText(apiKey)) {\n\t\t\tthrow new IllegalArgumentException(\n\t\t\t\t\t\"You must provide an API key.  Put it in an environment variable under the name DASHSCOPE_API_KEY\");\n\t\t}\n\t\treturn apiKey;\n\t}\n\n\t@Bean\n\tpublic ChatModel dashscopeChatModel(DashScopeApi dashscopeChatApi, TestObservationRegistry observationRegistry) {\n\t\treturn new DashScopeChatModel(dashscopeChatApi,\n\t\t\t\tDashScopeChatOptions.builder().withModel(DashScopeApi.DEFAULT_CHAT_MODEL).build(), null,\n\t\t\t\tRetryUtils.DEFAULT_RETRY_TEMPLATE, observationRegistry);\n\t}\n\n\t@Bean\n\tpublic EmbeddingModel dashscopeEmbeddingModel(DashScopeApi dashscopeApi) {\n\t\treturn new DashScopeEmbeddingModel(dashscopeApi);\n\t}\n\n\t@Bean\n\tpublic DashScopeImageModel dashscopeImageModel(DashScopeImageApi dashscopeImageApi) {\n\t\treturn new DashScopeImageModel(dashscopeImageApi);\n\t}\n\n\t@Bean\n\tpublic DashScopeSpeechSynthesisModel dashScopeSpeechSynthesisModel(\n\t\t\tDashScopeSpeechSynthesisApi dashScopeSpeechSynthesisApi) {\n\t\treturn new DashScopeSpeechSynthesisModel(dashScopeSpeechSynthesisApi,\n\t\t\t\tDashScopeSpeechSynthesisOptions.builder().withModel(\"cosyvoice-v1\").withVoice(\"longhua\").build());\n\t}\n\n\t@Bean\n\tpublic DashScopeAudioTranscriptionModel dashScopeAudioTranscriptionModel(\n\t\t\tDashScopeAudioTranscriptionApi dashScopeAudioTranscriptionApi) {\n\t\treturn new DashScopeAudioTranscriptionModel(dashScopeAudioTranscriptionApi);\n\t}\n\n\t@Bean\n\tpublic TestObservationRegistry observationRegistry() {\n\t\treturn TestObservationRegistry.create();\n\t}\n\n\t@Bean\n\t@Scope(\"prototype\")\n\t@ConditionalOnMissingBean\n\tpublic SpeechSynthesizer speechSynthesizer() {\n\t\treturn new SpeechSynthesizer();\n\t}\n\n\t@Bean\n\t@ConditionalOnMissingBean\n\tpublic Transcription transcription() {\n\t\treturn new Transcription();\n\t}\n\n\t@Bean\n\t@ConditionalOnMissingBean\n\tpublic RerankModel dashscopeRerankModel(DashScopeApi dashscopeApi) {\n\t\treturn new DashScopeRerankModel(dashscopeApi);\n\t}\n\n}", "metadata": {"commit_sha": "7b7ac450", "lines_added": 2, "lines_deleted": 1, "total_changes": 3, "chunks": 2}}
